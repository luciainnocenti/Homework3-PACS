{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDL - Homework3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/Homework3-PACS/blob/master/MLDL_Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "#**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from numpy import random \n",
        "\n",
        "random.seed(33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "#**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "BATCH_SIZE = 128     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 20      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "alfa = 1\n",
        "LR = 1e-6          # The initial Learning Rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "#**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),   \n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "# Define transforms for the test phase\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "#**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "outputId": "64470ea2-b1a8-47d9-d3e7-a124c2d4f552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "# Clone github repository with data\n",
        "!git clone https://github.com/luciainnocenti/Homework3-PACS.git\n",
        "!mv 'Homework3-PACS' 'HW_PACS'\n",
        "\n",
        "from HW_PACS.dataset import PACS_Dataset \n",
        "\n",
        "rootPhoto = \"HW_PACS/PACS/photo\"\n",
        "photos = PACS_Dataset(root = rootPhoto, transform = train_transform)\n",
        "\n",
        "rootArt_painting = \"HW_PACS/PACS/art_painting\"\n",
        "art_painting = PACS_Dataset(root = rootArt_painting, transform = test_transform)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(photos)))\n",
        "print('Test Dataset: {}'.format(len(art_painting)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 10108 (delta 2), reused 0 (delta 0), pack-reused 10102\u001b[K\n",
            "Receiving objects: 100% (10108/10108), 174.20 MiB | 38.51 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "Checking out files: 100% (9995/9995), done.\n",
            "Train Dataset: 1670\n",
            "Test Dataset: 2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "#**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "#**Model without DANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "##**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUjtXa22DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from HW_PACS.gradient_reversal_example import alexNetDA \n",
        "\n",
        "net = alexNetDA(num_classes = 7)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "##**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "# Choose parameters to optimize\n",
        "# To access a different set of parameters, you have to access submodules of AlexNet\n",
        "# (nn.Module objects, like AlexNet, implement the Composite Pattern)\n",
        "# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n",
        "# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n",
        "parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "# We use SGD with momentum\n",
        "\n",
        "#optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "optimizer = optim.Adam(parameters_to_optimize, LR)\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "outputId": "f8098344-58c4-4974-f1ad-e679b9655912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "running_corrects = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "# Iterate over the dataset\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  scheduler.step() \n",
        "  \n",
        "  for images, labels in  tqdm(photos_dataloader):\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(photos))\n",
        "  print(\"Accuracy on training set = \"  + str(accuracy))\n",
        "  running_corrects = 0\n",
        "    "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            " 14%|█▍        | 2/14 [00:02<00:17,  1.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 2.0112955570220947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 10, Loss 1.9544504880905151\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.181437125748503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 20, Loss 1.8786988258361816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.29101796407185626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 3/14 [00:02<00:11,  1.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 30, Loss 1.818904161453247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 40, Loss 1.6520856618881226\n",
            "Accuracy on training set = 0.36766467065868264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:03,  1.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 50, Loss 1.6478114128112793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.45269461077844314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 60, Loss 1.4276676177978516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.5329341317365269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2/14 [00:02<00:17,  1.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 70, Loss 1.5461167097091675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 12/14 [00:05<00:00,  2.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 80, Loss 1.402630090713501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.22it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.5544910179640719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 90, Loss 1.3871232271194458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.25it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.6053892215568862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:07,  1.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 100, Loss 1.2586095333099365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.26it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 110, Loss 1.2893433570861816\n",
            "Accuracy on training set = 0.6173652694610778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:03,  1.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 120, Loss 1.2737518548965454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.27it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.6383233532934132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 5/14 [00:03<00:07,  1.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 130, Loss 1.2010056972503662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.655688622754491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2/14 [00:02<00:16,  1.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 140, Loss 1.116728663444519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 150, Loss 0.9816076755523682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.32it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.6868263473053893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 160, Loss 0.9293521046638489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.26it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.6958083832335329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:08,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 170, Loss 0.972048819065094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 180, Loss 0.9433964490890503\n",
            "Accuracy on training set = 0.7149700598802395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 10/14 [00:05<00:01,  2.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 190, Loss 0.9736971259117126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.28it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.729940119760479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 200, Loss 1.0001200437545776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.26it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.7502994011976047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/14 [00:01<00:24,  1.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 210, Loss 0.8775646090507507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 220, Loss 0.9194539785385132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.7592814371257485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 230, Loss 0.7458876371383667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.7580838323353294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:07,  1.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 240, Loss 0.8007180690765381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 250, Loss 0.732064425945282\n",
            "Accuracy on training set = 0.781437125748503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:03,  1.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 260, Loss 0.7487094402313232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.7916167664670659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 5/14 [00:03<00:08,  1.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 270, Loss 0.7033335566520691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.7988023952095809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsHFI-GAJd69",
        "colab_type": "text"
      },
      "source": [
        "##**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3HV5pqJg1o",
        "colab_type": "code",
        "outputId": "8e76eac2-5bce-468b-99ee-efe0f65ef14c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(art_painting_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(art_painting))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.27734375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPzBRkB3iKWU",
        "colab_type": "code",
        "outputId": "5b92a7e9-ac03-416f-ddba-5bfe7f17ccd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.931746244430542"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NHDb2yBC7jX",
        "colab_type": "text"
      },
      "source": [
        "# Model with DANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9PNdrqJdkSO",
        "colab_type": "text"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC1hCskMXaTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = alexNetDA(num_classes = 7)\n",
        "net = net.to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NemzVoaidnQA",
        "colab_type": "text"
      },
      "source": [
        "## Loss, Optim and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbFj42qsER6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion_class = nn.CrossEntropyLoss() \n",
        "criterion_domain = nn.CrossEntropyLoss()\n",
        "\n",
        "parameters_to_optimize = net.parameters() \n",
        "\n",
        "#optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "optimizer = optim.Adam(parameters_to_optimize, LR)\n",
        "\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgONyH0xfN9W",
        "colab_type": "text"
      },
      "source": [
        "## Test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4arKipfR0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testFunction(datasetName, epoch):  \n",
        "  net = torch.load('model_epoch_' + str(epoch) + '.pt')\n",
        "  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "  if (datasetName == 'photo'):\n",
        "    dataLoader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "  elif( datasetName == 'artPainting'):\n",
        "    dataLoader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "  lenLoader = len(dataLoader)\n",
        "  iterator = iter(dataLoader)\n",
        "  totalLen = 0\n",
        "  running_corrects = 0\n",
        "  criterion = nn.CrossEntropyLoss() \n",
        "  for i in range(lenLoader):\n",
        "    t_img, t_label = next(iterator)\n",
        "\n",
        "    t_img = t_img.to(DEVICE)\n",
        "    t_label = t_label.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    classes_output = net(t_img)\n",
        "\n",
        "    loss = criterion(classes_output, t_label)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(classes_output.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == t_label.data).data.item()\n",
        "    totalLen += len(t_img)\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(totalLen)\n",
        "\n",
        "  print(f'Accuracy on  {datasetName}' f' during epoch {epoch}' f' is {accuracy}' f' loss is {loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW0rUNTbduSm",
        "colab_type": "text"
      },
      "source": [
        "## Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoZJAcaHEtYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "#art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "max_batches = max(len(photos_dataloader), len(art_painting_dataloader))\n",
        "min_batches = min(len(photos_dataloader), len(art_painting_dataloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4tSP1-uEPQt",
        "colab_type": "code",
        "outputId": "83654052-d87b-4f27-f8ad-186e77f05a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "running_corrects = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "# Iterate over the dataset\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  scheduler.step() \n",
        "  iterPh = iter(photos_dataloader)\n",
        "  iterAP = iter(art_painting_dataloader)\n",
        "  for batch in range(max_batches):\n",
        "    net.train() # Sets module in training mode\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "    if( batch == min_batches):\n",
        "      iterPh = iter(photos_dataloader)\n",
        "    images_source, labels_source = next(iterPh)\n",
        "    labels_domain = torch.zeros(len(images_source), dtype=torch.long)\n",
        "    \n",
        "    # Bring data over the device of choice\n",
        "    images_source = images_source.to(DEVICE)\n",
        "    labels_source = labels_source.to(DEVICE)\n",
        "    labels_domain = labels_domain.to(DEVICE)\n",
        "\n",
        "  \n",
        "    # Get the output for classes and domains; class_pred, domain_pred\n",
        "    classes_output = net(images_source)\n",
        "    # Compute the loss on the source domain\n",
        "    loss_s_label = criterion_class(classes_output, labels_source)\n",
        "\n",
        "    domain_output = net(images_source, alfa)\n",
        "    # Compute the loss on the source domain\n",
        "    loss_s_domain = criterion_domain(domain_output, labels_domain)\n",
        "\n",
        "    # Get the output for targets\n",
        "    targets, _ = next(iterAP)\n",
        "    target_domain = torch.ones(len(targets), dtype=torch.long)\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    targets = targets.to(DEVICE)\n",
        "    target_domain = target_domain.to(DEVICE)\n",
        "\n",
        "    target_output = net(targets, alfa)\n",
        "\n",
        "    # Compute the loss on the source domain\n",
        "    loss_t_domain = criterion_domain(target_output,target_domain)\n",
        "\n",
        "    loss = loss_s_label + loss_s_domain + loss_t_domain\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "    print(f'[{batch+1}/{max_batches}] '\n",
        "          f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n",
        "          f't_domain_loss: {loss_t_domain.item():.4f} '\n",
        "          )  \n",
        "  torch.save(net, 'model_epoch_{0}.pt'.format(epoch))\n",
        "  testFunction('photo', epoch)\n",
        "  testFunction('artPainting', epoch)\n",
        "  "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/16] class_loss: 2.1084 s_domain_loss: 0.9644 t_domain_loss: 0.5036 \n",
            "[2/16] class_loss: 2.0468 s_domain_loss: 0.9527 t_domain_loss: 0.5049 \n",
            "[3/16] class_loss: 2.1378 s_domain_loss: 0.9430 t_domain_loss: 0.5195 \n",
            "[4/16] class_loss: 2.1097 s_domain_loss: 0.9499 t_domain_loss: 0.5179 \n",
            "[5/16] class_loss: 2.0293 s_domain_loss: 0.9573 t_domain_loss: 0.5178 \n",
            "[6/16] class_loss: 2.1722 s_domain_loss: 0.9413 t_domain_loss: 0.5178 \n",
            "[7/16] class_loss: 2.1671 s_domain_loss: 0.9443 t_domain_loss: 0.5220 \n",
            "[8/16] class_loss: 2.0296 s_domain_loss: 0.9461 t_domain_loss: 0.5275 \n",
            "[9/16] class_loss: 1.9898 s_domain_loss: 0.9376 t_domain_loss: 0.5275 \n",
            "[10/16] class_loss: 2.1053 s_domain_loss: 0.9369 t_domain_loss: 0.5261 \n",
            "[11/16] class_loss: 2.0317 s_domain_loss: 0.9337 t_domain_loss: 0.5269 \n",
            "[12/16] class_loss: 1.9593 s_domain_loss: 0.9427 t_domain_loss: 0.5261 \n",
            "[13/16] class_loss: 2.0361 s_domain_loss: 0.9339 t_domain_loss: 0.5225 \n",
            "[14/16] class_loss: 1.8322 s_domain_loss: 0.9710 t_domain_loss: 0.5290 \n",
            "[15/16] class_loss: 2.0064 s_domain_loss: 0.9252 t_domain_loss: 0.5353 \n",
            "[16/16] class_loss: 2.0002 s_domain_loss: 0.9139 t_domain_loss: 0.5331 \n",
            "Accuracy on  photo during epoch 0 is 0.19640718562874251 loss is 2.3725767135620117\n",
            "Accuracy on  artPainting during epoch 0 is 0.17578125 loss is 1.9012941122055054\n",
            "[1/16] class_loss: 1.8479 s_domain_loss: 0.9233 t_domain_loss: 0.5206 \n",
            "[2/16] class_loss: 2.0053 s_domain_loss: 0.9247 t_domain_loss: 0.5220 \n",
            "[3/16] class_loss: 1.9696 s_domain_loss: 0.9064 t_domain_loss: 0.5369 \n",
            "[4/16] class_loss: 1.8619 s_domain_loss: 0.9120 t_domain_loss: 0.5353 \n",
            "[5/16] class_loss: 1.9045 s_domain_loss: 0.9203 t_domain_loss: 0.5351 \n",
            "[6/16] class_loss: 1.9272 s_domain_loss: 0.9087 t_domain_loss: 0.5363 \n",
            "[7/16] class_loss: 1.9630 s_domain_loss: 0.9116 t_domain_loss: 0.5411 \n",
            "[8/16] class_loss: 1.9399 s_domain_loss: 0.9095 t_domain_loss: 0.5460 \n",
            "[9/16] class_loss: 1.9691 s_domain_loss: 0.9031 t_domain_loss: 0.5455 \n",
            "[10/16] class_loss: 1.9095 s_domain_loss: 0.9050 t_domain_loss: 0.5447 \n",
            "[11/16] class_loss: 2.0112 s_domain_loss: 0.8998 t_domain_loss: 0.5445 \n",
            "[12/16] class_loss: 1.8944 s_domain_loss: 0.8903 t_domain_loss: 0.5445 \n",
            "[13/16] class_loss: 1.9408 s_domain_loss: 0.9001 t_domain_loss: 0.5417 \n",
            "[14/16] class_loss: 1.9211 s_domain_loss: 0.8988 t_domain_loss: 0.5481 \n",
            "[15/16] class_loss: 1.8734 s_domain_loss: 0.8920 t_domain_loss: 0.5540 \n",
            "[16/16] class_loss: 1.7880 s_domain_loss: 0.8878 t_domain_loss: 0.5519 \n",
            "Accuracy on  photo during epoch 1 is 0.26766467065868266 loss is 1.7761346101760864\n",
            "Accuracy on  artPainting during epoch 1 is 0.18359375 loss is 1.9201089143753052\n",
            "[1/16] class_loss: 1.8784 s_domain_loss: 0.8936 t_domain_loss: 0.5391 \n",
            "[2/16] class_loss: 1.9005 s_domain_loss: 0.8848 t_domain_loss: 0.5402 \n",
            "[3/16] class_loss: 1.8319 s_domain_loss: 0.8789 t_domain_loss: 0.5551 \n",
            "[4/16] class_loss: 1.8152 s_domain_loss: 0.8825 t_domain_loss: 0.5534 \n",
            "[5/16] class_loss: 1.8498 s_domain_loss: 0.8846 t_domain_loss: 0.5529 \n",
            "[6/16] class_loss: 1.8392 s_domain_loss: 0.8744 t_domain_loss: 0.5548 \n",
            "[7/16] class_loss: 1.8138 s_domain_loss: 0.8751 t_domain_loss: 0.5599 \n",
            "[8/16] class_loss: 1.8564 s_domain_loss: 0.8736 t_domain_loss: 0.5644 \n",
            "[9/16] class_loss: 1.7541 s_domain_loss: 0.8675 t_domain_loss: 0.5634 \n",
            "[10/16] class_loss: 1.8182 s_domain_loss: 0.8590 t_domain_loss: 0.5630 \n",
            "[11/16] class_loss: 1.7264 s_domain_loss: 0.8753 t_domain_loss: 0.5620 \n",
            "[12/16] class_loss: 1.7552 s_domain_loss: 0.8626 t_domain_loss: 0.5624 \n",
            "[13/16] class_loss: 1.8516 s_domain_loss: 0.8607 t_domain_loss: 0.5603 \n",
            "[14/16] class_loss: 1.9980 s_domain_loss: 0.8932 t_domain_loss: 0.5666 \n",
            "[15/16] class_loss: 1.7662 s_domain_loss: 0.8528 t_domain_loss: 0.5720 \n",
            "[16/16] class_loss: 1.8697 s_domain_loss: 0.8493 t_domain_loss: 0.5701 \n",
            "Accuracy on  photo during epoch 2 is 0.3904191616766467 loss is 1.610486626625061\n",
            "Accuracy on  artPainting during epoch 2 is 0.19140625 loss is 1.936487078666687\n",
            "[1/16] class_loss: 1.7352 s_domain_loss: 0.8480 t_domain_loss: 0.5571 \n",
            "[2/16] class_loss: 1.7692 s_domain_loss: 0.8451 t_domain_loss: 0.5579 \n",
            "[3/16] class_loss: 1.7102 s_domain_loss: 0.8555 t_domain_loss: 0.5728 \n",
            "[4/16] class_loss: 1.7516 s_domain_loss: 0.8471 t_domain_loss: 0.5710 \n",
            "[5/16] class_loss: 1.6338 s_domain_loss: 0.8475 t_domain_loss: 0.5703 \n",
            "[6/16] class_loss: 1.6623 s_domain_loss: 0.8384 t_domain_loss: 0.5727 \n",
            "[7/16] class_loss: 1.7603 s_domain_loss: 0.8509 t_domain_loss: 0.5780 \n",
            "[8/16] class_loss: 1.7575 s_domain_loss: 0.8444 t_domain_loss: 0.5820 \n",
            "[9/16] class_loss: 1.7227 s_domain_loss: 0.8422 t_domain_loss: 0.5806 \n",
            "[10/16] class_loss: 1.6756 s_domain_loss: 0.8449 t_domain_loss: 0.5805 \n",
            "[11/16] class_loss: 1.7309 s_domain_loss: 0.8466 t_domain_loss: 0.5790 \n",
            "[12/16] class_loss: 1.7656 s_domain_loss: 0.8363 t_domain_loss: 0.5796 \n",
            "[13/16] class_loss: 1.6626 s_domain_loss: 0.8406 t_domain_loss: 0.5783 \n",
            "[14/16] class_loss: 1.9407 s_domain_loss: 0.8361 t_domain_loss: 0.5842 \n",
            "[15/16] class_loss: 1.6684 s_domain_loss: 0.8294 t_domain_loss: 0.5892 \n",
            "[16/16] class_loss: 1.7113 s_domain_loss: 0.8320 t_domain_loss: 0.5874 \n",
            "Accuracy on  photo during epoch 3 is 0.47005988023952094 loss is 1.8777552843093872\n",
            "Accuracy on  artPainting during epoch 3 is 0.2041015625 loss is 1.947076439857483\n",
            "[1/16] class_loss: 1.6250 s_domain_loss: 0.8358 t_domain_loss: 0.5743 \n",
            "[2/16] class_loss: 1.6646 s_domain_loss: 0.8317 t_domain_loss: 0.5747 \n",
            "[3/16] class_loss: 1.6409 s_domain_loss: 0.8320 t_domain_loss: 0.5896 \n",
            "[4/16] class_loss: 1.7036 s_domain_loss: 0.8190 t_domain_loss: 0.5877 \n",
            "[5/16] class_loss: 1.5624 s_domain_loss: 0.8244 t_domain_loss: 0.5870 \n",
            "[6/16] class_loss: 1.6518 s_domain_loss: 0.8165 t_domain_loss: 0.5896 \n",
            "[7/16] class_loss: 1.6424 s_domain_loss: 0.8188 t_domain_loss: 0.5950 \n",
            "[8/16] class_loss: 1.6014 s_domain_loss: 0.8070 t_domain_loss: 0.5985 \n",
            "[9/16] class_loss: 1.6382 s_domain_loss: 0.8097 t_domain_loss: 0.5969 \n",
            "[10/16] class_loss: 1.6114 s_domain_loss: 0.8169 t_domain_loss: 0.5969 \n",
            "[11/16] class_loss: 1.5858 s_domain_loss: 0.8049 t_domain_loss: 0.5948 \n",
            "[12/16] class_loss: 1.5567 s_domain_loss: 0.8064 t_domain_loss: 0.5956 \n",
            "[13/16] class_loss: 1.5632 s_domain_loss: 0.8016 t_domain_loss: 0.5949 \n",
            "[14/16] class_loss: 1.3873 s_domain_loss: 0.8247 t_domain_loss: 0.6007 \n",
            "[15/16] class_loss: 1.5403 s_domain_loss: 0.8042 t_domain_loss: 0.6051 \n",
            "[16/16] class_loss: 1.6163 s_domain_loss: 0.8002 t_domain_loss: 0.6034 \n",
            "Accuracy on  photo during epoch 4 is 0.5341317365269461 loss is 1.2184950113296509\n",
            "Accuracy on  artPainting during epoch 4 is 0.220703125 loss is 1.9610179662704468\n",
            "[1/16] class_loss: 1.5794 s_domain_loss: 0.8046 t_domain_loss: 0.5903 \n",
            "[2/16] class_loss: 1.5207 s_domain_loss: 0.8059 t_domain_loss: 0.5902 \n",
            "[3/16] class_loss: 1.4591 s_domain_loss: 0.7958 t_domain_loss: 0.6051 \n",
            "[4/16] class_loss: 1.5453 s_domain_loss: 0.7917 t_domain_loss: 0.6032 \n",
            "[5/16] class_loss: 1.5521 s_domain_loss: 0.7992 t_domain_loss: 0.6024 \n",
            "[6/16] class_loss: 1.4891 s_domain_loss: 0.7998 t_domain_loss: 0.6050 \n",
            "[7/16] class_loss: 1.5917 s_domain_loss: 0.7939 t_domain_loss: 0.6104 \n",
            "[8/16] class_loss: 1.5000 s_domain_loss: 0.7849 t_domain_loss: 0.6134 \n",
            "[9/16] class_loss: 1.5226 s_domain_loss: 0.7907 t_domain_loss: 0.6117 \n",
            "[10/16] class_loss: 1.4658 s_domain_loss: 0.7859 t_domain_loss: 0.6117 \n",
            "[11/16] class_loss: 1.4294 s_domain_loss: 0.7886 t_domain_loss: 0.6093 \n",
            "[12/16] class_loss: 1.5395 s_domain_loss: 0.7908 t_domain_loss: 0.6101 \n",
            "[13/16] class_loss: 1.5304 s_domain_loss: 0.7825 t_domain_loss: 0.6099 \n",
            "[14/16] class_loss: 1.4046 s_domain_loss: 0.8168 t_domain_loss: 0.6156 \n",
            "[15/16] class_loss: 1.5265 s_domain_loss: 0.7857 t_domain_loss: 0.6195 \n",
            "[16/16] class_loss: 1.4266 s_domain_loss: 0.7768 t_domain_loss: 0.6179 \n",
            "Accuracy on  photo during epoch 5 is 0.5724550898203593 loss is 1.3596082925796509\n",
            "Accuracy on  artPainting during epoch 5 is 0.2294921875 loss is 1.9729923009872437\n",
            "[1/16] class_loss: 1.4883 s_domain_loss: 0.7772 t_domain_loss: 0.6050 \n",
            "[2/16] class_loss: 1.4842 s_domain_loss: 0.7811 t_domain_loss: 0.6043 \n",
            "[3/16] class_loss: 1.4765 s_domain_loss: 0.7767 t_domain_loss: 0.6190 \n",
            "[4/16] class_loss: 1.4113 s_domain_loss: 0.7764 t_domain_loss: 0.6172 \n",
            "[5/16] class_loss: 1.3932 s_domain_loss: 0.7719 t_domain_loss: 0.6165 \n",
            "[6/16] class_loss: 1.4222 s_domain_loss: 0.7777 t_domain_loss: 0.6191 \n",
            "[7/16] class_loss: 1.4105 s_domain_loss: 0.7761 t_domain_loss: 0.6244 \n",
            "[8/16] class_loss: 1.3824 s_domain_loss: 0.7692 t_domain_loss: 0.6268 \n",
            "[9/16] class_loss: 1.4467 s_domain_loss: 0.7661 t_domain_loss: 0.6251 \n",
            "[10/16] class_loss: 1.3746 s_domain_loss: 0.7688 t_domain_loss: 0.6250 \n",
            "[11/16] class_loss: 1.3706 s_domain_loss: 0.7587 t_domain_loss: 0.6223 \n",
            "[12/16] class_loss: 1.3373 s_domain_loss: 0.7634 t_domain_loss: 0.6231 \n",
            "[13/16] class_loss: 1.4135 s_domain_loss: 0.7647 t_domain_loss: 0.6234 \n",
            "[14/16] class_loss: 1.6230 s_domain_loss: 0.8069 t_domain_loss: 0.6289 \n",
            "[15/16] class_loss: 1.3086 s_domain_loss: 0.7626 t_domain_loss: 0.6324 \n",
            "[16/16] class_loss: 1.3347 s_domain_loss: 0.7561 t_domain_loss: 0.6309 \n",
            "Accuracy on  photo during epoch 6 is 0.6203592814371257 loss is 1.7217117547988892\n",
            "Accuracy on  artPainting during epoch 6 is 0.24267578125 loss is 1.9890121221542358\n",
            "[1/16] class_loss: 1.3603 s_domain_loss: 0.7642 t_domain_loss: 0.6181 \n",
            "[2/16] class_loss: 1.3686 s_domain_loss: 0.7524 t_domain_loss: 0.6169 \n",
            "[3/16] class_loss: 1.3571 s_domain_loss: 0.7588 t_domain_loss: 0.6314 \n",
            "[4/16] class_loss: 1.2958 s_domain_loss: 0.7588 t_domain_loss: 0.6295 \n",
            "[5/16] class_loss: 1.3011 s_domain_loss: 0.7537 t_domain_loss: 0.6289 \n",
            "[6/16] class_loss: 1.3802 s_domain_loss: 0.7547 t_domain_loss: 0.6314 \n",
            "[7/16] class_loss: 1.3609 s_domain_loss: 0.7490 t_domain_loss: 0.6366 \n",
            "[8/16] class_loss: 1.2966 s_domain_loss: 0.7502 t_domain_loss: 0.6384 \n",
            "[9/16] class_loss: 1.3043 s_domain_loss: 0.7480 t_domain_loss: 0.6368 \n",
            "[10/16] class_loss: 1.3280 s_domain_loss: 0.7597 t_domain_loss: 0.6364 \n",
            "[11/16] class_loss: 1.3040 s_domain_loss: 0.7445 t_domain_loss: 0.6335 \n",
            "[12/16] class_loss: 1.3225 s_domain_loss: 0.7483 t_domain_loss: 0.6343 \n",
            "[13/16] class_loss: 1.2877 s_domain_loss: 0.7445 t_domain_loss: 0.6351 \n",
            "[14/16] class_loss: 1.4045 s_domain_loss: 0.7775 t_domain_loss: 0.6404 \n",
            "[15/16] class_loss: 1.2784 s_domain_loss: 0.7425 t_domain_loss: 0.6436 \n",
            "[16/16] class_loss: 1.4028 s_domain_loss: 0.7417 t_domain_loss: 0.6421 \n",
            "Accuracy on  photo during epoch 7 is 0.6622754491017964 loss is 1.3455463647842407\n",
            "Accuracy on  artPainting during epoch 7 is 0.2548828125 loss is 2.003380537033081\n",
            "[1/16] class_loss: 1.2557 s_domain_loss: 0.7416 t_domain_loss: 0.6295 \n",
            "[2/16] class_loss: 1.1827 s_domain_loss: 0.7382 t_domain_loss: 0.6279 \n",
            "[3/16] class_loss: 1.2204 s_domain_loss: 0.7354 t_domain_loss: 0.6421 \n",
            "[4/16] class_loss: 1.2246 s_domain_loss: 0.7329 t_domain_loss: 0.6402 \n",
            "[5/16] class_loss: 1.3045 s_domain_loss: 0.7459 t_domain_loss: 0.6398 \n",
            "[6/16] class_loss: 1.2226 s_domain_loss: 0.7370 t_domain_loss: 0.6420 \n",
            "[7/16] class_loss: 1.2514 s_domain_loss: 0.7389 t_domain_loss: 0.6473 \n",
            "[8/16] class_loss: 1.2814 s_domain_loss: 0.7380 t_domain_loss: 0.6485 \n",
            "[9/16] class_loss: 1.1902 s_domain_loss: 0.7378 t_domain_loss: 0.6471 \n",
            "[10/16] class_loss: 1.1918 s_domain_loss: 0.7336 t_domain_loss: 0.6464 \n",
            "[11/16] class_loss: 1.2058 s_domain_loss: 0.7359 t_domain_loss: 0.6432 \n",
            "[12/16] class_loss: 1.2933 s_domain_loss: 0.7326 t_domain_loss: 0.6441 \n",
            "[13/16] class_loss: 1.2002 s_domain_loss: 0.7275 t_domain_loss: 0.6454 \n",
            "[14/16] class_loss: 1.0259 s_domain_loss: 0.7686 t_domain_loss: 0.6503 \n",
            "[15/16] class_loss: 1.2096 s_domain_loss: 0.7261 t_domain_loss: 0.6534 \n",
            "[16/16] class_loss: 1.1982 s_domain_loss: 0.7299 t_domain_loss: 0.6517 \n",
            "Accuracy on  photo during epoch 8 is 0.704191616766467 loss is 1.3968156576156616\n",
            "Accuracy on  artPainting during epoch 8 is 0.271484375 loss is 2.0266494750976562\n",
            "[1/16] class_loss: 1.1200 s_domain_loss: 0.7262 t_domain_loss: 0.6392 \n",
            "[2/16] class_loss: 1.2602 s_domain_loss: 0.7293 t_domain_loss: 0.6373 \n",
            "[3/16] class_loss: 1.1337 s_domain_loss: 0.7225 t_domain_loss: 0.6510 \n",
            "[4/16] class_loss: 1.1886 s_domain_loss: 0.7295 t_domain_loss: 0.6491 \n",
            "[5/16] class_loss: 1.1959 s_domain_loss: 0.7276 t_domain_loss: 0.6489 \n",
            "[6/16] class_loss: 1.1814 s_domain_loss: 0.7157 t_domain_loss: 0.6509 \n",
            "[7/16] class_loss: 1.1575 s_domain_loss: 0.7264 t_domain_loss: 0.6560 \n",
            "[8/16] class_loss: 1.2358 s_domain_loss: 0.7249 t_domain_loss: 0.6567 \n",
            "[9/16] class_loss: 1.1607 s_domain_loss: 0.7125 t_domain_loss: 0.6556 \n",
            "[10/16] class_loss: 1.1798 s_domain_loss: 0.7252 t_domain_loss: 0.6546 \n",
            "[11/16] class_loss: 1.0724 s_domain_loss: 0.7125 t_domain_loss: 0.6510 \n",
            "[12/16] class_loss: 1.1437 s_domain_loss: 0.7258 t_domain_loss: 0.6520 \n",
            "[13/16] class_loss: 1.1062 s_domain_loss: 0.7155 t_domain_loss: 0.6538 \n",
            "[14/16] class_loss: 1.1643 s_domain_loss: 0.7245 t_domain_loss: 0.6583 \n",
            "[15/16] class_loss: 1.1104 s_domain_loss: 0.7142 t_domain_loss: 0.6613 \n",
            "[16/16] class_loss: 1.1729 s_domain_loss: 0.7093 t_domain_loss: 0.6593 \n",
            "Accuracy on  photo during epoch 9 is 0.7461077844311377 loss is 1.1787766218185425\n",
            "Accuracy on  artPainting during epoch 9 is 0.28662109375 loss is 2.054417610168457\n",
            "[1/16] class_loss: 1.1154 s_domain_loss: 0.7212 t_domain_loss: 0.6472 \n",
            "[2/16] class_loss: 1.0792 s_domain_loss: 0.7038 t_domain_loss: 0.6448 \n",
            "[3/16] class_loss: 1.0730 s_domain_loss: 0.7164 t_domain_loss: 0.6583 \n",
            "[4/16] class_loss: 1.0092 s_domain_loss: 0.7117 t_domain_loss: 0.6563 \n",
            "[5/16] class_loss: 1.0242 s_domain_loss: 0.7089 t_domain_loss: 0.6564 \n",
            "[6/16] class_loss: 1.0310 s_domain_loss: 0.7115 t_domain_loss: 0.6581 \n",
            "[7/16] class_loss: 1.0184 s_domain_loss: 0.7129 t_domain_loss: 0.6629 \n",
            "[8/16] class_loss: 1.1049 s_domain_loss: 0.7007 t_domain_loss: 0.6632 \n",
            "[9/16] class_loss: 1.1272 s_domain_loss: 0.7079 t_domain_loss: 0.6624 \n",
            "[10/16] class_loss: 1.0635 s_domain_loss: 0.7114 t_domain_loss: 0.6610 \n",
            "[11/16] class_loss: 1.0778 s_domain_loss: 0.7170 t_domain_loss: 0.6573 \n",
            "[12/16] class_loss: 1.0935 s_domain_loss: 0.7184 t_domain_loss: 0.6586 \n",
            "[13/16] class_loss: 1.0421 s_domain_loss: 0.7025 t_domain_loss: 0.6605 \n",
            "[14/16] class_loss: 0.7836 s_domain_loss: 0.7434 t_domain_loss: 0.6645 \n",
            "[15/16] class_loss: 1.0090 s_domain_loss: 0.7083 t_domain_loss: 0.6675 \n",
            "[16/16] class_loss: 1.0837 s_domain_loss: 0.7059 t_domain_loss: 0.6655 \n",
            "Accuracy on  photo during epoch 10 is 0.7718562874251497 loss is 1.2729816436767578\n",
            "Accuracy on  artPainting during epoch 10 is 0.30224609375 loss is 2.087313413619995\n",
            "[1/16] class_loss: 1.0045 s_domain_loss: 0.6978 t_domain_loss: 0.6536 \n",
            "[2/16] class_loss: 1.0013 s_domain_loss: 0.6977 t_domain_loss: 0.6509 \n",
            "[3/16] class_loss: 1.1220 s_domain_loss: 0.7049 t_domain_loss: 0.6642 \n",
            "[4/16] class_loss: 0.9606 s_domain_loss: 0.7086 t_domain_loss: 0.6621 \n",
            "[5/16] class_loss: 0.9266 s_domain_loss: 0.6999 t_domain_loss: 0.6625 \n",
            "[6/16] class_loss: 1.0040 s_domain_loss: 0.7049 t_domain_loss: 0.6639 \n",
            "[7/16] class_loss: 1.0244 s_domain_loss: 0.6988 t_domain_loss: 0.6686 \n",
            "[8/16] class_loss: 1.0181 s_domain_loss: 0.7019 t_domain_loss: 0.6686 \n",
            "[9/16] class_loss: 0.9729 s_domain_loss: 0.7062 t_domain_loss: 0.6680 \n",
            "[10/16] class_loss: 1.0155 s_domain_loss: 0.7089 t_domain_loss: 0.6663 \n",
            "[11/16] class_loss: 0.9531 s_domain_loss: 0.6977 t_domain_loss: 0.6624 \n",
            "[12/16] class_loss: 1.0519 s_domain_loss: 0.6964 t_domain_loss: 0.6638 \n",
            "[13/16] class_loss: 0.8889 s_domain_loss: 0.6954 t_domain_loss: 0.6660 \n",
            "[14/16] class_loss: 1.0719 s_domain_loss: 0.7026 t_domain_loss: 0.6698 \n",
            "[15/16] class_loss: 0.9397 s_domain_loss: 0.6892 t_domain_loss: 0.6726 \n",
            "[16/16] class_loss: 1.0093 s_domain_loss: 0.6987 t_domain_loss: 0.6706 \n",
            "Accuracy on  photo during epoch 11 is 0.7868263473053893 loss is 1.0280526876449585\n",
            "Accuracy on  artPainting during epoch 11 is 0.322265625 loss is 2.1220340728759766\n",
            "[1/16] class_loss: 1.0112 s_domain_loss: 0.6936 t_domain_loss: 0.6589 \n",
            "[2/16] class_loss: 0.9587 s_domain_loss: 0.6935 t_domain_loss: 0.6558 \n",
            "[3/16] class_loss: 0.9144 s_domain_loss: 0.6892 t_domain_loss: 0.6690 \n",
            "[4/16] class_loss: 0.8227 s_domain_loss: 0.6825 t_domain_loss: 0.6669 \n",
            "[5/16] class_loss: 0.9380 s_domain_loss: 0.6955 t_domain_loss: 0.6673 \n",
            "[6/16] class_loss: 0.9358 s_domain_loss: 0.7029 t_domain_loss: 0.6684 \n",
            "[7/16] class_loss: 0.9296 s_domain_loss: 0.6881 t_domain_loss: 0.6731 \n",
            "[8/16] class_loss: 0.8492 s_domain_loss: 0.6918 t_domain_loss: 0.6726 \n",
            "[9/16] class_loss: 0.8874 s_domain_loss: 0.6941 t_domain_loss: 0.6723 \n",
            "[10/16] class_loss: 0.8785 s_domain_loss: 0.6926 t_domain_loss: 0.6702 \n",
            "[11/16] class_loss: 1.0045 s_domain_loss: 0.7015 t_domain_loss: 0.6660 \n",
            "[12/16] class_loss: 0.8727 s_domain_loss: 0.6876 t_domain_loss: 0.6677 \n",
            "[13/16] class_loss: 0.8969 s_domain_loss: 0.6917 t_domain_loss: 0.6701 \n",
            "[14/16] class_loss: 0.9138 s_domain_loss: 0.7061 t_domain_loss: 0.6736 \n",
            "[15/16] class_loss: 0.9248 s_domain_loss: 0.6886 t_domain_loss: 0.6762 \n",
            "[16/16] class_loss: 0.8499 s_domain_loss: 0.6793 t_domain_loss: 0.6744 \n",
            "Accuracy on  photo during epoch 12 is 0.8053892215568862 loss is 0.6006473302841187\n",
            "Accuracy on  artPainting during epoch 12 is 0.3369140625 loss is 2.157217264175415\n",
            "[1/16] class_loss: 0.7979 s_domain_loss: 0.6858 t_domain_loss: 0.6628 \n",
            "[2/16] class_loss: 1.0024 s_domain_loss: 0.6922 t_domain_loss: 0.6595 \n",
            "[3/16] class_loss: 0.8811 s_domain_loss: 0.6903 t_domain_loss: 0.6726 \n",
            "[4/16] class_loss: 0.9189 s_domain_loss: 0.6891 t_domain_loss: 0.6704 \n",
            "[5/16] class_loss: 0.8117 s_domain_loss: 0.6842 t_domain_loss: 0.6710 \n",
            "[6/16] class_loss: 0.8525 s_domain_loss: 0.6901 t_domain_loss: 0.6717 \n",
            "[7/16] class_loss: 0.8817 s_domain_loss: 0.6814 t_domain_loss: 0.6763 \n",
            "[8/16] class_loss: 0.8131 s_domain_loss: 0.6792 t_domain_loss: 0.6755 \n",
            "[9/16] class_loss: 0.8402 s_domain_loss: 0.6834 t_domain_loss: 0.6755 \n",
            "[10/16] class_loss: 0.7915 s_domain_loss: 0.6883 t_domain_loss: 0.6730 \n",
            "[11/16] class_loss: 0.9129 s_domain_loss: 0.6912 t_domain_loss: 0.6685 \n",
            "[12/16] class_loss: 0.9185 s_domain_loss: 0.6938 t_domain_loss: 0.6707 \n",
            "[13/16] class_loss: 0.7829 s_domain_loss: 0.6814 t_domain_loss: 0.6730 \n",
            "[14/16] class_loss: 0.7300 s_domain_loss: 0.7037 t_domain_loss: 0.6765 \n",
            "[15/16] class_loss: 0.8030 s_domain_loss: 0.6697 t_domain_loss: 0.6787 \n",
            "[16/16] class_loss: 0.8898 s_domain_loss: 0.6894 t_domain_loss: 0.6774 \n",
            "Accuracy on  photo during epoch 13 is 0.8197604790419162 loss is 0.5845584273338318\n",
            "Accuracy on  artPainting during epoch 13 is 0.34912109375 loss is 2.2049145698547363\n",
            "[1/16] class_loss: 0.8823 s_domain_loss: 0.6808 t_domain_loss: 0.6658 \n",
            "[2/16] class_loss: 0.8248 s_domain_loss: 0.6805 t_domain_loss: 0.6623 \n",
            "[3/16] class_loss: 0.8637 s_domain_loss: 0.6821 t_domain_loss: 0.6752 \n",
            "[4/16] class_loss: 0.8937 s_domain_loss: 0.6872 t_domain_loss: 0.6731 \n",
            "[5/16] class_loss: 0.7778 s_domain_loss: 0.6832 t_domain_loss: 0.6737 \n",
            "[6/16] class_loss: 0.7677 s_domain_loss: 0.6812 t_domain_loss: 0.6741 \n",
            "[7/16] class_loss: 0.8788 s_domain_loss: 0.6917 t_domain_loss: 0.6787 \n",
            "[8/16] class_loss: 0.8381 s_domain_loss: 0.6838 t_domain_loss: 0.6776 \n",
            "[9/16] class_loss: 0.7638 s_domain_loss: 0.6767 t_domain_loss: 0.6780 \n",
            "[10/16] class_loss: 0.7644 s_domain_loss: 0.6757 t_domain_loss: 0.6752 \n",
            "[11/16] class_loss: 0.7109 s_domain_loss: 0.6695 t_domain_loss: 0.6704 \n",
            "[12/16] class_loss: 0.8216 s_domain_loss: 0.6789 t_domain_loss: 0.6730 \n",
            "[13/16] class_loss: 0.6808 s_domain_loss: 0.6754 t_domain_loss: 0.6753 \n",
            "[14/16] class_loss: 0.9439 s_domain_loss: 0.6970 t_domain_loss: 0.6786 \n",
            "[15/16] class_loss: 0.8014 s_domain_loss: 0.6693 t_domain_loss: 0.6807 \n",
            "[16/16] class_loss: 0.7757 s_domain_loss: 0.6791 t_domain_loss: 0.6795 \n",
            "Accuracy on  photo during epoch 14 is 0.832934131736527 loss is 0.705427885055542\n",
            "Accuracy on  artPainting during epoch 14 is 0.3583984375 loss is 2.251713514328003\n",
            "[1/16] class_loss: 0.7656 s_domain_loss: 0.6716 t_domain_loss: 0.6680 \n",
            "[2/16] class_loss: 0.7719 s_domain_loss: 0.6854 t_domain_loss: 0.6643 \n",
            "[3/16] class_loss: 0.8024 s_domain_loss: 0.6711 t_domain_loss: 0.6771 \n",
            "[4/16] class_loss: 0.8251 s_domain_loss: 0.6750 t_domain_loss: 0.6749 \n",
            "[5/16] class_loss: 0.7870 s_domain_loss: 0.6730 t_domain_loss: 0.6756 \n",
            "[6/16] class_loss: 0.7862 s_domain_loss: 0.6861 t_domain_loss: 0.6757 \n",
            "[7/16] class_loss: 0.6815 s_domain_loss: 0.6764 t_domain_loss: 0.6802 \n",
            "[8/16] class_loss: 0.6617 s_domain_loss: 0.6712 t_domain_loss: 0.6789 \n",
            "[9/16] class_loss: 0.7033 s_domain_loss: 0.6720 t_domain_loss: 0.6796 \n",
            "[10/16] class_loss: 0.7865 s_domain_loss: 0.6737 t_domain_loss: 0.6764 \n",
            "[11/16] class_loss: 0.7257 s_domain_loss: 0.6806 t_domain_loss: 0.6714 \n",
            "[12/16] class_loss: 0.7065 s_domain_loss: 0.6675 t_domain_loss: 0.6744 \n",
            "[13/16] class_loss: 0.7560 s_domain_loss: 0.6723 t_domain_loss: 0.6765 \n",
            "[14/16] class_loss: 0.6269 s_domain_loss: 0.6961 t_domain_loss: 0.6799 \n",
            "[15/16] class_loss: 0.8039 s_domain_loss: 0.6734 t_domain_loss: 0.6816 \n",
            "[16/16] class_loss: 0.7410 s_domain_loss: 0.6807 t_domain_loss: 0.6807 \n",
            "Accuracy on  photo during epoch 15 is 0.8413173652694611 loss is 0.9625234603881836\n",
            "Accuracy on  artPainting during epoch 15 is 0.3681640625 loss is 2.311173439025879\n",
            "[1/16] class_loss: 0.7708 s_domain_loss: 0.6747 t_domain_loss: 0.6693 \n",
            "[2/16] class_loss: 0.7895 s_domain_loss: 0.6844 t_domain_loss: 0.6655 \n",
            "[3/16] class_loss: 0.7482 s_domain_loss: 0.6736 t_domain_loss: 0.6781 \n",
            "[4/16] class_loss: 0.7382 s_domain_loss: 0.6627 t_domain_loss: 0.6758 \n",
            "[5/16] class_loss: 0.7808 s_domain_loss: 0.6756 t_domain_loss: 0.6767 \n",
            "[6/16] class_loss: 0.7471 s_domain_loss: 0.6783 t_domain_loss: 0.6765 \n",
            "[7/16] class_loss: 0.6197 s_domain_loss: 0.6579 t_domain_loss: 0.6810 \n",
            "[8/16] class_loss: 0.8153 s_domain_loss: 0.6751 t_domain_loss: 0.6795 \n",
            "[9/16] class_loss: 0.6496 s_domain_loss: 0.6664 t_domain_loss: 0.6806 \n",
            "[10/16] class_loss: 0.6407 s_domain_loss: 0.6652 t_domain_loss: 0.6770 \n",
            "[11/16] class_loss: 0.7097 s_domain_loss: 0.6674 t_domain_loss: 0.6720 \n",
            "[12/16] class_loss: 0.6674 s_domain_loss: 0.6677 t_domain_loss: 0.6751 \n",
            "[13/16] class_loss: 0.6451 s_domain_loss: 0.6697 t_domain_loss: 0.6772 \n",
            "[14/16] class_loss: 0.2905 s_domain_loss: 0.7147 t_domain_loss: 0.6806 \n",
            "[15/16] class_loss: 0.7469 s_domain_loss: 0.6732 t_domain_loss: 0.6821 \n",
            "[16/16] class_loss: 0.6550 s_domain_loss: 0.6628 t_domain_loss: 0.6812 \n",
            "Accuracy on  photo during epoch 16 is 0.8520958083832335 loss is 0.6385035514831543\n",
            "Accuracy on  artPainting during epoch 16 is 0.37109375 loss is 2.3789587020874023\n",
            "[1/16] class_loss: 0.6359 s_domain_loss: 0.6704 t_domain_loss: 0.6701 \n",
            "[2/16] class_loss: 0.7666 s_domain_loss: 0.6723 t_domain_loss: 0.6662 \n",
            "[3/16] class_loss: 0.6349 s_domain_loss: 0.6654 t_domain_loss: 0.6786 \n",
            "[4/16] class_loss: 0.6607 s_domain_loss: 0.6671 t_domain_loss: 0.6762 \n",
            "[5/16] class_loss: 0.6928 s_domain_loss: 0.6541 t_domain_loss: 0.6772 \n",
            "[6/16] class_loss: 0.6218 s_domain_loss: 0.6651 t_domain_loss: 0.6768 \n",
            "[7/16] class_loss: 0.7092 s_domain_loss: 0.6628 t_domain_loss: 0.6812 \n",
            "[8/16] class_loss: 0.6689 s_domain_loss: 0.6748 t_domain_loss: 0.6796 \n",
            "[9/16] class_loss: 0.7108 s_domain_loss: 0.6743 t_domain_loss: 0.6811 \n",
            "[10/16] class_loss: 0.7111 s_domain_loss: 0.6759 t_domain_loss: 0.6770 \n",
            "[11/16] class_loss: 0.5940 s_domain_loss: 0.6605 t_domain_loss: 0.6719 \n",
            "[12/16] class_loss: 0.5899 s_domain_loss: 0.6597 t_domain_loss: 0.6753 \n",
            "[13/16] class_loss: 0.6860 s_domain_loss: 0.6696 t_domain_loss: 0.6774 \n",
            "[14/16] class_loss: 0.7607 s_domain_loss: 0.6902 t_domain_loss: 0.6806 \n",
            "[15/16] class_loss: 0.6390 s_domain_loss: 0.6683 t_domain_loss: 0.6820 \n",
            "[16/16] class_loss: 0.6498 s_domain_loss: 0.6666 t_domain_loss: 0.6811 \n",
            "Accuracy on  photo during epoch 17 is 0.859880239520958 loss is 0.4482559859752655\n",
            "Accuracy on  artPainting during epoch 17 is 0.3779296875 loss is 2.44621205329895\n",
            "[1/16] class_loss: 0.6966 s_domain_loss: 0.6622 t_domain_loss: 0.6703 \n",
            "[2/16] class_loss: 0.5922 s_domain_loss: 0.6568 t_domain_loss: 0.6663 \n",
            "[3/16] class_loss: 0.6636 s_domain_loss: 0.6652 t_domain_loss: 0.6783 \n",
            "[4/16] class_loss: 0.7074 s_domain_loss: 0.6576 t_domain_loss: 0.6760 \n",
            "[5/16] class_loss: 0.6611 s_domain_loss: 0.6722 t_domain_loss: 0.6770 \n",
            "[6/16] class_loss: 0.5554 s_domain_loss: 0.6673 t_domain_loss: 0.6765 \n",
            "[7/16] class_loss: 0.5675 s_domain_loss: 0.6600 t_domain_loss: 0.6807 \n",
            "[8/16] class_loss: 0.6650 s_domain_loss: 0.6653 t_domain_loss: 0.6790 \n",
            "[9/16] class_loss: 0.7284 s_domain_loss: 0.6753 t_domain_loss: 0.6810 \n",
            "[10/16] class_loss: 0.6475 s_domain_loss: 0.6652 t_domain_loss: 0.6764 \n",
            "[11/16] class_loss: 0.5374 s_domain_loss: 0.6670 t_domain_loss: 0.6713 \n",
            "[12/16] class_loss: 0.5096 s_domain_loss: 0.6560 t_domain_loss: 0.6748 \n",
            "[13/16] class_loss: 0.6756 s_domain_loss: 0.6701 t_domain_loss: 0.6772 \n",
            "[14/16] class_loss: 0.8513 s_domain_loss: 0.6655 t_domain_loss: 0.6803 \n",
            "[15/16] class_loss: 0.5057 s_domain_loss: 0.6556 t_domain_loss: 0.6814 \n",
            "[16/16] class_loss: 0.6478 s_domain_loss: 0.6685 t_domain_loss: 0.6806 \n",
            "Accuracy on  photo during epoch 18 is 0.8694610778443114 loss is 0.6060343980789185\n",
            "Accuracy on  artPainting during epoch 18 is 0.37744140625 loss is 2.520625352859497\n",
            "[1/16] class_loss: 0.5790 s_domain_loss: 0.6581 t_domain_loss: 0.6700 \n",
            "[2/16] class_loss: 0.6444 s_domain_loss: 0.6588 t_domain_loss: 0.6659 \n",
            "[3/16] class_loss: 0.5544 s_domain_loss: 0.6620 t_domain_loss: 0.6777 \n",
            "[4/16] class_loss: 0.4489 s_domain_loss: 0.6494 t_domain_loss: 0.6755 \n",
            "[5/16] class_loss: 0.6490 s_domain_loss: 0.6677 t_domain_loss: 0.6766 \n",
            "[6/16] class_loss: 0.6164 s_domain_loss: 0.6653 t_domain_loss: 0.6760 \n",
            "[7/16] class_loss: 0.6744 s_domain_loss: 0.6657 t_domain_loss: 0.6800 \n",
            "[8/16] class_loss: 0.6415 s_domain_loss: 0.6699 t_domain_loss: 0.6784 \n",
            "[9/16] class_loss: 0.6070 s_domain_loss: 0.6578 t_domain_loss: 0.6807 \n",
            "[10/16] class_loss: 0.5943 s_domain_loss: 0.6597 t_domain_loss: 0.6758 \n",
            "[11/16] class_loss: 0.5814 s_domain_loss: 0.6641 t_domain_loss: 0.6708 \n",
            "[12/16] class_loss: 0.6196 s_domain_loss: 0.6720 t_domain_loss: 0.6744 \n",
            "[13/16] class_loss: 0.6275 s_domain_loss: 0.6612 t_domain_loss: 0.6770 \n",
            "[14/16] class_loss: 0.7152 s_domain_loss: 0.6756 t_domain_loss: 0.6801 \n",
            "[15/16] class_loss: 0.7190 s_domain_loss: 0.6742 t_domain_loss: 0.6811 \n",
            "[16/16] class_loss: 0.5488 s_domain_loss: 0.6618 t_domain_loss: 0.6804 \n",
            "Accuracy on  photo during epoch 19 is 0.8706586826347306 loss is 0.2807891070842743\n",
            "Accuracy on  artPainting during epoch 19 is 0.3779296875 loss is 2.5277602672576904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu1dmt7k_W1P",
        "colab_type": "code",
        "outputId": "99febd23-ab1e-4664-fb8c-38184c8d7c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LR"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1e-06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u01ZFqgWF4zG",
        "colab_type": "code",
        "outputId": "da06d9fd-eec2-4df9-a719-a2fcf8b1a233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alfa"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}