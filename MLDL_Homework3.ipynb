{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDL - Homework3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/Homework3-PACS/blob/master/MLDL_Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "#**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from numpy import random \n",
        "\n",
        "random.seed(33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "#**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "BATCH_SIZE = 128     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 20      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "alfa = 0.01\n",
        "LR = 1e-4          # The initial Learning Rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "#**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      #transforms.RandomCrop( 64 , padding =2) ,\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "# Define transforms for the test phase\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "#**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "outputId": "2b9c4488-a29a-4134-e05b-aa0622009138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# Clone github repository with data\n",
        "!git clone https://github.com/luciainnocenti/Homework3-PACS.git\n",
        "!mv 'Homework3-PACS' 'HW_PACS'\n",
        "\n",
        "from HW_PACS.dataset import PACS_Dataset \n",
        "\n",
        "rootPhoto = \"HW_PACS/PACS/photo\"\n",
        "photos = PACS_Dataset(root = rootPhoto, transform = train_transform)\n",
        "\n",
        "rootArt_painting = \"HW_PACS/PACS/art_painting\"\n",
        "art_painting = PACS_Dataset(root = rootArt_painting, transform = test_transform)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(photos)))\n",
        "print('Test Dataset: {}'.format(len(art_painting)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 10102, done.\u001b[K\n",
            "remote: Total 10102 (delta 0), reused 0 (delta 0), pack-reused 10102\u001b[K\n",
            "Receiving objects: 100% (10102/10102), 174.18 MiB | 29.97 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n",
            "Checking out files: 100% (9995/9995), done.\n",
            "Train Dataset: 1670\n",
            "Test Dataset: 2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "#**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "#**Model without DANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "##**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUjtXa22DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from HW_PACS.gradient_reversal_example import alexNetDA \n",
        "\n",
        "net = alexNetDA(num_classes = 7)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "##**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "# Choose parameters to optimize\n",
        "# To access a different set of parameters, you have to access submodules of AlexNet\n",
        "# (nn.Module objects, like AlexNet, implement the Composite Pattern)\n",
        "# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n",
        "# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n",
        "parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "# We use SGD with momentum\n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "#optimizer = optim.Adam(parameters_to_optimize, LR)\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "outputId": "2973ef57-0220-4bd2-a2ad-de465af35022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "running_corrects = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "# Iterate over the dataset\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  scheduler.step() \n",
        "  \n",
        "  for images, labels in  tqdm(photos_dataloader):\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(photos))\n",
        "  print(\"Accuracy on training set = \"  + str(accuracy))\n",
        "  running_corrects = 0\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            " 14%|█▍        | 2/14 [00:02<00:17,  1.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 2.1148531436920166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 10, Loss 1.4435231685638428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.36946107784431137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 20, Loss 0.9774367213249207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.6970059880239521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:07,  1.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 30, Loss 0.7604193091392517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 40, Loss 0.4694751799106598\n",
            "Accuracy on training set = 0.8311377245508982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 10/14 [00:05<00:01,  2.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 50, Loss 0.38208815455436707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.8784431137724551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 60, Loss 0.40540677309036255\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.32it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9005988023952096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2/14 [00:01<00:15,  1.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 70, Loss 0.3361206352710724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 80, Loss 0.2659076154232025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9149700598802395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 90, Loss 0.2513381242752075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9173652694610779\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:07,  1.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 100, Loss 0.21343590319156647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 110, Loss 0.2759970724582672\n",
            "Accuracy on training set = 0.9275449101796407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 10/14 [00:05<00:01,  2.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 120, Loss 0.19524644315242767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9413173652694611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 5/14 [00:03<00:08,  1.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 130, Loss 0.1941853165626526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9437125748502994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2/14 [00:02<00:17,  1.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 140, Loss 0.21364907920360565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 150, Loss 0.22004646062850952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.937125748502994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 160, Loss 0.1822589933872223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.948502994011976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:07,  1.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 170, Loss 0.19476532936096191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 180, Loss 0.1456691175699234\n",
            "Accuracy on training set = 0.9508982035928144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:03,  1.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 190, Loss 0.11495558172464371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9556886227544911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 200, Loss 0.1887865513563156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9532934131736527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2/14 [00:02<00:17,  1.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 210, Loss 0.13302458822727203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 12/14 [00:05<00:00,  2.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 220, Loss 0.08059795200824738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.29it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9526946107784431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 230, Loss 0.19394399225711823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9574850299401197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:08,  1.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 240, Loss 0.09139358997344971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 250, Loss 0.16974523663520813\n",
            "Accuracy on training set = 0.9580838323353293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:03,  1.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 260, Loss 0.12675343453884125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9580838323353293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 5/14 [00:03<00:08,  1.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 270, Loss 0.10453487187623978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9640718562874252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsHFI-GAJd69",
        "colab_type": "text"
      },
      "source": [
        "##**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3HV5pqJg1o",
        "colab_type": "code",
        "outputId": "2f5a881f-4b91-4d96-d6fd-4564c5d6b555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(art_painting_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(art_painting))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.453125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPzBRkB3iKWU",
        "colab_type": "code",
        "outputId": "6d2b8c45-6fce-4897-8578-b50e4cf80536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.220218181610107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NHDb2yBC7jX",
        "colab_type": "text"
      },
      "source": [
        "# Model with DANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9PNdrqJdkSO",
        "colab_type": "text"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC1hCskMXaTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = alexNetDA(num_classes = 7)\n",
        "net = net.to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NemzVoaidnQA",
        "colab_type": "text"
      },
      "source": [
        "## Loss, Optim and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbFj42qsER6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion_class = nn.CrossEntropyLoss() \n",
        "criterion_domain = nn.CrossEntropyLoss()\n",
        "\n",
        "parameters_to_optimize = net.parameters() \n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgONyH0xfN9W",
        "colab_type": "text"
      },
      "source": [
        "## Test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4arKipfR0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testFunction(datasetName, epoch):  \n",
        "  net = torch.load('model_epoch_' + str(epoch) + '.pt')\n",
        "  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "  if (datasetName == 'photo'):\n",
        "    dataLoader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "  elif( datasetName == 'artPainting'):\n",
        "    dataLoader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "  lenLoader = len(dataLoader)\n",
        "  iterator = iter(dataLoader)\n",
        "  totalLen = 0\n",
        "  running_corrects = 0\n",
        "  criterion = nn.CrossEntropyLoss() \n",
        "  for i in range(lenLoader):\n",
        "    t_img, t_label = next(iterator)\n",
        "\n",
        "    t_img = t_img.to(DEVICE)\n",
        "    t_label = t_label.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    classes_output = net(t_img)\n",
        "\n",
        "    loss = criterion(classes_output, t_label)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(classes_output.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == t_label.data).data.item()\n",
        "    totalLen += len(t_img)\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(totalLen)\n",
        "\n",
        "  print(f'Accuracy on  {datasetName}' f' during epoch {epoch}' f' is {accuracy}' f' loss is {loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW0rUNTbduSm",
        "colab_type": "text"
      },
      "source": [
        "## Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoZJAcaHEtYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "#art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "max_batches = max(len(photos_dataloader), len(art_painting_dataloader))\n",
        "min_batches = min(len(photos_dataloader), len(art_painting_dataloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4tSP1-uEPQt",
        "colab_type": "code",
        "outputId": "50c5e7be-b314-413c-d35d-3a97eea5e38e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "running_corrects = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "# Iterate over the dataset\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  scheduler.step() \n",
        "  iterPh = iter(photos_dataloader)\n",
        "  iterAP = iter(art_painting_dataloader)\n",
        "  for batch in range(max_batches):\n",
        "    net.train() # Sets module in training mode\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "    if( batch == min_batches):\n",
        "      iterPh = iter(photos_dataloader)\n",
        "    images_source, labels_source = next(iterPh)\n",
        "    labels_domain = torch.zeros(len(images_source), dtype=torch.long)\n",
        "    \n",
        "    # Bring data over the device of choice\n",
        "    images_source = images_source.to(DEVICE)\n",
        "    labels_source = labels_source.to(DEVICE)\n",
        "    labels_domain = labels_domain.to(DEVICE)\n",
        "\n",
        "  \n",
        "    # Get the output for classes and domains; class_pred, domain_pred\n",
        "    classes_output = net(images_source)\n",
        "    # Compute the loss on the source domain\n",
        "    loss_s_label = criterion_class(classes_output, labels_source)\n",
        "\n",
        "    domain_output = net(images_source, alfa)\n",
        "    # Compute the loss on the source domain\n",
        "    loss_s_domain = criterion_domain(domain_output, labels_domain)\n",
        "\n",
        "    # Get the output for targets\n",
        "    targets, _ = next(iterAP)\n",
        "    target_domain = torch.ones(len(targets), dtype=torch.long)\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    targets = targets.to(DEVICE)\n",
        "    target_domain = target_domain.to(DEVICE)\n",
        "\n",
        "    target_output = net(targets, alfa)\n",
        "\n",
        "    # Compute the loss on the source domain\n",
        "    loss_t_domain = criterion_domain(target_output,target_domain)\n",
        "\n",
        "    loss = loss_s_label + loss_s_domain + loss_t_domain\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "    print(f'[{batch+1}/{max_batches}] '\n",
        "          f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n",
        "          f't_domain_loss: {loss_t_domain.item():.4f} '\n",
        "          )  \n",
        "  torch.save(net, 'model_epoch_{0}.pt'.format(epoch))\n",
        "  testFunction('photo', epoch)\n",
        "  testFunction('artPainting', epoch)\n",
        "  "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/16] class_loss: 1.8094 s_domain_loss: 0.5647 t_domain_loss: 0.8890 \n",
            "[2/16] class_loss: 1.9195 s_domain_loss: 0.5704 t_domain_loss: 0.8728 \n",
            "[3/16] class_loss: 1.9845 s_domain_loss: 0.5858 t_domain_loss: 0.8663 \n",
            "[4/16] class_loss: 1.7855 s_domain_loss: 0.6130 t_domain_loss: 0.8223 \n",
            "[5/16] class_loss: 1.7782 s_domain_loss: 0.6305 t_domain_loss: 0.8063 \n",
            "[6/16] class_loss: 1.6556 s_domain_loss: 0.6680 t_domain_loss: 0.7700 \n",
            "[7/16] class_loss: 1.7188 s_domain_loss: 0.6935 t_domain_loss: 0.7398 \n",
            "[8/16] class_loss: 1.3688 s_domain_loss: 0.7160 t_domain_loss: 0.7185 \n",
            "[9/16] class_loss: 1.4695 s_domain_loss: 0.7437 t_domain_loss: 0.6835 \n",
            "[10/16] class_loss: 1.3398 s_domain_loss: 0.7589 t_domain_loss: 0.6617 \n",
            "[11/16] class_loss: 1.2121 s_domain_loss: 0.7829 t_domain_loss: 0.6489 \n",
            "[12/16] class_loss: 1.2303 s_domain_loss: 0.7834 t_domain_loss: 0.6538 \n",
            "[13/16] class_loss: 1.2330 s_domain_loss: 0.7910 t_domain_loss: 0.6392 \n",
            "[14/16] class_loss: 0.9629 s_domain_loss: 0.7986 t_domain_loss: 0.6404 \n",
            "[15/16] class_loss: 1.1805 s_domain_loss: 0.7663 t_domain_loss: 0.6528 \n",
            "[16/16] class_loss: 0.9944 s_domain_loss: 0.7516 t_domain_loss: 0.6645 \n",
            "Accuracy is: 0.518562874251497\n",
            "Accuracy on  photo during epoch 0 is 0.6982035928143713 loss is 0.6928246021270752\n",
            "Accuracy on  artPainting during epoch 0 is 0.31884765625 loss is 1.6199641227722168\n",
            "[1/16] class_loss: 0.9812 s_domain_loss: 0.7336 t_domain_loss: 0.6808 \n",
            "[2/16] class_loss: 1.0124 s_domain_loss: 0.7173 t_domain_loss: 0.6923 \n",
            "[3/16] class_loss: 0.9031 s_domain_loss: 0.6990 t_domain_loss: 0.7209 \n",
            "[4/16] class_loss: 0.9235 s_domain_loss: 0.6793 t_domain_loss: 0.7193 \n",
            "[5/16] class_loss: 0.8582 s_domain_loss: 0.6750 t_domain_loss: 0.7460 \n",
            "[6/16] class_loss: 0.7982 s_domain_loss: 0.6597 t_domain_loss: 0.7522 \n",
            "[7/16] class_loss: 0.7948 s_domain_loss: 0.6544 t_domain_loss: 0.7603 \n",
            "[8/16] class_loss: 0.7397 s_domain_loss: 0.6522 t_domain_loss: 0.7681 \n",
            "[9/16] class_loss: 0.9174 s_domain_loss: 0.6573 t_domain_loss: 0.7593 \n",
            "[10/16] class_loss: 0.7923 s_domain_loss: 0.6557 t_domain_loss: 0.7526 \n",
            "[11/16] class_loss: 0.6441 s_domain_loss: 0.6578 t_domain_loss: 0.7477 \n",
            "[12/16] class_loss: 0.7559 s_domain_loss: 0.6616 t_domain_loss: 0.7513 \n",
            "[13/16] class_loss: 0.6468 s_domain_loss: 0.6709 t_domain_loss: 0.7296 \n",
            "[14/16] class_loss: 0.5740 s_domain_loss: 0.7071 t_domain_loss: 0.7175 \n",
            "[15/16] class_loss: 0.5724 s_domain_loss: 0.6934 t_domain_loss: 0.7148 \n",
            "[16/16] class_loss: 0.5989 s_domain_loss: 0.6982 t_domain_loss: 0.7055 \n",
            "Accuracy is: 0.870059880239521\n",
            "Accuracy on  photo during epoch 1 is 0.8449101796407186 loss is 0.7942710518836975\n",
            "Accuracy on  artPainting during epoch 1 is 0.38623046875 loss is 2.2091739177703857\n",
            "[1/16] class_loss: 0.5985 s_domain_loss: 0.6994 t_domain_loss: 0.7031 \n",
            "[2/16] class_loss: 0.6614 s_domain_loss: 0.6979 t_domain_loss: 0.6946 \n",
            "[3/16] class_loss: 0.6122 s_domain_loss: 0.7016 t_domain_loss: 0.7021 \n",
            "[4/16] class_loss: 0.5080 s_domain_loss: 0.7019 t_domain_loss: 0.6837 \n",
            "[5/16] class_loss: 0.4036 s_domain_loss: 0.7036 t_domain_loss: 0.6965 \n",
            "[6/16] class_loss: 0.5467 s_domain_loss: 0.7115 t_domain_loss: 0.6937 \n",
            "[7/16] class_loss: 0.4636 s_domain_loss: 0.7031 t_domain_loss: 0.6960 \n",
            "[8/16] class_loss: 0.5557 s_domain_loss: 0.6985 t_domain_loss: 0.7011 \n",
            "[9/16] class_loss: 0.4662 s_domain_loss: 0.7024 t_domain_loss: 0.6958 \n",
            "[10/16] class_loss: 0.4614 s_domain_loss: 0.6944 t_domain_loss: 0.6961 \n",
            "[11/16] class_loss: 0.4465 s_domain_loss: 0.6950 t_domain_loss: 0.7004 \n",
            "[12/16] class_loss: 0.4729 s_domain_loss: 0.6944 t_domain_loss: 0.7141 \n",
            "[13/16] class_loss: 0.4814 s_domain_loss: 0.6917 t_domain_loss: 0.7047 \n",
            "[14/16] class_loss: 0.3859 s_domain_loss: 0.6868 t_domain_loss: 0.7043 \n",
            "[15/16] class_loss: 0.4130 s_domain_loss: 0.6745 t_domain_loss: 0.7130 \n",
            "[16/16] class_loss: 0.4139 s_domain_loss: 0.6896 t_domain_loss: 0.7120 \n",
            "Accuracy is: 0.9958083832335329\n",
            "Accuracy on  photo during epoch 2 is 0.9083832335329342 loss is 0.3608638346195221\n",
            "Accuracy on  artPainting during epoch 2 is 0.41064453125 loss is 2.915921449661255\n",
            "[1/16] class_loss: 0.3471 s_domain_loss: 0.6731 t_domain_loss: 0.7180 \n",
            "[2/16] class_loss: 0.4186 s_domain_loss: 0.6642 t_domain_loss: 0.7160 \n",
            "[3/16] class_loss: 0.3669 s_domain_loss: 0.6705 t_domain_loss: 0.7263 \n",
            "[4/16] class_loss: 0.3897 s_domain_loss: 0.6659 t_domain_loss: 0.7097 \n",
            "[5/16] class_loss: 0.4014 s_domain_loss: 0.6741 t_domain_loss: 0.7220 \n",
            "[6/16] class_loss: 0.3327 s_domain_loss: 0.6701 t_domain_loss: 0.7174 \n",
            "[7/16] class_loss: 0.3770 s_domain_loss: 0.6748 t_domain_loss: 0.7149 \n",
            "[8/16] class_loss: 0.3118 s_domain_loss: 0.6866 t_domain_loss: 0.7148 \n",
            "[9/16] class_loss: 0.3065 s_domain_loss: 0.6827 t_domain_loss: 0.7032 \n",
            "[10/16] class_loss: 0.3965 s_domain_loss: 0.6815 t_domain_loss: 0.6979 \n",
            "[11/16] class_loss: 0.4666 s_domain_loss: 0.6916 t_domain_loss: 0.6960 \n",
            "[12/16] class_loss: 0.4266 s_domain_loss: 0.6968 t_domain_loss: 0.7045 \n",
            "[13/16] class_loss: 0.3235 s_domain_loss: 0.6941 t_domain_loss: 0.6908 \n",
            "[14/16] class_loss: 0.2136 s_domain_loss: 0.6968 t_domain_loss: 0.6859 \n",
            "[15/16] class_loss: 0.3365 s_domain_loss: 0.7041 t_domain_loss: 0.6901 \n",
            "[16/16] class_loss: 0.2523 s_domain_loss: 0.6900 t_domain_loss: 0.6862 \n",
            "Accuracy is: 1.0365269461077844\n",
            "Accuracy on  photo during epoch 3 is 0.921556886227545 loss is 0.11288150399923325\n",
            "Accuracy on  artPainting during epoch 3 is 0.41796875 loss is 3.413487672805786\n",
            "[1/16] class_loss: 0.2611 s_domain_loss: 0.6866 t_domain_loss: 0.6909 \n",
            "[2/16] class_loss: 0.3568 s_domain_loss: 0.6899 t_domain_loss: 0.6897 \n",
            "[3/16] class_loss: 0.3048 s_domain_loss: 0.6977 t_domain_loss: 0.7010 \n",
            "[4/16] class_loss: 0.4287 s_domain_loss: 0.6930 t_domain_loss: 0.6879 \n",
            "[5/16] class_loss: 0.3327 s_domain_loss: 0.6870 t_domain_loss: 0.7031 \n",
            "[6/16] class_loss: 0.2472 s_domain_loss: 0.6751 t_domain_loss: 0.7046 \n",
            "[7/16] class_loss: 0.3057 s_domain_loss: 0.6748 t_domain_loss: 0.7067 \n",
            "[8/16] class_loss: 0.3649 s_domain_loss: 0.6739 t_domain_loss: 0.7114 \n",
            "[9/16] class_loss: 0.2922 s_domain_loss: 0.6757 t_domain_loss: 0.7035 \n",
            "[10/16] class_loss: 0.2229 s_domain_loss: 0.6757 t_domain_loss: 0.7021 \n",
            "[11/16] class_loss: 0.2456 s_domain_loss: 0.6630 t_domain_loss: 0.7025 \n",
            "[12/16] class_loss: 0.2796 s_domain_loss: 0.6700 t_domain_loss: 0.7133 \n",
            "[13/16] class_loss: 0.2962 s_domain_loss: 0.6716 t_domain_loss: 0.7012 \n",
            "[14/16] class_loss: 0.2039 s_domain_loss: 0.7154 t_domain_loss: 0.6950 \n",
            "[15/16] class_loss: 0.2207 s_domain_loss: 0.6848 t_domain_loss: 0.6994 \n",
            "[16/16] class_loss: 0.2894 s_domain_loss: 0.6771 t_domain_loss: 0.6947 \n",
            "Accuracy is: 1.0610778443113773\n",
            "Accuracy on  photo during epoch 4 is 0.9365269461077844 loss is 0.6770663857460022\n",
            "Accuracy on  artPainting during epoch 4 is 0.41943359375 loss is 3.728475570678711\n",
            "[1/16] class_loss: 0.3350 s_domain_loss: 0.6784 t_domain_loss: 0.6987 \n",
            "[2/16] class_loss: 0.4115 s_domain_loss: 0.6766 t_domain_loss: 0.6956 \n",
            "[3/16] class_loss: 0.2301 s_domain_loss: 0.6773 t_domain_loss: 0.7041 \n",
            "[4/16] class_loss: 0.3033 s_domain_loss: 0.6805 t_domain_loss: 0.6888 \n",
            "[5/16] class_loss: 0.2261 s_domain_loss: 0.6754 t_domain_loss: 0.7006 \n",
            "[6/16] class_loss: 0.3039 s_domain_loss: 0.6731 t_domain_loss: 0.7000 \n",
            "[7/16] class_loss: 0.2651 s_domain_loss: 0.6776 t_domain_loss: 0.6996 \n",
            "[8/16] class_loss: 0.2294 s_domain_loss: 0.6717 t_domain_loss: 0.7025 \n",
            "[9/16] class_loss: 0.2982 s_domain_loss: 0.6879 t_domain_loss: 0.6941 \n",
            "[10/16] class_loss: 0.2813 s_domain_loss: 0.6789 t_domain_loss: 0.6929 \n",
            "[11/16] class_loss: 0.2547 s_domain_loss: 0.6683 t_domain_loss: 0.6927 \n",
            "[12/16] class_loss: 0.2050 s_domain_loss: 0.6704 t_domain_loss: 0.7047 \n",
            "[13/16] class_loss: 0.1562 s_domain_loss: 0.6684 t_domain_loss: 0.6940 \n",
            "[14/16] class_loss: 0.2299 s_domain_loss: 0.6923 t_domain_loss: 0.6888 \n",
            "[15/16] class_loss: 0.2614 s_domain_loss: 0.6761 t_domain_loss: 0.6938 \n",
            "[16/16] class_loss: 0.2339 s_domain_loss: 0.6657 t_domain_loss: 0.6902 \n",
            "Accuracy is: 1.0622754491017965\n",
            "Accuracy on  photo during epoch 5 is 0.9401197604790419 loss is 0.35789695382118225\n",
            "Accuracy on  artPainting during epoch 5 is 0.43017578125 loss is 3.90313982963562\n",
            "[1/16] class_loss: 0.2493 s_domain_loss: 0.6733 t_domain_loss: 0.6959 \n",
            "[2/16] class_loss: 0.2609 s_domain_loss: 0.6691 t_domain_loss: 0.6946 \n",
            "[3/16] class_loss: 0.3279 s_domain_loss: 0.6583 t_domain_loss: 0.7033 \n",
            "[4/16] class_loss: 0.2385 s_domain_loss: 0.6739 t_domain_loss: 0.6879 \n",
            "[5/16] class_loss: 0.2523 s_domain_loss: 0.6714 t_domain_loss: 0.6993 \n",
            "[6/16] class_loss: 0.2206 s_domain_loss: 0.6765 t_domain_loss: 0.6987 \n",
            "[7/16] class_loss: 0.2106 s_domain_loss: 0.6680 t_domain_loss: 0.6984 \n",
            "[8/16] class_loss: 0.2550 s_domain_loss: 0.6735 t_domain_loss: 0.6994 \n",
            "[9/16] class_loss: 0.2617 s_domain_loss: 0.6730 t_domain_loss: 0.6907 \n",
            "[10/16] class_loss: 0.2133 s_domain_loss: 0.6633 t_domain_loss: 0.6896 \n",
            "[11/16] class_loss: 0.3318 s_domain_loss: 0.6772 t_domain_loss: 0.6877 \n",
            "[12/16] class_loss: 0.2480 s_domain_loss: 0.6757 t_domain_loss: 0.6997 \n",
            "[13/16] class_loss: 0.2365 s_domain_loss: 0.6790 t_domain_loss: 0.6894 \n",
            "[14/16] class_loss: 0.0417 s_domain_loss: 0.6689 t_domain_loss: 0.6840 \n",
            "[15/16] class_loss: 0.2030 s_domain_loss: 0.6711 t_domain_loss: 0.6884 \n",
            "[16/16] class_loss: 0.1480 s_domain_loss: 0.6671 t_domain_loss: 0.6843 \n",
            "Accuracy is: 1.0622754491017965\n",
            "Accuracy on  photo during epoch 6 is 0.9467065868263473 loss is 0.08969060331583023\n",
            "Accuracy on  artPainting during epoch 6 is 0.43212890625 loss is 4.00323486328125\n",
            "[1/16] class_loss: 0.2070 s_domain_loss: 0.6679 t_domain_loss: 0.6900 \n",
            "[2/16] class_loss: 0.1935 s_domain_loss: 0.6637 t_domain_loss: 0.6887 \n",
            "[3/16] class_loss: 0.1868 s_domain_loss: 0.6732 t_domain_loss: 0.6970 \n",
            "[4/16] class_loss: 0.1745 s_domain_loss: 0.6837 t_domain_loss: 0.6822 \n",
            "[5/16] class_loss: 0.1966 s_domain_loss: 0.6769 t_domain_loss: 0.6946 \n",
            "[6/16] class_loss: 0.2667 s_domain_loss: 0.6616 t_domain_loss: 0.6951 \n",
            "[7/16] class_loss: 0.1907 s_domain_loss: 0.6558 t_domain_loss: 0.6955 \n",
            "[8/16] class_loss: 0.2398 s_domain_loss: 0.6730 t_domain_loss: 0.6968 \n",
            "[9/16] class_loss: 0.1989 s_domain_loss: 0.6615 t_domain_loss: 0.6889 \n",
            "[10/16] class_loss: 0.2100 s_domain_loss: 0.6642 t_domain_loss: 0.6884 \n",
            "[11/16] class_loss: 0.2450 s_domain_loss: 0.6734 t_domain_loss: 0.6862 \n",
            "[12/16] class_loss: 0.1895 s_domain_loss: 0.6657 t_domain_loss: 0.6989 \n",
            "[13/16] class_loss: 0.2882 s_domain_loss: 0.6663 t_domain_loss: 0.6890 \n",
            "[14/16] class_loss: 0.1711 s_domain_loss: 0.7372 t_domain_loss: 0.6830 \n",
            "[15/16] class_loss: 0.2077 s_domain_loss: 0.6558 t_domain_loss: 0.6881 \n",
            "[16/16] class_loss: 0.1788 s_domain_loss: 0.6575 t_domain_loss: 0.6855 \n",
            "Accuracy is: 1.074251497005988\n",
            "Accuracy on  photo during epoch 7 is 0.9497005988023952 loss is 0.16512934863567352\n",
            "Accuracy on  artPainting during epoch 7 is 0.4365234375 loss is 4.1053571701049805\n",
            "[1/16] class_loss: 0.2624 s_domain_loss: 0.6655 t_domain_loss: 0.6921 \n",
            "[2/16] class_loss: 0.1650 s_domain_loss: 0.6659 t_domain_loss: 0.6916 \n",
            "[3/16] class_loss: 0.1796 s_domain_loss: 0.6524 t_domain_loss: 0.7000 \n",
            "[4/16] class_loss: 0.1844 s_domain_loss: 0.6531 t_domain_loss: 0.6850 \n",
            "[5/16] class_loss: 0.2236 s_domain_loss: 0.6725 t_domain_loss: 0.6961 \n",
            "[6/16] class_loss: 0.1902 s_domain_loss: 0.6606 t_domain_loss: 0.6952 \n",
            "[7/16] class_loss: 0.1892 s_domain_loss: 0.6879 t_domain_loss: 0.6941 \n",
            "[8/16] class_loss: 0.2077 s_domain_loss: 0.6650 t_domain_loss: 0.6944 \n",
            "[9/16] class_loss: 0.1549 s_domain_loss: 0.6524 t_domain_loss: 0.6861 \n",
            "[10/16] class_loss: 0.2293 s_domain_loss: 0.6616 t_domain_loss: 0.6850 \n",
            "[11/16] class_loss: 0.2020 s_domain_loss: 0.6446 t_domain_loss: 0.6813 \n",
            "[12/16] class_loss: 0.1941 s_domain_loss: 0.6771 t_domain_loss: 0.6929 \n",
            "[13/16] class_loss: 0.1954 s_domain_loss: 0.6739 t_domain_loss: 0.6830 \n",
            "[14/16] class_loss: 0.4125 s_domain_loss: 0.7626 t_domain_loss: 0.6769 \n",
            "[15/16] class_loss: 0.1736 s_domain_loss: 0.6678 t_domain_loss: 0.6768 \n",
            "[16/16] class_loss: 0.1824 s_domain_loss: 0.6718 t_domain_loss: 0.6710 \n",
            "Accuracy is: 1.08562874251497\n",
            "Accuracy on  photo during epoch 8 is 0.951497005988024 loss is 0.2062370330095291\n",
            "Accuracy on  artPainting during epoch 8 is 0.44384765625 loss is 4.262325286865234\n",
            "[1/16] class_loss: 0.2045 s_domain_loss: 0.6678 t_domain_loss: 0.6752 \n",
            "[2/16] class_loss: 0.2054 s_domain_loss: 0.6713 t_domain_loss: 0.6738 \n",
            "[3/16] class_loss: 0.1773 s_domain_loss: 0.6709 t_domain_loss: 0.6819 \n",
            "[4/16] class_loss: 0.1809 s_domain_loss: 0.6696 t_domain_loss: 0.6680 \n",
            "[5/16] class_loss: 0.2333 s_domain_loss: 0.6781 t_domain_loss: 0.6806 \n",
            "[6/16] class_loss: 0.2064 s_domain_loss: 0.6585 t_domain_loss: 0.6819 \n",
            "[7/16] class_loss: 0.2318 s_domain_loss: 0.6736 t_domain_loss: 0.6835 \n",
            "[8/16] class_loss: 0.1642 s_domain_loss: 0.6720 t_domain_loss: 0.6862 \n",
            "[9/16] class_loss: 0.1432 s_domain_loss: 0.6553 t_domain_loss: 0.6812 \n",
            "[10/16] class_loss: 0.1989 s_domain_loss: 0.6813 t_domain_loss: 0.6830 \n",
            "[11/16] class_loss: 0.2482 s_domain_loss: 0.6583 t_domain_loss: 0.6814 \n",
            "[12/16] class_loss: 0.1212 s_domain_loss: 0.6572 t_domain_loss: 0.6971 \n",
            "[13/16] class_loss: 0.1793 s_domain_loss: 0.6662 t_domain_loss: 0.6898 \n",
            "[14/16] class_loss: 0.0564 s_domain_loss: 0.6583 t_domain_loss: 0.6848 \n",
            "[15/16] class_loss: 0.2269 s_domain_loss: 0.6553 t_domain_loss: 0.6885 \n",
            "[16/16] class_loss: 0.1615 s_domain_loss: 0.6578 t_domain_loss: 0.6848 \n",
            "Accuracy is: 1.08562874251497\n",
            "Accuracy on  photo during epoch 9 is 0.9592814371257485 loss is 0.1723804473876953\n",
            "Accuracy on  artPainting during epoch 9 is 0.44580078125 loss is 4.400312900543213\n",
            "[1/16] class_loss: 0.1464 s_domain_loss: 0.6576 t_domain_loss: 0.6907 \n",
            "[2/16] class_loss: 0.2351 s_domain_loss: 0.6567 t_domain_loss: 0.6898 \n",
            "[3/16] class_loss: 0.2003 s_domain_loss: 0.6446 t_domain_loss: 0.6969 \n",
            "[4/16] class_loss: 0.2133 s_domain_loss: 0.6787 t_domain_loss: 0.6807 \n",
            "[5/16] class_loss: 0.2889 s_domain_loss: 0.6602 t_domain_loss: 0.6914 \n",
            "[6/16] class_loss: 0.1630 s_domain_loss: 0.6533 t_domain_loss: 0.6899 \n",
            "[7/16] class_loss: 0.1637 s_domain_loss: 0.6471 t_domain_loss: 0.6884 \n",
            "[8/16] class_loss: 0.1395 s_domain_loss: 0.6548 t_domain_loss: 0.6869 \n",
            "[9/16] class_loss: 0.2147 s_domain_loss: 0.6548 t_domain_loss: 0.6784 \n",
            "[10/16] class_loss: 0.1267 s_domain_loss: 0.6675 t_domain_loss: 0.6766 \n",
            "[11/16] class_loss: 0.1298 s_domain_loss: 0.6685 t_domain_loss: 0.6703 \n",
            "[12/16] class_loss: 0.1496 s_domain_loss: 0.6667 t_domain_loss: 0.6840 \n",
            "[13/16] class_loss: 0.1824 s_domain_loss: 0.6658 t_domain_loss: 0.6758 \n",
            "[14/16] class_loss: 0.0687 s_domain_loss: 0.7078 t_domain_loss: 0.6705 \n",
            "[15/16] class_loss: 0.1071 s_domain_loss: 0.6526 t_domain_loss: 0.6743 \n",
            "[16/16] class_loss: 0.1822 s_domain_loss: 0.6595 t_domain_loss: 0.6719 \n",
            "Accuracy is: 1.0886227544910179\n",
            "Accuracy on  photo during epoch 10 is 0.962874251497006 loss is 0.1570899486541748\n",
            "Accuracy on  artPainting during epoch 10 is 0.44580078125 loss is 4.566633701324463\n",
            "[1/16] class_loss: 0.1569 s_domain_loss: 0.6509 t_domain_loss: 0.6793 \n",
            "[2/16] class_loss: 0.2196 s_domain_loss: 0.6532 t_domain_loss: 0.6797 \n",
            "[3/16] class_loss: 0.2363 s_domain_loss: 0.6520 t_domain_loss: 0.6886 \n",
            "[4/16] class_loss: 0.1679 s_domain_loss: 0.6633 t_domain_loss: 0.6743 \n",
            "[5/16] class_loss: 0.1439 s_domain_loss: 0.6655 t_domain_loss: 0.6865 \n",
            "[6/16] class_loss: 0.1597 s_domain_loss: 0.6522 t_domain_loss: 0.6866 \n",
            "[7/16] class_loss: 0.1161 s_domain_loss: 0.6433 t_domain_loss: 0.6868 \n",
            "[8/16] class_loss: 0.1555 s_domain_loss: 0.6544 t_domain_loss: 0.6863 \n",
            "[9/16] class_loss: 0.1355 s_domain_loss: 0.6662 t_domain_loss: 0.6792 \n",
            "[10/16] class_loss: 0.2169 s_domain_loss: 0.6476 t_domain_loss: 0.6791 \n",
            "[11/16] class_loss: 0.1205 s_domain_loss: 0.6728 t_domain_loss: 0.6733 \n",
            "[12/16] class_loss: 0.1708 s_domain_loss: 0.6697 t_domain_loss: 0.6876 \n",
            "[13/16] class_loss: 0.1824 s_domain_loss: 0.6485 t_domain_loss: 0.6799 \n",
            "[14/16] class_loss: 0.0484 s_domain_loss: 0.8016 t_domain_loss: 0.6737 \n",
            "[15/16] class_loss: 0.2044 s_domain_loss: 0.6611 t_domain_loss: 0.6729 \n",
            "[16/16] class_loss: 0.1536 s_domain_loss: 0.6714 t_domain_loss: 0.6676 \n",
            "Accuracy is: 1.0904191616766468\n",
            "Accuracy on  photo during epoch 11 is 0.9658682634730539 loss is 0.06749621778726578\n",
            "Accuracy on  artPainting during epoch 11 is 0.44482421875 loss is 4.643836498260498\n",
            "[1/16] class_loss: 0.1538 s_domain_loss: 0.6560 t_domain_loss: 0.6720 \n",
            "[2/16] class_loss: 0.0976 s_domain_loss: 0.6497 t_domain_loss: 0.6711 \n",
            "[3/16] class_loss: 0.1313 s_domain_loss: 0.6676 t_domain_loss: 0.6785 \n",
            "[4/16] class_loss: 0.1397 s_domain_loss: 0.6684 t_domain_loss: 0.6642 \n",
            "[5/16] class_loss: 0.1839 s_domain_loss: 0.6520 t_domain_loss: 0.6766 \n",
            "[6/16] class_loss: 0.1254 s_domain_loss: 0.6542 t_domain_loss: 0.6766 \n",
            "[7/16] class_loss: 0.1292 s_domain_loss: 0.6594 t_domain_loss: 0.6780 \n",
            "[8/16] class_loss: 0.1442 s_domain_loss: 0.6666 t_domain_loss: 0.6788 \n",
            "[9/16] class_loss: 0.1478 s_domain_loss: 0.6516 t_domain_loss: 0.6739 \n",
            "[10/16] class_loss: 0.2460 s_domain_loss: 0.6587 t_domain_loss: 0.6753 \n",
            "[11/16] class_loss: 0.2139 s_domain_loss: 0.6731 t_domain_loss: 0.6706 \n",
            "[12/16] class_loss: 0.1262 s_domain_loss: 0.6552 t_domain_loss: 0.6862 \n",
            "[13/16] class_loss: 0.1467 s_domain_loss: 0.6641 t_domain_loss: 0.6800 \n",
            "[14/16] class_loss: 0.0128 s_domain_loss: 0.6760 t_domain_loss: 0.6741 \n",
            "[15/16] class_loss: 0.1637 s_domain_loss: 0.6525 t_domain_loss: 0.6764 \n",
            "[16/16] class_loss: 0.1211 s_domain_loss: 0.6485 t_domain_loss: 0.6730 \n",
            "Accuracy is: 1.1041916167664672\n",
            "Accuracy on  photo during epoch 12 is 0.9694610778443113 loss is 0.13230113685131073\n",
            "Accuracy on  artPainting during epoch 12 is 0.44287109375 loss is 4.737985134124756\n",
            "[1/16] class_loss: 0.1443 s_domain_loss: 0.6485 t_domain_loss: 0.6787 \n",
            "[2/16] class_loss: 0.1457 s_domain_loss: 0.6709 t_domain_loss: 0.6783 \n",
            "[3/16] class_loss: 0.1624 s_domain_loss: 0.6406 t_domain_loss: 0.6857 \n",
            "[4/16] class_loss: 0.1580 s_domain_loss: 0.6419 t_domain_loss: 0.6701 \n",
            "[5/16] class_loss: 0.1212 s_domain_loss: 0.6681 t_domain_loss: 0.6810 \n",
            "[6/16] class_loss: 0.1788 s_domain_loss: 0.6643 t_domain_loss: 0.6790 \n",
            "[7/16] class_loss: 0.0899 s_domain_loss: 0.6308 t_domain_loss: 0.6787 \n",
            "[8/16] class_loss: 0.1980 s_domain_loss: 0.6676 t_domain_loss: 0.6764 \n",
            "[9/16] class_loss: 0.1409 s_domain_loss: 0.6550 t_domain_loss: 0.6693 \n",
            "[10/16] class_loss: 0.1593 s_domain_loss: 0.6621 t_domain_loss: 0.6683 \n",
            "[11/16] class_loss: 0.1744 s_domain_loss: 0.6526 t_domain_loss: 0.6614 \n",
            "[12/16] class_loss: 0.1319 s_domain_loss: 0.6507 t_domain_loss: 0.6764 \n",
            "[13/16] class_loss: 0.1219 s_domain_loss: 0.6621 t_domain_loss: 0.6700 \n",
            "[14/16] class_loss: 0.1515 s_domain_loss: 0.7395 t_domain_loss: 0.6646 \n",
            "[15/16] class_loss: 0.0885 s_domain_loss: 0.6431 t_domain_loss: 0.6678 \n",
            "[16/16] class_loss: 0.1657 s_domain_loss: 0.6675 t_domain_loss: 0.6670 \n",
            "Accuracy is: 1.1023952095808383\n",
            "Accuracy on  photo during epoch 13 is 0.9694610778443113 loss is 0.131199911236763\n",
            "Accuracy on  artPainting during epoch 13 is 0.4462890625 loss is 4.813557147979736\n",
            "[1/16] class_loss: 0.1482 s_domain_loss: 0.6305 t_domain_loss: 0.6752 \n",
            "[2/16] class_loss: 0.1225 s_domain_loss: 0.6449 t_domain_loss: 0.6762 \n",
            "[3/16] class_loss: 0.2205 s_domain_loss: 0.6604 t_domain_loss: 0.6847 \n",
            "[4/16] class_loss: 0.1337 s_domain_loss: 0.6342 t_domain_loss: 0.6709 \n",
            "[5/16] class_loss: 0.1048 s_domain_loss: 0.6473 t_domain_loss: 0.6827 \n",
            "[6/16] class_loss: 0.1580 s_domain_loss: 0.6442 t_domain_loss: 0.6816 \n",
            "[7/16] class_loss: 0.0935 s_domain_loss: 0.6506 t_domain_loss: 0.6814 \n",
            "[8/16] class_loss: 0.1299 s_domain_loss: 0.6502 t_domain_loss: 0.6801 \n",
            "[9/16] class_loss: 0.1138 s_domain_loss: 0.6488 t_domain_loss: 0.6737 \n",
            "[10/16] class_loss: 0.1236 s_domain_loss: 0.6382 t_domain_loss: 0.6728 \n",
            "[11/16] class_loss: 0.1874 s_domain_loss: 0.6589 t_domain_loss: 0.6641 \n",
            "[12/16] class_loss: 0.1455 s_domain_loss: 0.6594 t_domain_loss: 0.6780 \n",
            "[13/16] class_loss: 0.1838 s_domain_loss: 0.6407 t_domain_loss: 0.6712 \n",
            "[14/16] class_loss: 0.0964 s_domain_loss: 0.7539 t_domain_loss: 0.6641 \n",
            "[15/16] class_loss: 0.1126 s_domain_loss: 0.6448 t_domain_loss: 0.6662 \n",
            "[16/16] class_loss: 0.1918 s_domain_loss: 0.6471 t_domain_loss: 0.6655 \n",
            "Accuracy is: 1.1053892215568861\n",
            "Accuracy on  photo during epoch 14 is 0.9712574850299401 loss is 0.019262393936514854\n",
            "Accuracy on  artPainting during epoch 14 is 0.44091796875 loss is 4.937544822692871\n",
            "[1/16] class_loss: 0.1005 s_domain_loss: 0.6447 t_domain_loss: 0.6723 \n",
            "[2/16] class_loss: 0.2186 s_domain_loss: 0.6432 t_domain_loss: 0.6735 \n",
            "[3/16] class_loss: 0.0987 s_domain_loss: 0.6430 t_domain_loss: 0.6823 \n",
            "[4/16] class_loss: 0.0913 s_domain_loss: 0.6365 t_domain_loss: 0.6683 \n",
            "[5/16] class_loss: 0.1482 s_domain_loss: 0.6455 t_domain_loss: 0.6791 \n",
            "[6/16] class_loss: 0.0837 s_domain_loss: 0.6375 t_domain_loss: 0.6786 \n",
            "[7/16] class_loss: 0.1256 s_domain_loss: 0.6688 t_domain_loss: 0.6784 \n",
            "[8/16] class_loss: 0.1543 s_domain_loss: 0.6345 t_domain_loss: 0.6772 \n",
            "[9/16] class_loss: 0.2003 s_domain_loss: 0.6330 t_domain_loss: 0.6714 \n",
            "[10/16] class_loss: 0.1752 s_domain_loss: 0.6461 t_domain_loss: 0.6699 \n",
            "[11/16] class_loss: 0.1314 s_domain_loss: 0.6534 t_domain_loss: 0.6609 \n",
            "[12/16] class_loss: 0.1459 s_domain_loss: 0.6507 t_domain_loss: 0.6748 \n",
            "[13/16] class_loss: 0.1237 s_domain_loss: 0.6543 t_domain_loss: 0.6688 \n",
            "[14/16] class_loss: 0.0704 s_domain_loss: 0.7568 t_domain_loss: 0.6618 \n",
            "[15/16] class_loss: 0.1565 s_domain_loss: 0.6512 t_domain_loss: 0.6628 \n",
            "[16/16] class_loss: 0.1312 s_domain_loss: 0.6665 t_domain_loss: 0.6625 \n",
            "Accuracy is: 1.1023952095808383\n",
            "Accuracy on  photo during epoch 15 is 0.9706586826347305 loss is 0.03489851951599121\n",
            "Accuracy on  artPainting during epoch 15 is 0.451171875 loss is 4.955747604370117\n",
            "[1/16] class_loss: 0.1079 s_domain_loss: 0.6470 t_domain_loss: 0.6694 \n",
            "[2/16] class_loss: 0.0870 s_domain_loss: 0.6306 t_domain_loss: 0.6712 \n",
            "[3/16] class_loss: 0.1405 s_domain_loss: 0.6492 t_domain_loss: 0.6793 \n",
            "[4/16] class_loss: 0.1223 s_domain_loss: 0.6612 t_domain_loss: 0.6653 \n",
            "[5/16] class_loss: 0.1012 s_domain_loss: 0.6319 t_domain_loss: 0.6766 \n",
            "[6/16] class_loss: 0.1710 s_domain_loss: 0.6273 t_domain_loss: 0.6765 \n",
            "[7/16] class_loss: 0.1407 s_domain_loss: 0.6249 t_domain_loss: 0.6765 \n",
            "[8/16] class_loss: 0.1404 s_domain_loss: 0.6549 t_domain_loss: 0.6733 \n",
            "[9/16] class_loss: 0.1182 s_domain_loss: 0.6434 t_domain_loss: 0.6676 \n",
            "[10/16] class_loss: 0.2229 s_domain_loss: 0.6452 t_domain_loss: 0.6663 \n",
            "[11/16] class_loss: 0.1214 s_domain_loss: 0.6434 t_domain_loss: 0.6567 \n",
            "[12/16] class_loss: 0.1128 s_domain_loss: 0.6655 t_domain_loss: 0.6708 \n",
            "[13/16] class_loss: 0.1558 s_domain_loss: 0.6411 t_domain_loss: 0.6657 \n",
            "[14/16] class_loss: 0.0746 s_domain_loss: 0.7308 t_domain_loss: 0.6592 \n",
            "[15/16] class_loss: 0.1398 s_domain_loss: 0.6581 t_domain_loss: 0.6585 \n",
            "[16/16] class_loss: 0.0933 s_domain_loss: 0.6512 t_domain_loss: 0.6582 \n",
            "Accuracy is: 1.1065868263473053\n",
            "Accuracy on  photo during epoch 16 is 0.9766467065868264 loss is 0.020691633224487305\n",
            "Accuracy on  artPainting during epoch 16 is 0.44677734375 loss is 5.011390686035156\n",
            "[1/16] class_loss: 0.1250 s_domain_loss: 0.6303 t_domain_loss: 0.6643 \n",
            "[2/16] class_loss: 0.1023 s_domain_loss: 0.6480 t_domain_loss: 0.6653 \n",
            "[3/16] class_loss: 0.1550 s_domain_loss: 0.6531 t_domain_loss: 0.6735 \n",
            "[4/16] class_loss: 0.1587 s_domain_loss: 0.6471 t_domain_loss: 0.6601 \n",
            "[5/16] class_loss: 0.1060 s_domain_loss: 0.6341 t_domain_loss: 0.6721 \n",
            "[6/16] class_loss: 0.0973 s_domain_loss: 0.6346 t_domain_loss: 0.6723 \n",
            "[7/16] class_loss: 0.1573 s_domain_loss: 0.6290 t_domain_loss: 0.6730 \n",
            "[8/16] class_loss: 0.1300 s_domain_loss: 0.6435 t_domain_loss: 0.6709 \n",
            "[9/16] class_loss: 0.1312 s_domain_loss: 0.6282 t_domain_loss: 0.6667 \n",
            "[10/16] class_loss: 0.1166 s_domain_loss: 0.6388 t_domain_loss: 0.6652 \n",
            "[11/16] class_loss: 0.1058 s_domain_loss: 0.6525 t_domain_loss: 0.6553 \n",
            "[12/16] class_loss: 0.1255 s_domain_loss: 0.6500 t_domain_loss: 0.6697 \n",
            "[13/16] class_loss: 0.1394 s_domain_loss: 0.6435 t_domain_loss: 0.6650 \n",
            "[14/16] class_loss: 0.0037 s_domain_loss: 0.7068 t_domain_loss: 0.6579 \n",
            "[15/16] class_loss: 0.0918 s_domain_loss: 0.6333 t_domain_loss: 0.6563 \n",
            "[16/16] class_loss: 0.1862 s_domain_loss: 0.6379 t_domain_loss: 0.6550 \n",
            "Accuracy is: 1.1077844311377245\n",
            "Accuracy on  photo during epoch 17 is 0.9796407185628743 loss is 0.21990621089935303\n",
            "Accuracy on  artPainting during epoch 17 is 0.447265625 loss is 5.029671669006348\n",
            "[1/16] class_loss: 0.1284 s_domain_loss: 0.6461 t_domain_loss: 0.6594 \n",
            "[2/16] class_loss: 0.1194 s_domain_loss: 0.6267 t_domain_loss: 0.6596 \n",
            "[3/16] class_loss: 0.1125 s_domain_loss: 0.6310 t_domain_loss: 0.6670 \n",
            "[4/16] class_loss: 0.1141 s_domain_loss: 0.6387 t_domain_loss: 0.6524 \n",
            "[5/16] class_loss: 0.1152 s_domain_loss: 0.6300 t_domain_loss: 0.6630 \n",
            "[6/16] class_loss: 0.0924 s_domain_loss: 0.6424 t_domain_loss: 0.6620 \n",
            "[7/16] class_loss: 0.1296 s_domain_loss: 0.6606 t_domain_loss: 0.6632 \n",
            "[8/16] class_loss: 0.0950 s_domain_loss: 0.6515 t_domain_loss: 0.6616 \n",
            "[9/16] class_loss: 0.1461 s_domain_loss: 0.6538 t_domain_loss: 0.6589 \n",
            "[10/16] class_loss: 0.0668 s_domain_loss: 0.6324 t_domain_loss: 0.6601 \n",
            "[11/16] class_loss: 0.1070 s_domain_loss: 0.6434 t_domain_loss: 0.6523 \n",
            "[12/16] class_loss: 0.1612 s_domain_loss: 0.6351 t_domain_loss: 0.6684 \n",
            "[13/16] class_loss: 0.1460 s_domain_loss: 0.6566 t_domain_loss: 0.6652 \n",
            "[14/16] class_loss: 0.0324 s_domain_loss: 0.7009 t_domain_loss: 0.6592 \n",
            "[15/16] class_loss: 0.1391 s_domain_loss: 0.6317 t_domain_loss: 0.6587 \n",
            "[16/16] class_loss: 0.1479 s_domain_loss: 0.6484 t_domain_loss: 0.6585 \n",
            "Accuracy is: 1.110179640718563\n",
            "Accuracy on  photo during epoch 18 is 0.9760479041916168 loss is 0.0375823974609375\n",
            "Accuracy on  artPainting during epoch 18 is 0.45654296875 loss is 5.046346664428711\n",
            "[1/16] class_loss: 0.1305 s_domain_loss: 0.6270 t_domain_loss: 0.6645 \n",
            "[2/16] class_loss: 0.0835 s_domain_loss: 0.6247 t_domain_loss: 0.6636 \n",
            "[3/16] class_loss: 0.1453 s_domain_loss: 0.6352 t_domain_loss: 0.6707 \n",
            "[4/16] class_loss: 0.1525 s_domain_loss: 0.6381 t_domain_loss: 0.6561 \n",
            "[5/16] class_loss: 0.1114 s_domain_loss: 0.6099 t_domain_loss: 0.6668 \n",
            "[6/16] class_loss: 0.0934 s_domain_loss: 0.6572 t_domain_loss: 0.6664 \n",
            "[7/16] class_loss: 0.1076 s_domain_loss: 0.6367 t_domain_loss: 0.6682 \n",
            "[8/16] class_loss: 0.1254 s_domain_loss: 0.6459 t_domain_loss: 0.6668 \n",
            "[9/16] class_loss: 0.1792 s_domain_loss: 0.6324 t_domain_loss: 0.6641 \n",
            "[10/16] class_loss: 0.0728 s_domain_loss: 0.6326 t_domain_loss: 0.6650 \n",
            "[11/16] class_loss: 0.1155 s_domain_loss: 0.6350 t_domain_loss: 0.6569 \n",
            "[12/16] class_loss: 0.1158 s_domain_loss: 0.6376 t_domain_loss: 0.6729 \n",
            "[13/16] class_loss: 0.0968 s_domain_loss: 0.6282 t_domain_loss: 0.6702 \n",
            "[14/16] class_loss: 0.0393 s_domain_loss: 0.6758 t_domain_loss: 0.6643 \n",
            "[15/16] class_loss: 0.0823 s_domain_loss: 0.6330 t_domain_loss: 0.6608 \n",
            "[16/16] class_loss: 0.1238 s_domain_loss: 0.6351 t_domain_loss: 0.6585 \n",
            "Accuracy is: 1.11437125748503\n",
            "Accuracy on  photo during epoch 19 is 0.9766467065868264 loss is 0.17170220613479614\n",
            "Accuracy on  artPainting during epoch 19 is 0.4541015625 loss is 5.060258865356445\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}