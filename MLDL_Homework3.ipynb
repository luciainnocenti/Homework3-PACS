{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDL - Homework3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/Homework3-PACS/blob/master/MLDL_Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "#**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from numpy import random \n",
        "\n",
        "random.seed(33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "#**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "BATCH_SIZE = 128     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 20      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "alfa = 0.1\n",
        "LR = 1e-4            # The initial Learning Rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "#**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      #transforms.RandomCrop( 64 , padding =2) ,\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "# Define transforms for the test phase\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "#**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "outputId": "0d8da47c-6292-41db-9f81-ea425eca4055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "# Clone github repository with data\n",
        "!git clone https://github.com/luciainnocenti/Homework3-PACS.git\n",
        "!mv 'Homework3-PACS' 'HW_PACS'\n",
        "\n",
        "from HW_PACS.dataset import PACS_Dataset \n",
        "\n",
        "rootPhoto = \"HW_PACS/PACS/photo\"\n",
        "photos = PACS_Dataset(root = rootPhoto, transform = train_transform)\n",
        "\n",
        "rootArt_painting = \"HW_PACS/PACS/art_painting\"\n",
        "art_painting = PACS_Dataset(root = rootArt_painting, transform = test_transform)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(photos)))\n",
        "print('Test Dataset: {}'.format(len(art_painting)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/58)\u001b[K\rremote: Counting objects:   3% (2/58)\u001b[K\rremote: Counting objects:   5% (3/58)\u001b[K\rremote: Counting objects:   6% (4/58)\u001b[K\rremote: Counting objects:   8% (5/58)\u001b[K\rremote: Counting objects:  10% (6/58)\u001b[K\rremote: Counting objects:  12% (7/58)\u001b[K\rremote: Counting objects:  13% (8/58)\u001b[K\rremote: Counting objects:  15% (9/58)\u001b[K\rremote: Counting objects:  17% (10/58)\u001b[K\rremote: Counting objects:  18% (11/58)\u001b[K\rremote: Counting objects:  20% (12/58)\u001b[K\rremote: Counting objects:  22% (13/58)\u001b[K\rremote: Counting objects:  24% (14/58)\u001b[K\rremote: Counting objects:  25% (15/58)\u001b[K\rremote: Counting objects:  27% (16/58)\u001b[K\rremote: Counting objects:  29% (17/58)\u001b[K\rremote: Counting objects:  31% (18/58)\u001b[K\rremote: Counting objects:  32% (19/58)\u001b[K\rremote: Counting objects:  34% (20/58)\u001b[K\rremote: Counting objects:  36% (21/58)\u001b[K\rremote: Counting objects:  37% (22/58)\u001b[K\rremote: Counting objects:  39% (23/58)\u001b[K\rremote: Counting objects:  41% (24/58)\u001b[K\rremote: Counting objects:  43% (25/58)\u001b[K\rremote: Counting objects:  44% (26/58)\u001b[K\rremote: Counting objects:  46% (27/58)\u001b[K\rremote: Counting objects:  48% (28/58)\u001b[K\rremote: Counting objects:  50% (29/58)\u001b[K\rremote: Counting objects:  51% (30/58)\u001b[K\rremote: Counting objects:  53% (31/58)\u001b[K\rremote: Counting objects:  55% (32/58)\u001b[K\rremote: Counting objects:  56% (33/58)\u001b[K\rremote: Counting objects:  58% (34/58)\u001b[K\rremote: Counting objects:  60% (35/58)\u001b[K\rremote: Counting objects:  62% (36/58)\u001b[K\rremote: Counting objects:  63% (37/58)\u001b[K\rremote: Counting objects:  65% (38/58)\u001b[K\rremote: Counting objects:  67% (39/58)\u001b[K\rremote: Counting objects:  68% (40/58)\u001b[K\rremote: Counting objects:  70% (41/58)\u001b[K\rremote: Counting objects:  72% (42/58)\u001b[K\rremote: Counting objects:  74% (43/58)\u001b[K\rremote: Counting objects:  75% (44/58)\u001b[K\rremote: Counting objects:  77% (45/58)\u001b[K\rremote: Counting objects:  79% (46/58)\u001b[K\rremote: Counting objects:  81% (47/58)\u001b[K\rremote: Counting objects:  82% (48/58)\u001b[K\rremote: Counting objects:  84% (49/58)\u001b[K\rremote: Counting objects:  86% (50/58)\u001b[K\rremote: Counting objects:  87% (51/58)\u001b[K\rremote: Counting objects:  89% (52/58)\u001b[K\rremote: Counting objects:  91% (53/58)\u001b[K\rremote: Counting objects:  93% (54/58)\u001b[K\rremote: Counting objects:  94% (55/58)\u001b[K\rremote: Counting objects:  96% (56/58)\u001b[K\rremote: Counting objects:  98% (57/58)\u001b[K\rremote: Counting objects: 100% (58/58)\u001b[K\rremote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 10090 (delta 33), reused 0 (delta 0), pack-reused 10032\u001b[K\n",
            "Receiving objects: 100% (10090/10090), 174.16 MiB | 42.27 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n",
            "Checking out files: 100% (9995/9995), done.\n",
            "Train Dataset: 1670\n",
            "Test Dataset: 2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "#**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "#**Model without DANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "##**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUjtXa22DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from HW_PACS.gradient_reversal_example import alexNetDA \n",
        "\n",
        "net = alexNetDA(num_classes = 7)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "##**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "# Choose parameters to optimize\n",
        "# To access a different set of parameters, you have to access submodules of AlexNet\n",
        "# (nn.Module objects, like AlexNet, implement the Composite Pattern)\n",
        "# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n",
        "# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n",
        "parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "# We use SGD with momentum\n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "#optimizer = optim.Adam(parameters_to_optimize, LR)\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "outputId": "93bd0912-2b8e-49b8-efc4-dea2dc10b04f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "running_corrects = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "# Iterate over the dataset\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  scheduler.step() \n",
        "  \n",
        "  for images, labels in  tqdm(photos_dataloader):\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(photos))\n",
        "  print(\"Accuracy on training set = \"  + str(accuracy))\n",
        "  running_corrects = 0\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "  7%|▋         | 1/14 [00:01<00:23,  1.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 1.9673067331314087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 10, Loss 1.3539432287216187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.45it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.3844311377245509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:03<00:02,  2.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 20, Loss 0.9486551880836487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.45it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.692814371257485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:07,  1.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 30, Loss 0.6538233160972595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.48it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 40, Loss 0.4664308428764343\n",
            "Accuracy on training set = 0.8161676646706587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:04<00:03,  1.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 50, Loss 0.47665244340896606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.50it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.8712574850299402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:04,  1.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 60, Loss 0.39233338832855225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.49it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/14 [00:01<00:24,  1.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 70, Loss 0.29677897691726685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 80, Loss 0.27069222927093506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.49it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9119760479041916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:03<00:02,  2.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 90, Loss 0.2601691782474518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.51it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9209580838323354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:06,  1.46it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 100, Loss 0.28928154706954956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.49it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 110, Loss 0.22764863073825836\n",
            "Accuracy on training set = 0.9293413173652695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:04<00:02,  1.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 120, Loss 0.22545912861824036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.48it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9395209580838323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 130, Loss 0.19737476110458374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.47it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9389221556886228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2/14 [00:01<00:16,  1.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 140, Loss 0.17453761398792267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 150, Loss 0.18441283702850342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.49it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9455089820359281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:03<00:02,  2.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 160, Loss 0.15890364348888397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.50it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9502994011976048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:06,  1.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 170, Loss 0.16938064992427826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.52it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 180, Loss 0.14955152571201324\n",
            "Accuracy on training set = 0.9520958083832335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:04<00:02,  1.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 190, Loss 0.17593692243099213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.51it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9550898203592815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 200, Loss 0.1073397547006607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.50it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9556886227544911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/14 [00:01<00:21,  1.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 210, Loss 0.14131996035575867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 12/14 [00:05<00:00,  2.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 220, Loss 0.1882384568452835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.47it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9550898203592815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 230, Loss 0.11406238377094269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.49it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9592814371257485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:07,  1.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 240, Loss 0.15812012553215027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.50it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 250, Loss 0.1483478844165802\n",
            "Accuracy on training set = 0.9568862275449102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:04<00:02,  1.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 260, Loss 0.15378251671791077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.52it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9616766467065868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 270, Loss 0.12091600894927979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.962874251497006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsHFI-GAJd69",
        "colab_type": "text"
      },
      "source": [
        "##**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3HV5pqJg1o",
        "colab_type": "code",
        "outputId": "0f90a646-a1ec-44e3-c51b-70203d8d77ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(art_painting_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(art_painting))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:06<00:00,  2.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.45654296875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPzBRkB3iKWU",
        "colab_type": "code",
        "outputId": "45c84797-f8c7-4a06-e694-594ca1e184f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.834967613220215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NHDb2yBC7jX",
        "colab_type": "text"
      },
      "source": [
        "# Model with DANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9PNdrqJdkSO",
        "colab_type": "text"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC1hCskMXaTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = alexNetDA(num_classes = 7)\n",
        "net = net.to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NemzVoaidnQA",
        "colab_type": "text"
      },
      "source": [
        "## Loss, Optim and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbFj42qsER6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion_class = nn.CrossEntropyLoss() \n",
        "criterion_domain = nn.CrossEntropyLoss()\n",
        "\n",
        "parameters_to_optimize = net.parameters() \n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW0rUNTbduSm",
        "colab_type": "text"
      },
      "source": [
        "## Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoZJAcaHEtYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "#art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "max_batches = min(len(photos_dataloader), len(art_painting_dataloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4tSP1-uEPQt",
        "colab_type": "code",
        "outputId": "ff230d1d-8896-47bc-c3f9-4c2e6f140875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "running_corrects = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "# Iterate over the dataset\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  scheduler.step() \n",
        "  iterPh = iter(photos_dataloader)\n",
        "  iterAP = iter(art_painting_dataloader)\n",
        "  for batch in range(max_batches):\n",
        "    net.train() # Sets module in training mode\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    images_source, labels_source = next(iterPh)\n",
        "    labels_domain = torch.zeros(len(images_source), dtype=torch.long)\n",
        "    \n",
        "    # Bring data over the device of choice\n",
        "    images_source = images_source.to(DEVICE)\n",
        "    labels_source = labels_source.to(DEVICE)\n",
        "    labels_domain = labels_domain.to(DEVICE)\n",
        "\n",
        "  \n",
        "    # Get the output for classes and domains; class_pred, domain_pred\n",
        "    classes_output = net(images_source)\n",
        "    domain_output = net(images_source, alfa)\n",
        "   \n",
        "    #In orter to compute the accuracy, count the right preditected labels\n",
        "    _, preds = torch.max(classes_output.data, 1)\n",
        "    \n",
        "    running_corrects += torch.sum(preds == labels_source.data).data.item()\n",
        "    \n",
        "    # Compute the loss on the source domain\n",
        "    loss_s_label = criterion_class(classes_output, labels_source)\n",
        "    loss_s_label.backward()\n",
        "    loss_s_domain = criterion_domain(domain_output, labels_domain)\n",
        "    loss_s_domain.backward()\n",
        "    \n",
        "    # Get the output for targets\n",
        "    targets, _ = next(iterAP)\n",
        "    target_domain = torch.ones(len(targets), dtype=torch.long)\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    targets = targets.to(DEVICE)\n",
        "    target_domain = target_domain.to(DEVICE)\n",
        "\n",
        "    target_output = net(targets, alfa)\n",
        "\n",
        "    # Compute the loss on the source domain\n",
        "    loss_t_domain = criterion_domain(target_output,target_domain)\n",
        "    loss_t_domain.backward()\n",
        "\n",
        "    #loss = loss_s_label + loss_s_domain + loss_t_domain\n",
        "    #loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "    print(f'[{batch+1}/{max_batches}] '\n",
        "          f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n",
        "          f't_domain_loss: {loss_t_domain.item():.4f} '\n",
        "          )  \n",
        "  # Calculate Accuracy \n",
        "  accuracy = running_corrects/float(len(photos))\n",
        "  print(f'Accuracy is: {accuracy}')\n",
        "  running_corrects = 0\n",
        "  "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/14] class_loss: 2.1260 s_domain_loss: 0.4924 t_domain_loss: 0.9804 \n",
            "[2/14] class_loss: 2.1257 s_domain_loss: 0.5051 t_domain_loss: 0.9587 \n",
            "[3/14] class_loss: 2.0422 s_domain_loss: 0.5201 t_domain_loss: 0.9365 \n",
            "[4/14] class_loss: 2.0423 s_domain_loss: 0.5518 t_domain_loss: 0.8800 \n",
            "[5/14] class_loss: 1.8109 s_domain_loss: 0.5876 t_domain_loss: 0.8476 \n",
            "[6/14] class_loss: 1.7856 s_domain_loss: 0.6305 t_domain_loss: 0.8006 \n",
            "[7/14] class_loss: 1.5885 s_domain_loss: 0.6837 t_domain_loss: 0.7414 \n",
            "[8/14] class_loss: 1.6503 s_domain_loss: 0.7261 t_domain_loss: 0.6893 \n",
            "[9/14] class_loss: 1.4040 s_domain_loss: 0.7555 t_domain_loss: 0.6703 \n",
            "[10/14] class_loss: 1.5646 s_domain_loss: 0.7935 t_domain_loss: 0.6311 \n",
            "[11/14] class_loss: 1.4027 s_domain_loss: 0.8131 t_domain_loss: 0.6114 \n",
            "[12/14] class_loss: 1.2717 s_domain_loss: 0.8411 t_domain_loss: 0.5946 \n",
            "[13/14] class_loss: 1.2667 s_domain_loss: 0.8377 t_domain_loss: 0.5916 \n",
            "[14/14] class_loss: 1.3723 s_domain_loss: 0.8363 t_domain_loss: 0.5938 \n",
            "Accuracy is: 0.3671875Accuracy_2 is 0.39401197604790417\n",
            "[1/14] class_loss: 1.1836 s_domain_loss: 0.8146 t_domain_loss: 0.6083 \n",
            "[2/14] class_loss: 0.9992 s_domain_loss: 0.7842 t_domain_loss: 0.6226 \n",
            "[3/14] class_loss: 0.9507 s_domain_loss: 0.7618 t_domain_loss: 0.6548 \n",
            "[4/14] class_loss: 0.9100 s_domain_loss: 0.7323 t_domain_loss: 0.6655 \n",
            "[5/14] class_loss: 1.1113 s_domain_loss: 0.7143 t_domain_loss: 0.7053 \n",
            "[6/14] class_loss: 0.8150 s_domain_loss: 0.6820 t_domain_loss: 0.7327 \n",
            "[7/14] class_loss: 0.9138 s_domain_loss: 0.6652 t_domain_loss: 0.7433 \n",
            "[8/14] class_loss: 0.8830 s_domain_loss: 0.6493 t_domain_loss: 0.7518 \n",
            "[9/14] class_loss: 0.9460 s_domain_loss: 0.6440 t_domain_loss: 0.7829 \n",
            "[10/14] class_loss: 0.7777 s_domain_loss: 0.6327 t_domain_loss: 0.7762 \n",
            "[11/14] class_loss: 0.8607 s_domain_loss: 0.6288 t_domain_loss: 0.7761 \n",
            "[12/14] class_loss: 0.7812 s_domain_loss: 0.6298 t_domain_loss: 0.7697 \n",
            "[13/14] class_loss: 0.7674 s_domain_loss: 0.6342 t_domain_loss: 0.7656 \n",
            "[14/14] class_loss: 1.1578 s_domain_loss: 0.6395 t_domain_loss: 0.7536 \n",
            "Accuracy is: 0.6646205357142857Accuracy_2 is 0.7131736526946107\n",
            "[1/14] class_loss: 0.6974 s_domain_loss: 0.6485 t_domain_loss: 0.7470 \n",
            "[2/14] class_loss: 0.7528 s_domain_loss: 0.6687 t_domain_loss: 0.7297 \n",
            "[3/14] class_loss: 0.6105 s_domain_loss: 0.6755 t_domain_loss: 0.7263 \n",
            "[4/14] class_loss: 0.6347 s_domain_loss: 0.6801 t_domain_loss: 0.7025 \n",
            "[5/14] class_loss: 0.5859 s_domain_loss: 0.6925 t_domain_loss: 0.7054 \n",
            "[6/14] class_loss: 0.6450 s_domain_loss: 0.7217 t_domain_loss: 0.6991 \n",
            "[7/14] class_loss: 0.5443 s_domain_loss: 0.7089 t_domain_loss: 0.6816 \n",
            "[8/14] class_loss: 0.5999 s_domain_loss: 0.7193 t_domain_loss: 0.6692 \n",
            "[9/14] class_loss: 0.6179 s_domain_loss: 0.7298 t_domain_loss: 0.6844 \n",
            "[10/14] class_loss: 0.5067 s_domain_loss: 0.7244 t_domain_loss: 0.6715 \n",
            "[11/14] class_loss: 0.6059 s_domain_loss: 0.7295 t_domain_loss: 0.6699 \n",
            "[12/14] class_loss: 0.4643 s_domain_loss: 0.7159 t_domain_loss: 0.6729 \n",
            "[13/14] class_loss: 0.5127 s_domain_loss: 0.7037 t_domain_loss: 0.6802 \n",
            "[14/14] class_loss: 0.3908 s_domain_loss: 0.7137 t_domain_loss: 0.6852 \n",
            "Accuracy is: 0.7762276785714286Accuracy_2 is 0.832934131736527\n",
            "[1/14] class_loss: 0.5370 s_domain_loss: 0.6998 t_domain_loss: 0.6978 \n",
            "[2/14] class_loss: 0.5619 s_domain_loss: 0.6890 t_domain_loss: 0.7006 \n",
            "[3/14] class_loss: 0.3916 s_domain_loss: 0.6727 t_domain_loss: 0.7167 \n",
            "[4/14] class_loss: 0.4304 s_domain_loss: 0.6681 t_domain_loss: 0.7128 \n",
            "[5/14] class_loss: 0.4834 s_domain_loss: 0.6703 t_domain_loss: 0.7300 \n",
            "[6/14] class_loss: 0.3975 s_domain_loss: 0.6519 t_domain_loss: 0.7354 \n",
            "[7/14] class_loss: 0.5115 s_domain_loss: 0.6618 t_domain_loss: 0.7259 \n",
            "[8/14] class_loss: 0.4774 s_domain_loss: 0.6661 t_domain_loss: 0.7183 \n",
            "[9/14] class_loss: 0.4502 s_domain_loss: 0.6632 t_domain_loss: 0.7354 \n",
            "[10/14] class_loss: 0.4233 s_domain_loss: 0.6667 t_domain_loss: 0.7186 \n",
            "[11/14] class_loss: 0.3336 s_domain_loss: 0.6787 t_domain_loss: 0.7101 \n",
            "[12/14] class_loss: 0.5324 s_domain_loss: 0.6797 t_domain_loss: 0.7063 \n",
            "[13/14] class_loss: 0.3529 s_domain_loss: 0.6715 t_domain_loss: 0.7050 \n",
            "[14/14] class_loss: 0.5525 s_domain_loss: 0.6845 t_domain_loss: 0.6986 \n",
            "Accuracy is: 0.80859375Accuracy_2 is 0.8676646706586826\n",
            "[1/14] class_loss: 0.4199 s_domain_loss: 0.6840 t_domain_loss: 0.6998 \n",
            "[2/14] class_loss: 0.3769 s_domain_loss: 0.6831 t_domain_loss: 0.6914 \n",
            "[3/14] class_loss: 0.4222 s_domain_loss: 0.7008 t_domain_loss: 0.6969 \n",
            "[4/14] class_loss: 0.3982 s_domain_loss: 0.6995 t_domain_loss: 0.6878 \n",
            "[5/14] class_loss: 0.3738 s_domain_loss: 0.6885 t_domain_loss: 0.6987 \n",
            "[6/14] class_loss: 0.3134 s_domain_loss: 0.6814 t_domain_loss: 0.7008 \n",
            "[7/14] class_loss: 0.3122 s_domain_loss: 0.6766 t_domain_loss: 0.6910 \n",
            "[8/14] class_loss: 0.2654 s_domain_loss: 0.6813 t_domain_loss: 0.6849 \n",
            "[9/14] class_loss: 0.3354 s_domain_loss: 0.6901 t_domain_loss: 0.7044 \n",
            "[10/14] class_loss: 0.3303 s_domain_loss: 0.6829 t_domain_loss: 0.6928 \n",
            "[11/14] class_loss: 0.3677 s_domain_loss: 0.6787 t_domain_loss: 0.6881 \n",
            "[12/14] class_loss: 0.3110 s_domain_loss: 0.6903 t_domain_loss: 0.6916 \n",
            "[13/14] class_loss: 0.3976 s_domain_loss: 0.6906 t_domain_loss: 0.6961 \n",
            "[14/14] class_loss: 0.2740 s_domain_loss: 0.6973 t_domain_loss: 0.6964 \n",
            "Accuracy is: 0.83984375Accuracy_2 is 0.9011976047904192\n",
            "[1/14] class_loss: 0.3723 s_domain_loss: 0.6758 t_domain_loss: 0.7035 \n",
            "[2/14] class_loss: 0.3319 s_domain_loss: 0.6597 t_domain_loss: 0.7001 \n",
            "[3/14] class_loss: 0.2534 s_domain_loss: 0.6605 t_domain_loss: 0.7091 \n",
            "[4/14] class_loss: 0.3491 s_domain_loss: 0.6716 t_domain_loss: 0.7033 \n",
            "[5/14] class_loss: 0.3397 s_domain_loss: 0.6648 t_domain_loss: 0.7142 \n",
            "[6/14] class_loss: 0.3457 s_domain_loss: 0.6728 t_domain_loss: 0.7154 \n",
            "[7/14] class_loss: 0.2794 s_domain_loss: 0.6605 t_domain_loss: 0.7042 \n",
            "[8/14] class_loss: 0.2867 s_domain_loss: 0.6706 t_domain_loss: 0.6957 \n",
            "[9/14] class_loss: 0.2535 s_domain_loss: 0.6740 t_domain_loss: 0.7132 \n",
            "[10/14] class_loss: 0.3142 s_domain_loss: 0.6838 t_domain_loss: 0.6980 \n",
            "[11/14] class_loss: 0.3211 s_domain_loss: 0.6880 t_domain_loss: 0.6883 \n",
            "[12/14] class_loss: 0.2270 s_domain_loss: 0.6827 t_domain_loss: 0.6895 \n",
            "[13/14] class_loss: 0.2574 s_domain_loss: 0.6737 t_domain_loss: 0.6915 \n",
            "[14/14] class_loss: 0.3300 s_domain_loss: 0.7217 t_domain_loss: 0.6887 \n",
            "Accuracy is: 0.8470982142857143Accuracy_2 is 0.9089820359281438\n",
            "[1/14] class_loss: 0.2808 s_domain_loss: 0.6782 t_domain_loss: 0.6932 \n",
            "[2/14] class_loss: 0.2357 s_domain_loss: 0.6661 t_domain_loss: 0.6870 \n",
            "[3/14] class_loss: 0.2815 s_domain_loss: 0.6787 t_domain_loss: 0.6947 \n",
            "[4/14] class_loss: 0.2504 s_domain_loss: 0.6704 t_domain_loss: 0.6892 \n",
            "[5/14] class_loss: 0.1963 s_domain_loss: 0.6714 t_domain_loss: 0.6999 \n",
            "[6/14] class_loss: 0.3236 s_domain_loss: 0.6847 t_domain_loss: 0.7020 \n",
            "[7/14] class_loss: 0.2691 s_domain_loss: 0.6901 t_domain_loss: 0.6927 \n",
            "[8/14] class_loss: 0.2848 s_domain_loss: 0.6654 t_domain_loss: 0.6870 \n",
            "[9/14] class_loss: 0.2709 s_domain_loss: 0.6686 t_domain_loss: 0.7074 \n",
            "[10/14] class_loss: 0.3111 s_domain_loss: 0.6747 t_domain_loss: 0.6946 \n",
            "[11/14] class_loss: 0.2782 s_domain_loss: 0.6758 t_domain_loss: 0.6859 \n",
            "[12/14] class_loss: 0.2517 s_domain_loss: 0.6791 t_domain_loss: 0.6897 \n",
            "[13/14] class_loss: 0.2518 s_domain_loss: 0.6821 t_domain_loss: 0.6937 \n",
            "[14/14] class_loss: 0.2970 s_domain_loss: 0.6843 t_domain_loss: 0.6921 \n",
            "Accuracy is: 0.8582589285714286Accuracy_2 is 0.9209580838323354\n",
            "[1/14] class_loss: 0.2347 s_domain_loss: 0.6650 t_domain_loss: 0.6972 \n",
            "[2/14] class_loss: 0.2604 s_domain_loss: 0.6811 t_domain_loss: 0.6904 \n",
            "[3/14] class_loss: 0.1889 s_domain_loss: 0.6589 t_domain_loss: 0.6982 \n",
            "[4/14] class_loss: 0.2629 s_domain_loss: 0.6677 t_domain_loss: 0.6928 \n",
            "[5/14] class_loss: 0.1706 s_domain_loss: 0.6528 t_domain_loss: 0.7026 \n",
            "[6/14] class_loss: 0.2422 s_domain_loss: 0.6606 t_domain_loss: 0.7036 \n",
            "[7/14] class_loss: 0.2810 s_domain_loss: 0.6718 t_domain_loss: 0.6927 \n",
            "[8/14] class_loss: 0.2996 s_domain_loss: 0.6730 t_domain_loss: 0.6848 \n",
            "[9/14] class_loss: 0.2719 s_domain_loss: 0.6809 t_domain_loss: 0.7037 \n",
            "[10/14] class_loss: 0.2526 s_domain_loss: 0.6803 t_domain_loss: 0.6896 \n",
            "[11/14] class_loss: 0.2992 s_domain_loss: 0.6741 t_domain_loss: 0.6794 \n",
            "[12/14] class_loss: 0.2575 s_domain_loss: 0.6776 t_domain_loss: 0.6830 \n",
            "[13/14] class_loss: 0.1562 s_domain_loss: 0.6665 t_domain_loss: 0.6873 \n",
            "[14/14] class_loss: 0.2844 s_domain_loss: 0.7083 t_domain_loss: 0.6855 \n",
            "Accuracy is: 0.8649553571428571Accuracy_2 is 0.9281437125748503\n",
            "[1/14] class_loss: 0.2771 s_domain_loss: 0.6656 t_domain_loss: 0.6909 \n",
            "[2/14] class_loss: 0.2208 s_domain_loss: 0.6666 t_domain_loss: 0.6849 \n",
            "[3/14] class_loss: 0.1867 s_domain_loss: 0.6609 t_domain_loss: 0.6935 \n",
            "[4/14] class_loss: 0.2251 s_domain_loss: 0.6680 t_domain_loss: 0.6884 \n",
            "[5/14] class_loss: 0.2430 s_domain_loss: 0.6639 t_domain_loss: 0.6985 \n",
            "[6/14] class_loss: 0.2268 s_domain_loss: 0.6744 t_domain_loss: 0.7001 \n",
            "[7/14] class_loss: 0.1946 s_domain_loss: 0.6653 t_domain_loss: 0.6906 \n",
            "[8/14] class_loss: 0.2071 s_domain_loss: 0.6795 t_domain_loss: 0.6836 \n",
            "[9/14] class_loss: 0.2103 s_domain_loss: 0.6656 t_domain_loss: 0.7036 \n",
            "[10/14] class_loss: 0.1923 s_domain_loss: 0.6663 t_domain_loss: 0.6905 \n",
            "[11/14] class_loss: 0.1860 s_domain_loss: 0.6603 t_domain_loss: 0.6801 \n",
            "[12/14] class_loss: 0.2917 s_domain_loss: 0.6658 t_domain_loss: 0.6836 \n",
            "[13/14] class_loss: 0.1887 s_domain_loss: 0.6605 t_domain_loss: 0.6873 \n",
            "[14/14] class_loss: 0.1695 s_domain_loss: 0.7029 t_domain_loss: 0.6854 \n",
            "Accuracy is: 0.8699776785714286Accuracy_2 is 0.9335329341317365\n",
            "[1/14] class_loss: 0.1946 s_domain_loss: 0.6538 t_domain_loss: 0.6895 \n",
            "[2/14] class_loss: 0.2385 s_domain_loss: 0.6642 t_domain_loss: 0.6822 \n",
            "[3/14] class_loss: 0.2038 s_domain_loss: 0.6643 t_domain_loss: 0.6899 \n",
            "[4/14] class_loss: 0.1477 s_domain_loss: 0.6588 t_domain_loss: 0.6841 \n",
            "[5/14] class_loss: 0.1911 s_domain_loss: 0.6653 t_domain_loss: 0.6935 \n",
            "[6/14] class_loss: 0.2047 s_domain_loss: 0.6717 t_domain_loss: 0.6947 \n",
            "[7/14] class_loss: 0.2418 s_domain_loss: 0.6641 t_domain_loss: 0.6856 \n",
            "[8/14] class_loss: 0.1531 s_domain_loss: 0.6618 t_domain_loss: 0.6789 \n",
            "[9/14] class_loss: 0.2469 s_domain_loss: 0.6734 t_domain_loss: 0.6990 \n",
            "[10/14] class_loss: 0.2012 s_domain_loss: 0.6724 t_domain_loss: 0.6861 \n",
            "[11/14] class_loss: 0.2582 s_domain_loss: 0.6787 t_domain_loss: 0.6756 \n",
            "[12/14] class_loss: 0.2273 s_domain_loss: 0.6667 t_domain_loss: 0.6807 \n",
            "[13/14] class_loss: 0.1854 s_domain_loss: 0.6667 t_domain_loss: 0.6858 \n",
            "[14/14] class_loss: 0.0527 s_domain_loss: 0.6733 t_domain_loss: 0.6853 \n",
            "Accuracy is: 0.8755580357142857Accuracy_2 is 0.9395209580838323\n",
            "[1/14] class_loss: 0.2025 s_domain_loss: 0.6700 t_domain_loss: 0.6891 \n",
            "[2/14] class_loss: 0.1603 s_domain_loss: 0.6676 t_domain_loss: 0.6825 \n",
            "[3/14] class_loss: 0.1709 s_domain_loss: 0.6648 t_domain_loss: 0.6908 \n",
            "[4/14] class_loss: 0.2600 s_domain_loss: 0.6449 t_domain_loss: 0.6853 \n",
            "[5/14] class_loss: 0.1436 s_domain_loss: 0.6589 t_domain_loss: 0.6941 \n",
            "[6/14] class_loss: 0.2106 s_domain_loss: 0.6520 t_domain_loss: 0.6947 \n",
            "[7/14] class_loss: 0.1284 s_domain_loss: 0.6621 t_domain_loss: 0.6848 \n",
            "[8/14] class_loss: 0.1502 s_domain_loss: 0.6536 t_domain_loss: 0.6769 \n",
            "[9/14] class_loss: 0.2223 s_domain_loss: 0.6643 t_domain_loss: 0.6959 \n",
            "[10/14] class_loss: 0.2052 s_domain_loss: 0.6588 t_domain_loss: 0.6822 \n",
            "[11/14] class_loss: 0.2398 s_domain_loss: 0.6591 t_domain_loss: 0.6704 \n",
            "[12/14] class_loss: 0.1961 s_domain_loss: 0.6754 t_domain_loss: 0.6742 \n",
            "[13/14] class_loss: 0.2047 s_domain_loss: 0.6858 t_domain_loss: 0.6790 \n",
            "[14/14] class_loss: 0.1471 s_domain_loss: 0.7232 t_domain_loss: 0.6788 \n",
            "Accuracy is: 0.8777901785714286Accuracy_2 is 0.9419161676646707\n",
            "[1/14] class_loss: 0.1918 s_domain_loss: 0.6688 t_domain_loss: 0.6823 \n",
            "[2/14] class_loss: 0.2059 s_domain_loss: 0.6616 t_domain_loss: 0.6764 \n",
            "[3/14] class_loss: 0.2283 s_domain_loss: 0.6685 t_domain_loss: 0.6853 \n",
            "[4/14] class_loss: 0.1359 s_domain_loss: 0.6573 t_domain_loss: 0.6809 \n",
            "[5/14] class_loss: 0.0999 s_domain_loss: 0.6432 t_domain_loss: 0.6913 \n",
            "[6/14] class_loss: 0.1871 s_domain_loss: 0.6675 t_domain_loss: 0.6924 \n",
            "[7/14] class_loss: 0.1947 s_domain_loss: 0.6708 t_domain_loss: 0.6837 \n",
            "[8/14] class_loss: 0.1584 s_domain_loss: 0.6558 t_domain_loss: 0.6778 \n",
            "[9/14] class_loss: 0.1953 s_domain_loss: 0.6443 t_domain_loss: 0.6978 \n",
            "[10/14] class_loss: 0.2424 s_domain_loss: 0.6478 t_domain_loss: 0.6844 \n",
            "[11/14] class_loss: 0.1861 s_domain_loss: 0.6647 t_domain_loss: 0.6713 \n",
            "[12/14] class_loss: 0.1374 s_domain_loss: 0.6582 t_domain_loss: 0.6752 \n",
            "[13/14] class_loss: 0.1724 s_domain_loss: 0.6693 t_domain_loss: 0.6794 \n",
            "[14/14] class_loss: 0.1010 s_domain_loss: 0.7184 t_domain_loss: 0.6787 \n",
            "Accuracy is: 0.8816964285714286Accuracy_2 is 0.9461077844311377\n",
            "[1/14] class_loss: 0.1721 s_domain_loss: 0.6729 t_domain_loss: 0.6807 \n",
            "[2/14] class_loss: 0.1227 s_domain_loss: 0.6569 t_domain_loss: 0.6746 \n",
            "[3/14] class_loss: 0.1765 s_domain_loss: 0.6567 t_domain_loss: 0.6832 \n",
            "[4/14] class_loss: 0.1670 s_domain_loss: 0.6443 t_domain_loss: 0.6782 \n",
            "[5/14] class_loss: 0.1776 s_domain_loss: 0.6716 t_domain_loss: 0.6878 \n",
            "[6/14] class_loss: 0.1292 s_domain_loss: 0.6600 t_domain_loss: 0.6893 \n",
            "[7/14] class_loss: 0.1977 s_domain_loss: 0.6661 t_domain_loss: 0.6811 \n",
            "[8/14] class_loss: 0.1815 s_domain_loss: 0.6458 t_domain_loss: 0.6751 \n",
            "[9/14] class_loss: 0.2122 s_domain_loss: 0.6689 t_domain_loss: 0.6954 \n",
            "[10/14] class_loss: 0.2105 s_domain_loss: 0.6521 t_domain_loss: 0.6823 \n",
            "[11/14] class_loss: 0.1822 s_domain_loss: 0.6506 t_domain_loss: 0.6700 \n",
            "[12/14] class_loss: 0.1684 s_domain_loss: 0.6512 t_domain_loss: 0.6747 \n",
            "[13/14] class_loss: 0.1214 s_domain_loss: 0.6505 t_domain_loss: 0.6793 \n",
            "[14/14] class_loss: 0.0152 s_domain_loss: 0.6841 t_domain_loss: 0.6786 \n",
            "Accuracy is: 0.8800223214285714Accuracy_2 is 0.944311377245509\n",
            "[1/14] class_loss: 0.1384 s_domain_loss: 0.6455 t_domain_loss: 0.6766 \n",
            "[2/14] class_loss: 0.2421 s_domain_loss: 0.6659 t_domain_loss: 0.6666 \n",
            "[3/14] class_loss: 0.1289 s_domain_loss: 0.6596 t_domain_loss: 0.6727 \n",
            "[4/14] class_loss: 0.1847 s_domain_loss: 0.6666 t_domain_loss: 0.6657 \n",
            "[5/14] class_loss: 0.2462 s_domain_loss: 0.6695 t_domain_loss: 0.6744 \n",
            "[6/14] class_loss: 0.1650 s_domain_loss: 0.6515 t_domain_loss: 0.6754 \n",
            "[7/14] class_loss: 0.1274 s_domain_loss: 0.6730 t_domain_loss: 0.6675 \n",
            "[8/14] class_loss: 0.1251 s_domain_loss: 0.6612 t_domain_loss: 0.6621 \n",
            "[9/14] class_loss: 0.1455 s_domain_loss: 0.6672 t_domain_loss: 0.6840 \n",
            "[10/14] class_loss: 0.1569 s_domain_loss: 0.6701 t_domain_loss: 0.6728 \n",
            "[11/14] class_loss: 0.1350 s_domain_loss: 0.6494 t_domain_loss: 0.6633 \n",
            "[12/14] class_loss: 0.1746 s_domain_loss: 0.6582 t_domain_loss: 0.6707 \n",
            "[13/14] class_loss: 0.1778 s_domain_loss: 0.6773 t_domain_loss: 0.6780 \n",
            "[14/14] class_loss: 0.0323 s_domain_loss: 0.7329 t_domain_loss: 0.6799 \n",
            "Accuracy is: 0.8794642857142857Accuracy_2 is 0.9437125748502994\n",
            "[1/14] class_loss: 0.1723 s_domain_loss: 0.6560 t_domain_loss: 0.6842 \n",
            "[2/14] class_loss: 0.2214 s_domain_loss: 0.6374 t_domain_loss: 0.6794 \n",
            "[3/14] class_loss: 0.1884 s_domain_loss: 0.6321 t_domain_loss: 0.6888 \n",
            "[4/14] class_loss: 0.1773 s_domain_loss: 0.6405 t_domain_loss: 0.6826 \n",
            "[5/14] class_loss: 0.1570 s_domain_loss: 0.6345 t_domain_loss: 0.6910 \n",
            "[6/14] class_loss: 0.1352 s_domain_loss: 0.6630 t_domain_loss: 0.6901 \n",
            "[7/14] class_loss: 0.1818 s_domain_loss: 0.6345 t_domain_loss: 0.6800 \n",
            "[8/14] class_loss: 0.1713 s_domain_loss: 0.6580 t_domain_loss: 0.6711 \n",
            "[9/14] class_loss: 0.1931 s_domain_loss: 0.6534 t_domain_loss: 0.6895 \n",
            "[10/14] class_loss: 0.0950 s_domain_loss: 0.6522 t_domain_loss: 0.6739 \n",
            "[11/14] class_loss: 0.1250 s_domain_loss: 0.6728 t_domain_loss: 0.6603 \n",
            "[12/14] class_loss: 0.1106 s_domain_loss: 0.6745 t_domain_loss: 0.6650 \n",
            "[13/14] class_loss: 0.1021 s_domain_loss: 0.6523 t_domain_loss: 0.6698 \n",
            "[14/14] class_loss: 0.1702 s_domain_loss: 0.7202 t_domain_loss: 0.6702 \n",
            "Accuracy is: 0.88671875Accuracy_2 is 0.951497005988024\n",
            "[1/14] class_loss: 0.1591 s_domain_loss: 0.6567 t_domain_loss: 0.6714 \n",
            "[2/14] class_loss: 0.1512 s_domain_loss: 0.6549 t_domain_loss: 0.6646 \n",
            "[3/14] class_loss: 0.2199 s_domain_loss: 0.6577 t_domain_loss: 0.6738 \n",
            "[4/14] class_loss: 0.1821 s_domain_loss: 0.6545 t_domain_loss: 0.6685 \n",
            "[5/14] class_loss: 0.1181 s_domain_loss: 0.6584 t_domain_loss: 0.6787 \n",
            "[6/14] class_loss: 0.1219 s_domain_loss: 0.6505 t_domain_loss: 0.6805 \n",
            "[7/14] class_loss: 0.1535 s_domain_loss: 0.6363 t_domain_loss: 0.6732 \n",
            "[8/14] class_loss: 0.1333 s_domain_loss: 0.6464 t_domain_loss: 0.6667 \n",
            "[9/14] class_loss: 0.1573 s_domain_loss: 0.6507 t_domain_loss: 0.6871 \n",
            "[10/14] class_loss: 0.1207 s_domain_loss: 0.6598 t_domain_loss: 0.6736 \n",
            "[11/14] class_loss: 0.0839 s_domain_loss: 0.6537 t_domain_loss: 0.6608 \n",
            "[12/14] class_loss: 0.1867 s_domain_loss: 0.6416 t_domain_loss: 0.6670 \n",
            "[13/14] class_loss: 0.1284 s_domain_loss: 0.6595 t_domain_loss: 0.6723 \n",
            "[14/14] class_loss: 0.0064 s_domain_loss: 0.7185 t_domain_loss: 0.6737 \n",
            "Accuracy is: 0.89453125Accuracy_2 is 0.9598802395209581\n",
            "[1/14] class_loss: 0.1026 s_domain_loss: 0.6543 t_domain_loss: 0.6714 \n",
            "[2/14] class_loss: 0.1776 s_domain_loss: 0.6509 t_domain_loss: 0.6628 \n",
            "[3/14] class_loss: 0.1256 s_domain_loss: 0.6620 t_domain_loss: 0.6700 \n",
            "[4/14] class_loss: 0.1581 s_domain_loss: 0.6711 t_domain_loss: 0.6629 \n",
            "[5/14] class_loss: 0.1348 s_domain_loss: 0.6389 t_domain_loss: 0.6725 \n",
            "[6/14] class_loss: 0.1402 s_domain_loss: 0.6456 t_domain_loss: 0.6731 \n",
            "[7/14] class_loss: 0.1772 s_domain_loss: 0.6500 t_domain_loss: 0.6651 \n",
            "[8/14] class_loss: 0.1547 s_domain_loss: 0.6544 t_domain_loss: 0.6595 \n",
            "[9/14] class_loss: 0.1247 s_domain_loss: 0.6778 t_domain_loss: 0.6805 \n",
            "[10/14] class_loss: 0.1572 s_domain_loss: 0.6491 t_domain_loss: 0.6683 \n",
            "[11/14] class_loss: 0.1254 s_domain_loss: 0.6420 t_domain_loss: 0.6570 \n",
            "[12/14] class_loss: 0.1173 s_domain_loss: 0.6397 t_domain_loss: 0.6639 \n",
            "[13/14] class_loss: 0.1321 s_domain_loss: 0.6542 t_domain_loss: 0.6698 \n",
            "[14/14] class_loss: 0.1431 s_domain_loss: 0.7093 t_domain_loss: 0.6712 \n",
            "Accuracy is: 0.890625Accuracy_2 is 0.9556886227544911\n",
            "[1/14] class_loss: 0.1048 s_domain_loss: 0.6520 t_domain_loss: 0.6706 \n",
            "[2/14] class_loss: 0.1430 s_domain_loss: 0.6390 t_domain_loss: 0.6640 \n",
            "[3/14] class_loss: 0.1520 s_domain_loss: 0.6335 t_domain_loss: 0.6723 \n",
            "[4/14] class_loss: 0.1132 s_domain_loss: 0.6428 t_domain_loss: 0.6652 \n",
            "[5/14] class_loss: 0.1708 s_domain_loss: 0.6569 t_domain_loss: 0.6742 \n",
            "[6/14] class_loss: 0.1492 s_domain_loss: 0.6649 t_domain_loss: 0.6742 \n",
            "[7/14] class_loss: 0.1896 s_domain_loss: 0.6598 t_domain_loss: 0.6666 \n",
            "[8/14] class_loss: 0.1049 s_domain_loss: 0.6491 t_domain_loss: 0.6612 \n",
            "[9/14] class_loss: 0.1589 s_domain_loss: 0.6396 t_domain_loss: 0.6822 \n",
            "[10/14] class_loss: 0.1271 s_domain_loss: 0.6584 t_domain_loss: 0.6690 \n",
            "[11/14] class_loss: 0.1859 s_domain_loss: 0.6508 t_domain_loss: 0.6571 \n",
            "[12/14] class_loss: 0.1075 s_domain_loss: 0.6222 t_domain_loss: 0.6638 \n",
            "[13/14] class_loss: 0.1730 s_domain_loss: 0.6411 t_domain_loss: 0.6693 \n",
            "[14/14] class_loss: 0.2853 s_domain_loss: 0.7080 t_domain_loss: 0.6704 \n",
            "Accuracy is: 0.8883928571428571Accuracy_2 is 0.9532934131736527\n",
            "[1/14] class_loss: 0.1399 s_domain_loss: 0.6481 t_domain_loss: 0.6680 \n",
            "[2/14] class_loss: 0.2054 s_domain_loss: 0.6722 t_domain_loss: 0.6608 \n",
            "[3/14] class_loss: 0.0938 s_domain_loss: 0.6490 t_domain_loss: 0.6693 \n",
            "[4/14] class_loss: 0.1124 s_domain_loss: 0.6401 t_domain_loss: 0.6627 \n",
            "[5/14] class_loss: 0.1106 s_domain_loss: 0.6380 t_domain_loss: 0.6728 \n",
            "[6/14] class_loss: 0.1125 s_domain_loss: 0.6476 t_domain_loss: 0.6732 \n",
            "[7/14] class_loss: 0.1374 s_domain_loss: 0.6409 t_domain_loss: 0.6652 \n",
            "[8/14] class_loss: 0.1141 s_domain_loss: 0.6468 t_domain_loss: 0.6583 \n",
            "[9/14] class_loss: 0.0840 s_domain_loss: 0.6413 t_domain_loss: 0.6790 \n",
            "[10/14] class_loss: 0.1218 s_domain_loss: 0.6486 t_domain_loss: 0.6655 \n",
            "[11/14] class_loss: 0.1185 s_domain_loss: 0.6444 t_domain_loss: 0.6528 \n",
            "[12/14] class_loss: 0.1320 s_domain_loss: 0.6289 t_domain_loss: 0.6590 \n",
            "[13/14] class_loss: 0.0785 s_domain_loss: 0.6473 t_domain_loss: 0.6651 \n",
            "[14/14] class_loss: 0.3300 s_domain_loss: 0.7569 t_domain_loss: 0.6665 \n",
            "Accuracy is: 0.9051339285714286Accuracy_2 is 0.9712574850299401\n",
            "[1/14] class_loss: 0.1144 s_domain_loss: 0.6594 t_domain_loss: 0.6657 \n",
            "[2/14] class_loss: 0.1796 s_domain_loss: 0.6642 t_domain_loss: 0.6575 \n",
            "[3/14] class_loss: 0.1108 s_domain_loss: 0.6480 t_domain_loss: 0.6649 \n",
            "[4/14] class_loss: 0.1734 s_domain_loss: 0.6495 t_domain_loss: 0.6573 \n",
            "[5/14] class_loss: 0.1458 s_domain_loss: 0.6584 t_domain_loss: 0.6668 \n",
            "[6/14] class_loss: 0.1194 s_domain_loss: 0.6230 t_domain_loss: 0.6679 \n",
            "[7/14] class_loss: 0.1194 s_domain_loss: 0.6351 t_domain_loss: 0.6610 \n",
            "[8/14] class_loss: 0.1021 s_domain_loss: 0.6494 t_domain_loss: 0.6550 \n",
            "[9/14] class_loss: 0.1173 s_domain_loss: 0.6463 t_domain_loss: 0.6768 \n",
            "[10/14] class_loss: 0.1151 s_domain_loss: 0.6417 t_domain_loss: 0.6646 \n",
            "[11/14] class_loss: 0.1468 s_domain_loss: 0.6485 t_domain_loss: 0.6532 \n",
            "[12/14] class_loss: 0.1972 s_domain_loss: 0.6563 t_domain_loss: 0.6606 \n",
            "[13/14] class_loss: 0.0985 s_domain_loss: 0.6212 t_domain_loss: 0.6683 \n",
            "[14/14] class_loss: 0.0673 s_domain_loss: 0.7121 t_domain_loss: 0.6714 \n",
            "Accuracy is: 0.8922991071428571Accuracy_2 is 0.9574850299401197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgONyH0xfN9W",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4arKipfR0Q",
        "colab_type": "code",
        "outputId": "0d6ec733-638b-43c4-a3e8-3f6e749ee461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(art_painting_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(art_painting))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))\n",
        "print('Loss is: ' + str(loss.item()))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:06<00:00,  2.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.4462890625\n",
            "Loss is: 5.777981758117676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIyWY1Mn-ZP8",
        "colab_type": "code",
        "outputId": "36a34ced-ddeb-417d-c940-31d104e4d68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LR"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGi68vVW-a3G",
        "colab_type": "code",
        "outputId": "01caa485-4e07-43b3-c393-9c397ce1e8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alfa"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYzdDu7l-b5R",
        "colab_type": "code",
        "outputId": "8a61e654-51c1-4aaf-b313-8dc690324d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NUM_EPOCHS"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}