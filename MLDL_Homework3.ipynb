{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDL - Homework3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "20f44ed6807844dcb7bce70f5c5269ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b847cb22601645d886bc9b91cb3ad616",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7a2dc2a127a549b1b1d72097d4a6ece4",
              "IPY_MODEL_bd888d5b3ee148328ee852db2b7de852"
            ]
          }
        },
        "b847cb22601645d886bc9b91cb3ad616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a2dc2a127a549b1b1d72097d4a6ece4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08249054bdb24361816e487e1f2f7df4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3c16d3a64b243af9eb4d93cea1c34aa"
          }
        },
        "bd888d5b3ee148328ee852db2b7de852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c211af4d21a246788c29162ab16ab1c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [02:19&lt;00:00, 1.76MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbb4f4f26c2b4c39849b902f2e75ce4a"
          }
        },
        "08249054bdb24361816e487e1f2f7df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3c16d3a64b243af9eb4d93cea1c34aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c211af4d21a246788c29162ab16ab1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbb4f4f26c2b4c39849b902f2e75ce4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/Homework3-PACS/blob/master/MLDL_Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "#**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from numpy import random \n",
        "\n",
        "random.seed(33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "#**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "BATCH_SIZE = 128     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 20      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-67R9ZKOK56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#V1\n",
        "\n",
        "alfa = 1\n",
        "LR = 1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvfmR0ZtOeYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#V2\n",
        "\n",
        "alfa = 1\n",
        "LR = 1e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4olXnzoaOmVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#V3\n",
        "\n",
        "alfa = 1\n",
        "LR = 1e-6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehjxiMEmVMlk",
        "colab_type": "text"
      },
      "source": [
        "# Import and definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5u4Nr4vVLv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "cbca682e-f4a4-4ff9-8da9-fe0a3d612ced"
      },
      "source": [
        "# Clone github repository with data\n",
        "!git clone https://github.com/luciainnocenti/Homework3-PACS.git\n",
        "!mv 'Homework3-PACS' 'HW_PACS'\n",
        "\n",
        "from HW_PACS.dataset import PACS_Dataset "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 10117 (delta 7), reused 0 (delta 0), pack-reused 10102\u001b[K\n",
            "Receiving objects: 100% (10117/10117), 174.21 MiB | 40.73 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "Checking out files: 100% (9995/9995), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kYMQ1ccVO3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "50d05da8-d702-4197-ec2f-c09f3501d17c"
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),   \n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "])\n",
        "# Define transforms for the test phase\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "rootPhoto = \"HW_PACS/PACS/photo\"\n",
        "photos = PACS_Dataset(root = rootPhoto, transform = train_transform)\n",
        "\n",
        "rootArt_painting = \"HW_PACS/PACS/art_painting\"\n",
        "art_painting = PACS_Dataset(root = rootArt_painting, transform = test_transform)\n",
        "\n",
        "photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "print(photos.meanAndStd(photos_dataloader))\n",
        "print(art_painting.meanAndStd(art_painting_dataloader))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([0.5088, 0.4744, 0.4307]), tensor([0.2725, 0.2620, 0.2774]))\n",
            "(tensor([0.5530, 0.5018, 0.4488]), tensor([0.2750, 0.2648, 0.2775]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "#**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),   \n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "# Define transforms for the test phase\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "#**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "outputId": "de2e4165-c095-4f11-92ce-fefd92f84f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "rootPhoto = \"HW_PACS/PACS/photo\"\n",
        "photos = PACS_Dataset(root = rootPhoto, transform = train_transform)\n",
        "\n",
        "rootArt_painting = \"HW_PACS/PACS/art_painting\"\n",
        "art_painting = PACS_Dataset(root = rootArt_painting, transform = test_transform)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(photos)))\n",
        "print('Test Dataset: {}'.format(len(art_painting)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10111 (delta 4), reused 0 (delta 0), pack-reused 10102\u001b[K\n",
            "Receiving objects: 100% (10111/10111), 174.20 MiB | 41.04 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n",
            "Checking out files: 100% (9995/9995), done.\n",
            "Train Dataset: 1670\n",
            "Test Dataset: 2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "#**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "#**Model without DANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "##**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUjtXa22DN",
        "colab_type": "code",
        "outputId": "43543eef-7fc9-4e32-a8d5-963c2e43fc3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "20f44ed6807844dcb7bce70f5c5269ba",
            "b847cb22601645d886bc9b91cb3ad616",
            "7a2dc2a127a549b1b1d72097d4a6ece4",
            "bd888d5b3ee148328ee852db2b7de852",
            "08249054bdb24361816e487e1f2f7df4",
            "c3c16d3a64b243af9eb4d93cea1c34aa",
            "c211af4d21a246788c29162ab16ab1c1",
            "fbb4f4f26c2b4c39849b902f2e75ce4a"
          ]
        }
      },
      "source": [
        "from HW_PACS.gradient_reversal_example import alexNetDA \n",
        "\n",
        "net = alexNetDA(num_classes = 7)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20f44ed6807844dcb7bce70f5c5269ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "##**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "# Choose parameters to optimize\n",
        "# To access a different set of parameters, you have to access submodules of AlexNet\n",
        "# (nn.Module objects, like AlexNet, implement the Composite Pattern)\n",
        "# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n",
        "# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n",
        "parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "# We use SGD with momentum\n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "#optimizer = optim.Adam(parameters_to_optimize, LR)\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "outputId": "b7938e90-4ad6-4595-d570-1951f0bd9bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "running_corrects = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "# Iterate over the dataset\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  scheduler.step() \n",
        "  \n",
        "  for images, labels in  tqdm(photos_dataloader):\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(photos))\n",
        "  print(\"Accuracy on training set = \"  + str(accuracy))\n",
        "  running_corrects = 0\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "  7%|▋         | 1/14 [00:02<00:27,  2.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 2.202073097229004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 10, Loss 1.4075310230255127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.45it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.32335329341317365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 7/14 [00:03<00:03,  2.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 20, Loss 0.9367499351501465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.46it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.7143712574850299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:07,  1.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 30, Loss 0.6281982660293579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.47it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 40, Loss 0.5346744060516357\n",
            "Accuracy on training set = 0.8245508982035928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 10/14 [00:05<00:01,  2.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 50, Loss 0.41926366090774536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.46it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.8808383233532934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 60, Loss 0.37612807750701904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.47it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9041916167664671\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2/14 [00:02<00:17,  1.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 70, Loss 0.3193032145500183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 80, Loss 0.24280497431755066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.46it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9191616766467066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:03<00:02,  2.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 90, Loss 0.34502604603767395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.47it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9209580838323354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:07,  1.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 100, Loss 0.2576473653316498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.46it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 110, Loss 0.20148113369941711\n",
            "Accuracy on training set = 0.932934131736527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:02,  1.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 120, Loss 0.19320596754550934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.46it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9341317365269461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 130, Loss 0.18101529777050018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.45it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9413173652694611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2/14 [00:02<00:16,  1.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 140, Loss 0.21210607886314392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  2.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 150, Loss 0.16873371601104736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.45it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9359281437125748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:03<00:02,  2.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 160, Loss 0.14407256245613098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.45it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9491017964071856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:07,  1.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 170, Loss 0.09751266241073608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.41it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 180, Loss 0.23166052997112274\n",
            "Accuracy on training set = 0.9502994011976048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:03,  1.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 190, Loss 0.2000117003917694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.42it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9502994011976048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 200, Loss 0.1384681761264801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.44it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9520958083832335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/14 [00:01<00:24,  1.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 210, Loss 0.10375425219535828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 12/14 [00:05<00:00,  2.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 220, Loss 0.11435271799564362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.47it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9562874251497006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:03<00:02,  2.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 230, Loss 0.17930226027965546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.47it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9562874251497006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 3/14 [00:02<00:11,  1.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 240, Loss 0.14167127013206482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.46it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 250, Loss 0.16630400717258453\n",
            "Accuracy on training set = 0.9568862275449102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:02,  1.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 260, Loss 0.12892410159111023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.46it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9640718562874252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 270, Loss 0.1709321141242981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9604790419161676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsHFI-GAJd69",
        "colab_type": "text"
      },
      "source": [
        "##**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3HV5pqJg1o",
        "colab_type": "code",
        "outputId": "c368e55c-6b07-456a-8d2e-6301a81a4aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(art_painting_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(art_painting))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:06<00:00,  2.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.45751953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPzBRkB3iKWU",
        "colab_type": "code",
        "outputId": "aeb5f325-a458-4e11-ea5b-0d0f0c544711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.7857666015625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NHDb2yBC7jX",
        "colab_type": "text"
      },
      "source": [
        "# Model with DANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9PNdrqJdkSO",
        "colab_type": "text"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC1hCskMXaTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = alexNetDA(num_classes = 7)\n",
        "net = net.to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NemzVoaidnQA",
        "colab_type": "text"
      },
      "source": [
        "## Loss, Optim and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbFj42qsER6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion_class = nn.CrossEntropyLoss() \n",
        "criterion_domain = nn.CrossEntropyLoss()\n",
        "\n",
        "parameters_to_optimize = net.parameters() \n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "#optimizer = optim.Adam(parameters_to_optimize, LR)\n",
        "\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgONyH0xfN9W",
        "colab_type": "text"
      },
      "source": [
        "## Test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4arKipfR0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testFunction(datasetName, epoch):  \n",
        "  net = torch.load('model_epoch_' + str(epoch) + '.pt')\n",
        "  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "  if (datasetName == 'photo'):\n",
        "    dataLoader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "  elif( datasetName == 'artPainting'):\n",
        "    dataLoader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "  lenLoader = len(dataLoader)\n",
        "  iterator = iter(dataLoader)\n",
        "  totalLen = 0\n",
        "  running_corrects = 0\n",
        "  criterion = nn.CrossEntropyLoss() \n",
        "  for i in range(lenLoader):\n",
        "    t_img, t_label = next(iterator)\n",
        "\n",
        "    t_img = t_img.to(DEVICE)\n",
        "    t_label = t_label.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    classes_output = net(t_img)\n",
        "\n",
        "    loss = criterion(classes_output, t_label)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(classes_output.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == t_label.data).data.item()\n",
        "    totalLen += len(t_img)\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(totalLen)\n",
        "\n",
        "  print(f'Accuracy on  {datasetName}' f' during epoch {epoch}' f' is {accuracy}' f' loss is {loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW0rUNTbduSm",
        "colab_type": "text"
      },
      "source": [
        "## Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoZJAcaHEtYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "#art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "max_batches = max(len(photos_dataloader), len(art_painting_dataloader))\n",
        "min_batches = min(len(photos_dataloader), len(art_painting_dataloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4tSP1-uEPQt",
        "colab_type": "code",
        "outputId": "4670b9d8-0d1f-42d2-b1d2-b27ed92e159e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "running_corrects = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "# Iterate over the dataset\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  scheduler.step() \n",
        "  iterPh = iter(photos_dataloader)\n",
        "  iterAP = iter(art_painting_dataloader)\n",
        "  for batch in range(max_batches):\n",
        "    net.train() # Sets module in training mode\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "    if( batch == min_batches):\n",
        "      iterPh = iter(photos_dataloader)\n",
        "    images_source, labels_source = next(iterPh)\n",
        "    labels_domain = torch.zeros(len(images_source), dtype=torch.long)\n",
        "    \n",
        "    # Bring data over the device of choice\n",
        "    images_source = images_source.to(DEVICE)\n",
        "    labels_source = labels_source.to(DEVICE)\n",
        "    labels_domain = labels_domain.to(DEVICE)\n",
        "\n",
        "  \n",
        "    # Get the output for classes and domains; class_pred, domain_pred\n",
        "    classes_output = net(images_source)\n",
        "    # Compute the loss on the source domain\n",
        "    loss_s_label = criterion_class(classes_output, labels_source)\n",
        "\n",
        "    domain_output = net(images_source, alfa)\n",
        "    # Compute the loss on the source domain\n",
        "    loss_s_domain = criterion_domain(domain_output, labels_domain)\n",
        "\n",
        "    # Get the output for targets\n",
        "    targets, _ = next(iterAP)\n",
        "    target_domain = torch.ones(len(targets), dtype=torch.long)\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    targets = targets.to(DEVICE)\n",
        "    target_domain = target_domain.to(DEVICE)\n",
        "\n",
        "    target_output = net(targets, alfa)\n",
        "\n",
        "    # Compute the loss on the source domain\n",
        "    loss_t_domain = criterion_domain(target_output,target_domain)\n",
        "\n",
        "    loss = loss_s_label + loss_s_domain + loss_t_domain\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "    print(f'[{batch+1}/{max_batches}] '\n",
        "          f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n",
        "          f't_domain_loss: {loss_t_domain.item():.4f} '\n",
        "          )  \n",
        "  torch.save(net, 'model_epoch_{0}.pt'.format(epoch))\n",
        "  testFunction('photo', epoch)\n",
        "  testFunction('artPainting', epoch)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/16] class_loss: 1.9356 s_domain_loss: 0.8158 t_domain_loss: 0.6379 \n",
            "[2/16] class_loss: 1.9063 s_domain_loss: 0.8133 t_domain_loss: 0.6425 \n",
            "[3/16] class_loss: 1.9379 s_domain_loss: 0.7897 t_domain_loss: 0.6535 \n",
            "[4/16] class_loss: 1.8070 s_domain_loss: 0.7737 t_domain_loss: 0.6652 \n",
            "[5/16] class_loss: 1.6931 s_domain_loss: 0.7581 t_domain_loss: 0.6783 \n",
            "[6/16] class_loss: 1.7392 s_domain_loss: 0.7317 t_domain_loss: 0.7122 \n",
            "[7/16] class_loss: 1.6148 s_domain_loss: 0.7131 t_domain_loss: 0.7213 \n",
            "[8/16] class_loss: 1.4805 s_domain_loss: 0.6945 t_domain_loss: 0.7441 \n",
            "[9/16] class_loss: 1.4647 s_domain_loss: 0.6772 t_domain_loss: 0.7557 \n",
            "[10/16] class_loss: 1.3749 s_domain_loss: 0.6666 t_domain_loss: 0.7670 \n",
            "[11/16] class_loss: 1.3563 s_domain_loss: 0.6480 t_domain_loss: 0.7849 \n",
            "[12/16] class_loss: 1.2064 s_domain_loss: 0.6580 t_domain_loss: 0.7852 \n",
            "[13/16] class_loss: 1.2442 s_domain_loss: 0.6542 t_domain_loss: 0.7721 \n",
            "[14/16] class_loss: 1.1739 s_domain_loss: 0.6513 t_domain_loss: 0.7757 \n",
            "[15/16] class_loss: 1.0761 s_domain_loss: 0.6613 t_domain_loss: 0.7771 \n",
            "[16/16] class_loss: 1.1048 s_domain_loss: 0.6661 t_domain_loss: 0.7726 \n",
            "Accuracy on  photo during epoch 0 is 0.6916167664670658 loss is 0.8020463585853577\n",
            "Accuracy on  artPainting during epoch 0 is 0.31640625 loss is 1.7512927055358887\n",
            "[1/16] class_loss: 1.1362 s_domain_loss: 0.6621 t_domain_loss: 0.7587 \n",
            "[2/16] class_loss: 1.0442 s_domain_loss: 0.6755 t_domain_loss: 0.7485 \n",
            "[3/16] class_loss: 0.9187 s_domain_loss: 0.6779 t_domain_loss: 0.7360 \n",
            "[4/16] class_loss: 0.9478 s_domain_loss: 0.6916 t_domain_loss: 0.7259 \n",
            "[5/16] class_loss: 0.9242 s_domain_loss: 0.7060 t_domain_loss: 0.7113 \n",
            "[6/16] class_loss: 0.8915 s_domain_loss: 0.6976 t_domain_loss: 0.7186 \n",
            "[7/16] class_loss: 0.9484 s_domain_loss: 0.7082 t_domain_loss: 0.7026 \n",
            "[8/16] class_loss: 0.7976 s_domain_loss: 0.7248 t_domain_loss: 0.6974 \n",
            "[9/16] class_loss: 0.7505 s_domain_loss: 0.7172 t_domain_loss: 0.6915 \n",
            "[10/16] class_loss: 0.6788 s_domain_loss: 0.7160 t_domain_loss: 0.6893 \n",
            "[11/16] class_loss: 0.8374 s_domain_loss: 0.7200 t_domain_loss: 0.6963 \n",
            "[12/16] class_loss: 0.6725 s_domain_loss: 0.7218 t_domain_loss: 0.6987 \n",
            "[13/16] class_loss: 0.6673 s_domain_loss: 0.7123 t_domain_loss: 0.6938 \n",
            "[14/16] class_loss: 0.3241 s_domain_loss: 0.7055 t_domain_loss: 0.7006 \n",
            "[15/16] class_loss: 0.6739 s_domain_loss: 0.7015 t_domain_loss: 0.7110 \n",
            "[16/16] class_loss: 0.6770 s_domain_loss: 0.6913 t_domain_loss: 0.7194 \n",
            "Accuracy on  photo during epoch 1 is 0.848502994011976 loss is 0.41974547505378723\n",
            "Accuracy on  artPainting during epoch 1 is 0.40283203125 loss is 2.224256992340088\n",
            "[1/16] class_loss: 0.6758 s_domain_loss: 0.6898 t_domain_loss: 0.7202 \n",
            "[2/16] class_loss: 0.6999 s_domain_loss: 0.6811 t_domain_loss: 0.7254 \n",
            "[3/16] class_loss: 0.5819 s_domain_loss: 0.6749 t_domain_loss: 0.7270 \n",
            "[4/16] class_loss: 0.6477 s_domain_loss: 0.6694 t_domain_loss: 0.7300 \n",
            "[5/16] class_loss: 0.5431 s_domain_loss: 0.6627 t_domain_loss: 0.7267 \n",
            "[6/16] class_loss: 0.5608 s_domain_loss: 0.6710 t_domain_loss: 0.7421 \n",
            "[7/16] class_loss: 0.5426 s_domain_loss: 0.6731 t_domain_loss: 0.7323 \n",
            "[8/16] class_loss: 0.4726 s_domain_loss: 0.6752 t_domain_loss: 0.7273 \n",
            "[9/16] class_loss: 0.5027 s_domain_loss: 0.6801 t_domain_loss: 0.7216 \n",
            "[10/16] class_loss: 0.3623 s_domain_loss: 0.6809 t_domain_loss: 0.7164 \n",
            "[11/16] class_loss: 0.5108 s_domain_loss: 0.6814 t_domain_loss: 0.7179 \n",
            "[12/16] class_loss: 0.5187 s_domain_loss: 0.6815 t_domain_loss: 0.7163 \n",
            "[13/16] class_loss: 0.5183 s_domain_loss: 0.6938 t_domain_loss: 0.7062 \n",
            "[14/16] class_loss: 0.4709 s_domain_loss: 0.6763 t_domain_loss: 0.7049 \n",
            "[15/16] class_loss: 0.4951 s_domain_loss: 0.6904 t_domain_loss: 0.7058 \n",
            "[16/16] class_loss: 0.4350 s_domain_loss: 0.6904 t_domain_loss: 0.7063 \n",
            "Accuracy on  photo during epoch 2 is 0.8982035928143712 loss is 0.0800338163971901\n",
            "Accuracy on  artPainting during epoch 2 is 0.43798828125 loss is 2.844489574432373\n",
            "[1/16] class_loss: 0.4101 s_domain_loss: 0.6896 t_domain_loss: 0.7017 \n",
            "[2/16] class_loss: 0.4214 s_domain_loss: 0.6969 t_domain_loss: 0.7013 \n",
            "[3/16] class_loss: 0.5028 s_domain_loss: 0.6911 t_domain_loss: 0.6997 \n",
            "[4/16] class_loss: 0.3539 s_domain_loss: 0.6902 t_domain_loss: 0.7003 \n",
            "[5/16] class_loss: 0.3827 s_domain_loss: 0.6825 t_domain_loss: 0.6972 \n",
            "[6/16] class_loss: 0.4558 s_domain_loss: 0.6865 t_domain_loss: 0.7143 \n",
            "[7/16] class_loss: 0.4146 s_domain_loss: 0.6857 t_domain_loss: 0.7081 \n",
            "[8/16] class_loss: 0.4059 s_domain_loss: 0.6927 t_domain_loss: 0.7059 \n",
            "[9/16] class_loss: 0.3473 s_domain_loss: 0.6823 t_domain_loss: 0.7058 \n",
            "[10/16] class_loss: 0.3546 s_domain_loss: 0.6793 t_domain_loss: 0.7054 \n",
            "[11/16] class_loss: 0.4089 s_domain_loss: 0.6803 t_domain_loss: 0.7101 \n",
            "[12/16] class_loss: 0.3497 s_domain_loss: 0.6778 t_domain_loss: 0.7136 \n",
            "[13/16] class_loss: 0.3298 s_domain_loss: 0.6891 t_domain_loss: 0.7091 \n",
            "[14/16] class_loss: 0.7060 s_domain_loss: 0.6940 t_domain_loss: 0.7098 \n",
            "[15/16] class_loss: 0.2979 s_domain_loss: 0.6810 t_domain_loss: 0.7133 \n",
            "[16/16] class_loss: 0.3154 s_domain_loss: 0.6776 t_domain_loss: 0.7155 \n",
            "Accuracy on  photo during epoch 3 is 0.9263473053892216 loss is 0.09305425733327866\n",
            "Accuracy on  artPainting during epoch 3 is 0.43017578125 loss is 3.364410638809204\n",
            "[1/16] class_loss: 0.3855 s_domain_loss: 0.6746 t_domain_loss: 0.7125 \n",
            "[2/16] class_loss: 0.3782 s_domain_loss: 0.6722 t_domain_loss: 0.7121 \n",
            "[3/16] class_loss: 0.3727 s_domain_loss: 0.6781 t_domain_loss: 0.7091 \n",
            "[4/16] class_loss: 0.3501 s_domain_loss: 0.6812 t_domain_loss: 0.7075 \n",
            "[5/16] class_loss: 0.3070 s_domain_loss: 0.6806 t_domain_loss: 0.7027 \n",
            "[6/16] class_loss: 0.3552 s_domain_loss: 0.6787 t_domain_loss: 0.7171 \n",
            "[7/16] class_loss: 0.2643 s_domain_loss: 0.6760 t_domain_loss: 0.7091 \n",
            "[8/16] class_loss: 0.2541 s_domain_loss: 0.6827 t_domain_loss: 0.7035 \n",
            "[9/16] class_loss: 0.3226 s_domain_loss: 0.6759 t_domain_loss: 0.7010 \n",
            "[10/16] class_loss: 0.3498 s_domain_loss: 0.6872 t_domain_loss: 0.6974 \n",
            "[11/16] class_loss: 0.3053 s_domain_loss: 0.6810 t_domain_loss: 0.7004 \n",
            "[12/16] class_loss: 0.2656 s_domain_loss: 0.6784 t_domain_loss: 0.7026 \n",
            "[13/16] class_loss: 0.2970 s_domain_loss: 0.6837 t_domain_loss: 0.6984 \n",
            "[14/16] class_loss: 0.4519 s_domain_loss: 0.7251 t_domain_loss: 0.6975 \n",
            "[15/16] class_loss: 0.3227 s_domain_loss: 0.6845 t_domain_loss: 0.7019 \n",
            "[16/16] class_loss: 0.2675 s_domain_loss: 0.6703 t_domain_loss: 0.7048 \n",
            "Accuracy on  photo during epoch 4 is 0.937125748502994 loss is 0.17974965274333954\n",
            "Accuracy on  artPainting during epoch 4 is 0.4296875 loss is 3.7303075790405273\n",
            "[1/16] class_loss: 0.3441 s_domain_loss: 0.6835 t_domain_loss: 0.7029 \n",
            "[2/16] class_loss: 0.2708 s_domain_loss: 0.6767 t_domain_loss: 0.7037 \n",
            "[3/16] class_loss: 0.3249 s_domain_loss: 0.6807 t_domain_loss: 0.7024 \n",
            "[4/16] class_loss: 0.3325 s_domain_loss: 0.6805 t_domain_loss: 0.7019 \n",
            "[5/16] class_loss: 0.1972 s_domain_loss: 0.6714 t_domain_loss: 0.6988 \n",
            "[6/16] class_loss: 0.2006 s_domain_loss: 0.6705 t_domain_loss: 0.7146 \n",
            "[7/16] class_loss: 0.2161 s_domain_loss: 0.6715 t_domain_loss: 0.7074 \n",
            "[8/16] class_loss: 0.2818 s_domain_loss: 0.6703 t_domain_loss: 0.7020 \n",
            "[9/16] class_loss: 0.2204 s_domain_loss: 0.6653 t_domain_loss: 0.7001 \n",
            "[10/16] class_loss: 0.2864 s_domain_loss: 0.6739 t_domain_loss: 0.6972 \n",
            "[11/16] class_loss: 0.2227 s_domain_loss: 0.6848 t_domain_loss: 0.6982 \n",
            "[12/16] class_loss: 0.2815 s_domain_loss: 0.6844 t_domain_loss: 0.7005 \n",
            "[13/16] class_loss: 0.3471 s_domain_loss: 0.6797 t_domain_loss: 0.6980 \n",
            "[14/16] class_loss: 0.5510 s_domain_loss: 0.7266 t_domain_loss: 0.6956 \n",
            "[15/16] class_loss: 0.2312 s_domain_loss: 0.6775 t_domain_loss: 0.7006 \n",
            "[16/16] class_loss: 0.2666 s_domain_loss: 0.6749 t_domain_loss: 0.7029 \n",
            "Accuracy on  photo during epoch 5 is 0.9401197604790419 loss is 0.12450007349252701\n",
            "Accuracy on  artPainting during epoch 5 is 0.44775390625 loss is 4.000458240509033\n",
            "[1/16] class_loss: 0.1922 s_domain_loss: 0.6771 t_domain_loss: 0.7007 \n",
            "[2/16] class_loss: 0.1705 s_domain_loss: 0.6629 t_domain_loss: 0.7015 \n",
            "[3/16] class_loss: 0.3042 s_domain_loss: 0.6758 t_domain_loss: 0.6998 \n",
            "[4/16] class_loss: 0.2951 s_domain_loss: 0.6703 t_domain_loss: 0.6988 \n",
            "[5/16] class_loss: 0.2515 s_domain_loss: 0.6609 t_domain_loss: 0.6953 \n",
            "[6/16] class_loss: 0.2155 s_domain_loss: 0.6679 t_domain_loss: 0.7104 \n",
            "[7/16] class_loss: 0.2240 s_domain_loss: 0.6660 t_domain_loss: 0.7023 \n",
            "[8/16] class_loss: 0.2731 s_domain_loss: 0.6755 t_domain_loss: 0.6971 \n",
            "[9/16] class_loss: 0.3346 s_domain_loss: 0.6858 t_domain_loss: 0.6951 \n",
            "[10/16] class_loss: 0.2594 s_domain_loss: 0.6802 t_domain_loss: 0.6937 \n",
            "[11/16] class_loss: 0.2538 s_domain_loss: 0.6817 t_domain_loss: 0.6946 \n",
            "[12/16] class_loss: 0.2153 s_domain_loss: 0.6789 t_domain_loss: 0.6976 \n",
            "[13/16] class_loss: 0.2148 s_domain_loss: 0.6728 t_domain_loss: 0.6963 \n",
            "[14/16] class_loss: 0.3210 s_domain_loss: 0.7025 t_domain_loss: 0.6940 \n",
            "[15/16] class_loss: 0.2624 s_domain_loss: 0.6675 t_domain_loss: 0.6975 \n",
            "[16/16] class_loss: 0.1904 s_domain_loss: 0.6780 t_domain_loss: 0.6982 \n",
            "Accuracy on  photo during epoch 6 is 0.9473053892215569 loss is 0.09090606123209\n",
            "Accuracy on  artPainting during epoch 6 is 0.45703125 loss is 4.159281253814697\n",
            "[1/16] class_loss: 0.1633 s_domain_loss: 0.6731 t_domain_loss: 0.6954 \n",
            "[2/16] class_loss: 0.2770 s_domain_loss: 0.6715 t_domain_loss: 0.6956 \n",
            "[3/16] class_loss: 0.1917 s_domain_loss: 0.6774 t_domain_loss: 0.6932 \n",
            "[4/16] class_loss: 0.1619 s_domain_loss: 0.6817 t_domain_loss: 0.6921 \n",
            "[5/16] class_loss: 0.2495 s_domain_loss: 0.6651 t_domain_loss: 0.6893 \n",
            "[6/16] class_loss: 0.2610 s_domain_loss: 0.6695 t_domain_loss: 0.7045 \n",
            "[7/16] class_loss: 0.2202 s_domain_loss: 0.6735 t_domain_loss: 0.6975 \n",
            "[8/16] class_loss: 0.1823 s_domain_loss: 0.6772 t_domain_loss: 0.6940 \n",
            "[9/16] class_loss: 0.2489 s_domain_loss: 0.6604 t_domain_loss: 0.6930 \n",
            "[10/16] class_loss: 0.2875 s_domain_loss: 0.6640 t_domain_loss: 0.6922 \n",
            "[11/16] class_loss: 0.2238 s_domain_loss: 0.6723 t_domain_loss: 0.6930 \n",
            "[12/16] class_loss: 0.1946 s_domain_loss: 0.6708 t_domain_loss: 0.6960 \n",
            "[13/16] class_loss: 0.2443 s_domain_loss: 0.6749 t_domain_loss: 0.6948 \n",
            "[14/16] class_loss: 0.0964 s_domain_loss: 0.6887 t_domain_loss: 0.6918 \n",
            "[15/16] class_loss: 0.1653 s_domain_loss: 0.6696 t_domain_loss: 0.6939 \n",
            "[16/16] class_loss: 0.2374 s_domain_loss: 0.6754 t_domain_loss: 0.6941 \n",
            "Accuracy on  photo during epoch 7 is 0.9520958083832335 loss is 0.13684861361980438\n",
            "Accuracy on  artPainting during epoch 7 is 0.4580078125 loss is 4.2640180587768555\n",
            "[1/16] class_loss: 0.1510 s_domain_loss: 0.6704 t_domain_loss: 0.6909 \n",
            "[2/16] class_loss: 0.2443 s_domain_loss: 0.6741 t_domain_loss: 0.6909 \n",
            "[3/16] class_loss: 0.2198 s_domain_loss: 0.6758 t_domain_loss: 0.6879 \n",
            "[4/16] class_loss: 0.2061 s_domain_loss: 0.6606 t_domain_loss: 0.6867 \n",
            "[5/16] class_loss: 0.1972 s_domain_loss: 0.6722 t_domain_loss: 0.6840 \n",
            "[6/16] class_loss: 0.1952 s_domain_loss: 0.6678 t_domain_loss: 0.6981 \n",
            "[7/16] class_loss: 0.2106 s_domain_loss: 0.6750 t_domain_loss: 0.6916 \n",
            "[8/16] class_loss: 0.1385 s_domain_loss: 0.6677 t_domain_loss: 0.6877 \n",
            "[9/16] class_loss: 0.2370 s_domain_loss: 0.6838 t_domain_loss: 0.6874 \n",
            "[10/16] class_loss: 0.1892 s_domain_loss: 0.6740 t_domain_loss: 0.6876 \n",
            "[11/16] class_loss: 0.1574 s_domain_loss: 0.6712 t_domain_loss: 0.6899 \n",
            "[12/16] class_loss: 0.1419 s_domain_loss: 0.6606 t_domain_loss: 0.6944 \n",
            "[13/16] class_loss: 0.2205 s_domain_loss: 0.6736 t_domain_loss: 0.6941 \n",
            "[14/16] class_loss: 0.0132 s_domain_loss: 0.7698 t_domain_loss: 0.6918 \n",
            "[15/16] class_loss: 0.2547 s_domain_loss: 0.6722 t_domain_loss: 0.6924 \n",
            "[16/16] class_loss: 0.2154 s_domain_loss: 0.6664 t_domain_loss: 0.6923 \n",
            "Accuracy on  photo during epoch 8 is 0.9586826347305389 loss is 0.5308830142021179\n",
            "Accuracy on  artPainting during epoch 8 is 0.46240234375 loss is 4.356412410736084\n",
            "[1/16] class_loss: 0.1749 s_domain_loss: 0.6704 t_domain_loss: 0.6887 \n",
            "[2/16] class_loss: 0.1454 s_domain_loss: 0.6721 t_domain_loss: 0.6887 \n",
            "[3/16] class_loss: 0.2105 s_domain_loss: 0.6680 t_domain_loss: 0.6846 \n",
            "[4/16] class_loss: 0.1553 s_domain_loss: 0.6606 t_domain_loss: 0.6829 \n",
            "[5/16] class_loss: 0.1969 s_domain_loss: 0.6774 t_domain_loss: 0.6798 \n",
            "[6/16] class_loss: 0.2313 s_domain_loss: 0.6738 t_domain_loss: 0.6929 \n",
            "[7/16] class_loss: 0.1428 s_domain_loss: 0.6670 t_domain_loss: 0.6866 \n",
            "[8/16] class_loss: 0.2289 s_domain_loss: 0.6697 t_domain_loss: 0.6819 \n",
            "[9/16] class_loss: 0.1782 s_domain_loss: 0.6840 t_domain_loss: 0.6826 \n",
            "[10/16] class_loss: 0.2212 s_domain_loss: 0.6678 t_domain_loss: 0.6826 \n",
            "[11/16] class_loss: 0.0962 s_domain_loss: 0.6700 t_domain_loss: 0.6849 \n",
            "[12/16] class_loss: 0.2049 s_domain_loss: 0.6675 t_domain_loss: 0.6904 \n",
            "[13/16] class_loss: 0.1657 s_domain_loss: 0.6652 t_domain_loss: 0.6915 \n",
            "[14/16] class_loss: 0.2454 s_domain_loss: 0.7017 t_domain_loss: 0.6895 \n",
            "[15/16] class_loss: 0.1681 s_domain_loss: 0.6705 t_domain_loss: 0.6929 \n",
            "[16/16] class_loss: 0.1554 s_domain_loss: 0.6623 t_domain_loss: 0.6953 \n",
            "Accuracy on  photo during epoch 9 is 0.9604790419161676 loss is 0.03510872647166252\n",
            "Accuracy on  artPainting during epoch 9 is 0.46630859375 loss is 4.450251579284668\n",
            "[1/16] class_loss: 0.1590 s_domain_loss: 0.6624 t_domain_loss: 0.6939 \n",
            "[2/16] class_loss: 0.1753 s_domain_loss: 0.6650 t_domain_loss: 0.6958 \n",
            "[3/16] class_loss: 0.1585 s_domain_loss: 0.6559 t_domain_loss: 0.6923 \n",
            "[4/16] class_loss: 0.2340 s_domain_loss: 0.6600 t_domain_loss: 0.6907 \n",
            "[5/16] class_loss: 0.1899 s_domain_loss: 0.6588 t_domain_loss: 0.6879 \n",
            "[6/16] class_loss: 0.2039 s_domain_loss: 0.6570 t_domain_loss: 0.6994 \n",
            "[7/16] class_loss: 0.1670 s_domain_loss: 0.6546 t_domain_loss: 0.6918 \n",
            "[8/16] class_loss: 0.1796 s_domain_loss: 0.6650 t_domain_loss: 0.6839 \n",
            "[9/16] class_loss: 0.1761 s_domain_loss: 0.6564 t_domain_loss: 0.6829 \n",
            "[10/16] class_loss: 0.1441 s_domain_loss: 0.6689 t_domain_loss: 0.6795 \n",
            "[11/16] class_loss: 0.1356 s_domain_loss: 0.6687 t_domain_loss: 0.6793 \n",
            "[12/16] class_loss: 0.1311 s_domain_loss: 0.6624 t_domain_loss: 0.6829 \n",
            "[13/16] class_loss: 0.1723 s_domain_loss: 0.6789 t_domain_loss: 0.6831 \n",
            "[14/16] class_loss: 0.1783 s_domain_loss: 0.7267 t_domain_loss: 0.6801 \n",
            "[15/16] class_loss: 0.1250 s_domain_loss: 0.6754 t_domain_loss: 0.6838 \n",
            "[16/16] class_loss: 0.1699 s_domain_loss: 0.6685 t_domain_loss: 0.6872 \n",
            "Accuracy on  photo during epoch 10 is 0.9634730538922156 loss is 0.0790647640824318\n",
            "Accuracy on  artPainting during epoch 10 is 0.46533203125 loss is 4.459039211273193\n",
            "[1/16] class_loss: 0.1167 s_domain_loss: 0.6658 t_domain_loss: 0.6871 \n",
            "[2/16] class_loss: 0.1636 s_domain_loss: 0.6515 t_domain_loss: 0.6906 \n",
            "[3/16] class_loss: 0.1519 s_domain_loss: 0.6576 t_domain_loss: 0.6881 \n",
            "[4/16] class_loss: 0.1585 s_domain_loss: 0.6484 t_domain_loss: 0.6877 \n",
            "[5/16] class_loss: 0.1302 s_domain_loss: 0.6553 t_domain_loss: 0.6864 \n",
            "[6/16] class_loss: 0.1577 s_domain_loss: 0.6478 t_domain_loss: 0.6982 \n",
            "[7/16] class_loss: 0.1252 s_domain_loss: 0.6573 t_domain_loss: 0.6918 \n",
            "[8/16] class_loss: 0.1330 s_domain_loss: 0.6673 t_domain_loss: 0.6840 \n",
            "[9/16] class_loss: 0.1541 s_domain_loss: 0.6657 t_domain_loss: 0.6841 \n",
            "[10/16] class_loss: 0.1536 s_domain_loss: 0.6533 t_domain_loss: 0.6815 \n",
            "[11/16] class_loss: 0.2206 s_domain_loss: 0.6625 t_domain_loss: 0.6813 \n",
            "[12/16] class_loss: 0.1864 s_domain_loss: 0.6689 t_domain_loss: 0.6844 \n",
            "[13/16] class_loss: 0.1587 s_domain_loss: 0.6597 t_domain_loss: 0.6836 \n",
            "[14/16] class_loss: 0.0067 s_domain_loss: 0.7111 t_domain_loss: 0.6800 \n",
            "[15/16] class_loss: 0.1563 s_domain_loss: 0.6624 t_domain_loss: 0.6799 \n",
            "[16/16] class_loss: 0.2056 s_domain_loss: 0.6751 t_domain_loss: 0.6797 \n",
            "Accuracy on  photo during epoch 11 is 0.9670658682634731 loss is 0.046872932463884354\n",
            "Accuracy on  artPainting during epoch 11 is 0.47119140625 loss is 4.483852863311768\n",
            "[1/16] class_loss: 0.2056 s_domain_loss: 0.6717 t_domain_loss: 0.6760 \n",
            "[2/16] class_loss: 0.1402 s_domain_loss: 0.6604 t_domain_loss: 0.6769 \n",
            "[3/16] class_loss: 0.1716 s_domain_loss: 0.6673 t_domain_loss: 0.6726 \n",
            "[4/16] class_loss: 0.1267 s_domain_loss: 0.6690 t_domain_loss: 0.6717 \n",
            "[5/16] class_loss: 0.0869 s_domain_loss: 0.6559 t_domain_loss: 0.6713 \n",
            "[6/16] class_loss: 0.1411 s_domain_loss: 0.6797 t_domain_loss: 0.6839 \n",
            "[7/16] class_loss: 0.1651 s_domain_loss: 0.6589 t_domain_loss: 0.6801 \n",
            "[8/16] class_loss: 0.2086 s_domain_loss: 0.6685 t_domain_loss: 0.6751 \n",
            "[9/16] class_loss: 0.1331 s_domain_loss: 0.6571 t_domain_loss: 0.6782 \n",
            "[10/16] class_loss: 0.1048 s_domain_loss: 0.6512 t_domain_loss: 0.6783 \n",
            "[11/16] class_loss: 0.1692 s_domain_loss: 0.6544 t_domain_loss: 0.6805 \n",
            "[12/16] class_loss: 0.1317 s_domain_loss: 0.6523 t_domain_loss: 0.6859 \n",
            "[13/16] class_loss: 0.1746 s_domain_loss: 0.6575 t_domain_loss: 0.6867 \n",
            "[14/16] class_loss: 0.2471 s_domain_loss: 0.7237 t_domain_loss: 0.6843 \n",
            "[15/16] class_loss: 0.1195 s_domain_loss: 0.6593 t_domain_loss: 0.6860 \n",
            "[16/16] class_loss: 0.1601 s_domain_loss: 0.6684 t_domain_loss: 0.6868 \n",
            "Accuracy on  photo during epoch 12 is 0.9682634730538923 loss is 0.047950029373168945\n",
            "Accuracy on  artPainting during epoch 12 is 0.47021484375 loss is 4.579713821411133\n",
            "[1/16] class_loss: 0.0891 s_domain_loss: 0.6505 t_domain_loss: 0.6844 \n",
            "[2/16] class_loss: 0.2033 s_domain_loss: 0.6610 t_domain_loss: 0.6856 \n",
            "[3/16] class_loss: 0.1539 s_domain_loss: 0.6483 t_domain_loss: 0.6808 \n",
            "[4/16] class_loss: 0.2007 s_domain_loss: 0.6440 t_domain_loss: 0.6794 \n",
            "[5/16] class_loss: 0.1948 s_domain_loss: 0.6651 t_domain_loss: 0.6768 \n",
            "[6/16] class_loss: 0.1954 s_domain_loss: 0.6565 t_domain_loss: 0.6875 \n",
            "[7/16] class_loss: 0.0969 s_domain_loss: 0.6497 t_domain_loss: 0.6815 \n",
            "[8/16] class_loss: 0.1117 s_domain_loss: 0.6502 t_domain_loss: 0.6735 \n",
            "[9/16] class_loss: 0.0985 s_domain_loss: 0.6579 t_domain_loss: 0.6742 \n",
            "[10/16] class_loss: 0.1602 s_domain_loss: 0.6548 t_domain_loss: 0.6718 \n",
            "[11/16] class_loss: 0.1483 s_domain_loss: 0.6642 t_domain_loss: 0.6713 \n",
            "[12/16] class_loss: 0.1299 s_domain_loss: 0.6822 t_domain_loss: 0.6758 \n",
            "[13/16] class_loss: 0.1116 s_domain_loss: 0.6523 t_domain_loss: 0.6774 \n",
            "[14/16] class_loss: 0.0081 s_domain_loss: 0.6819 t_domain_loss: 0.6748 \n",
            "[15/16] class_loss: 0.1366 s_domain_loss: 0.6554 t_domain_loss: 0.6757 \n",
            "[16/16] class_loss: 0.1504 s_domain_loss: 0.6735 t_domain_loss: 0.6762 \n",
            "Accuracy on  photo during epoch 13 is 0.9694610778443113 loss is 0.3169194757938385\n",
            "Accuracy on  artPainting during epoch 13 is 0.4697265625 loss is 4.695221900939941\n",
            "[1/16] class_loss: 0.1274 s_domain_loss: 0.6633 t_domain_loss: 0.6739 \n",
            "[2/16] class_loss: 0.1750 s_domain_loss: 0.6546 t_domain_loss: 0.6760 \n",
            "[3/16] class_loss: 0.0960 s_domain_loss: 0.6568 t_domain_loss: 0.6717 \n",
            "[4/16] class_loss: 0.1316 s_domain_loss: 0.6605 t_domain_loss: 0.6721 \n",
            "[5/16] class_loss: 0.0967 s_domain_loss: 0.6554 t_domain_loss: 0.6716 \n",
            "[6/16] class_loss: 0.1005 s_domain_loss: 0.6414 t_domain_loss: 0.6838 \n",
            "[7/16] class_loss: 0.1432 s_domain_loss: 0.6478 t_domain_loss: 0.6793 \n",
            "[8/16] class_loss: 0.1396 s_domain_loss: 0.6463 t_domain_loss: 0.6722 \n",
            "[9/16] class_loss: 0.1440 s_domain_loss: 0.6506 t_domain_loss: 0.6736 \n",
            "[10/16] class_loss: 0.1479 s_domain_loss: 0.6622 t_domain_loss: 0.6720 \n",
            "[11/16] class_loss: 0.1450 s_domain_loss: 0.6540 t_domain_loss: 0.6719 \n",
            "[12/16] class_loss: 0.1938 s_domain_loss: 0.6629 t_domain_loss: 0.6766 \n",
            "[13/16] class_loss: 0.1616 s_domain_loss: 0.6464 t_domain_loss: 0.6786 \n",
            "[14/16] class_loss: 0.0572 s_domain_loss: 0.7449 t_domain_loss: 0.6756 \n",
            "[15/16] class_loss: 0.1294 s_domain_loss: 0.6631 t_domain_loss: 0.6770 \n",
            "[16/16] class_loss: 0.1235 s_domain_loss: 0.6585 t_domain_loss: 0.6786 \n",
            "Accuracy on  photo during epoch 14 is 0.9718562874251497 loss is 0.35800397396087646\n",
            "Accuracy on  artPainting during epoch 14 is 0.47412109375 loss is 4.792590618133545\n",
            "[1/16] class_loss: 0.1169 s_domain_loss: 0.6563 t_domain_loss: 0.6773 \n",
            "[2/16] class_loss: 0.1785 s_domain_loss: 0.6547 t_domain_loss: 0.6791 \n",
            "[3/16] class_loss: 0.1361 s_domain_loss: 0.6431 t_domain_loss: 0.6746 \n",
            "[4/16] class_loss: 0.1294 s_domain_loss: 0.6484 t_domain_loss: 0.6742 \n",
            "[5/16] class_loss: 0.1313 s_domain_loss: 0.6522 t_domain_loss: 0.6726 \n",
            "[6/16] class_loss: 0.0881 s_domain_loss: 0.6432 t_domain_loss: 0.6830 \n",
            "[7/16] class_loss: 0.1135 s_domain_loss: 0.6507 t_domain_loss: 0.6770 \n",
            "[8/16] class_loss: 0.1711 s_domain_loss: 0.6454 t_domain_loss: 0.6688 \n",
            "[9/16] class_loss: 0.1742 s_domain_loss: 0.6538 t_domain_loss: 0.6692 \n",
            "[10/16] class_loss: 0.1032 s_domain_loss: 0.6664 t_domain_loss: 0.6670 \n",
            "[11/16] class_loss: 0.1184 s_domain_loss: 0.6457 t_domain_loss: 0.6666 \n",
            "[12/16] class_loss: 0.1079 s_domain_loss: 0.6661 t_domain_loss: 0.6709 \n",
            "[13/16] class_loss: 0.0813 s_domain_loss: 0.6463 t_domain_loss: 0.6729 \n",
            "[14/16] class_loss: 0.4430 s_domain_loss: 0.6536 t_domain_loss: 0.6707 \n",
            "[15/16] class_loss: 0.1182 s_domain_loss: 0.6570 t_domain_loss: 0.6709 \n",
            "[16/16] class_loss: 0.1785 s_domain_loss: 0.6655 t_domain_loss: 0.6713 \n",
            "Accuracy on  photo during epoch 15 is 0.9736526946107784 loss is 0.029257139191031456\n",
            "Accuracy on  artPainting during epoch 15 is 0.474609375 loss is 4.878286361694336\n",
            "[1/16] class_loss: 0.0951 s_domain_loss: 0.6441 t_domain_loss: 0.6698 \n",
            "[2/16] class_loss: 0.0875 s_domain_loss: 0.6499 t_domain_loss: 0.6713 \n",
            "[3/16] class_loss: 0.1588 s_domain_loss: 0.6617 t_domain_loss: 0.6664 \n",
            "[4/16] class_loss: 0.1363 s_domain_loss: 0.6455 t_domain_loss: 0.6662 \n",
            "[5/16] class_loss: 0.1304 s_domain_loss: 0.6594 t_domain_loss: 0.6656 \n",
            "[6/16] class_loss: 0.0934 s_domain_loss: 0.6430 t_domain_loss: 0.6778 \n",
            "[7/16] class_loss: 0.1425 s_domain_loss: 0.6582 t_domain_loss: 0.6729 \n",
            "[8/16] class_loss: 0.1263 s_domain_loss: 0.6509 t_domain_loss: 0.6663 \n",
            "[9/16] class_loss: 0.1349 s_domain_loss: 0.6476 t_domain_loss: 0.6690 \n",
            "[10/16] class_loss: 0.1791 s_domain_loss: 0.6352 t_domain_loss: 0.6687 \n",
            "[11/16] class_loss: 0.1125 s_domain_loss: 0.6512 t_domain_loss: 0.6674 \n",
            "[12/16] class_loss: 0.1011 s_domain_loss: 0.6423 t_domain_loss: 0.6725 \n",
            "[13/16] class_loss: 0.1110 s_domain_loss: 0.6703 t_domain_loss: 0.6755 \n",
            "[14/16] class_loss: 0.1449 s_domain_loss: 0.6737 t_domain_loss: 0.6726 \n",
            "[15/16] class_loss: 0.1250 s_domain_loss: 0.6374 t_domain_loss: 0.6716 \n",
            "[16/16] class_loss: 0.0833 s_domain_loss: 0.6460 t_domain_loss: 0.6701 \n",
            "Accuracy on  photo during epoch 16 is 0.974251497005988 loss is 0.2501799166202545\n",
            "Accuracy on  artPainting during epoch 16 is 0.46533203125 loss is 4.950573921203613\n",
            "[1/16] class_loss: 0.1305 s_domain_loss: 0.6512 t_domain_loss: 0.6672 \n",
            "[2/16] class_loss: 0.1584 s_domain_loss: 0.6716 t_domain_loss: 0.6674 \n",
            "[3/16] class_loss: 0.1142 s_domain_loss: 0.6454 t_domain_loss: 0.6619 \n",
            "[4/16] class_loss: 0.0749 s_domain_loss: 0.6525 t_domain_loss: 0.6602 \n",
            "[5/16] class_loss: 0.1159 s_domain_loss: 0.6278 t_domain_loss: 0.6595 \n",
            "[6/16] class_loss: 0.1498 s_domain_loss: 0.6681 t_domain_loss: 0.6708 \n",
            "[7/16] class_loss: 0.1510 s_domain_loss: 0.6450 t_domain_loss: 0.6657 \n",
            "[8/16] class_loss: 0.1416 s_domain_loss: 0.6454 t_domain_loss: 0.6593 \n",
            "[9/16] class_loss: 0.1708 s_domain_loss: 0.6513 t_domain_loss: 0.6615 \n",
            "[10/16] class_loss: 0.0958 s_domain_loss: 0.6529 t_domain_loss: 0.6616 \n",
            "[11/16] class_loss: 0.1298 s_domain_loss: 0.6538 t_domain_loss: 0.6612 \n",
            "[12/16] class_loss: 0.1534 s_domain_loss: 0.6473 t_domain_loss: 0.6675 \n",
            "[13/16] class_loss: 0.1069 s_domain_loss: 0.6400 t_domain_loss: 0.6715 \n",
            "[14/16] class_loss: 0.1361 s_domain_loss: 0.6963 t_domain_loss: 0.6706 \n",
            "[15/16] class_loss: 0.1031 s_domain_loss: 0.6523 t_domain_loss: 0.6703 \n",
            "[16/16] class_loss: 0.1277 s_domain_loss: 0.6365 t_domain_loss: 0.6709 \n",
            "Accuracy on  photo during epoch 17 is 0.9802395209580839 loss is 0.0015951792011037469\n",
            "Accuracy on  artPainting during epoch 17 is 0.4716796875 loss is 4.9762797355651855\n",
            "[1/16] class_loss: 0.1229 s_domain_loss: 0.6215 t_domain_loss: 0.6695 \n",
            "[2/16] class_loss: 0.0990 s_domain_loss: 0.6650 t_domain_loss: 0.6698 \n",
            "[3/16] class_loss: 0.1301 s_domain_loss: 0.6424 t_domain_loss: 0.6644 \n",
            "[4/16] class_loss: 0.1429 s_domain_loss: 0.6473 t_domain_loss: 0.6624 \n",
            "[5/16] class_loss: 0.0957 s_domain_loss: 0.6442 t_domain_loss: 0.6617 \n",
            "[6/16] class_loss: 0.1448 s_domain_loss: 0.6371 t_domain_loss: 0.6726 \n",
            "[7/16] class_loss: 0.1628 s_domain_loss: 0.6367 t_domain_loss: 0.6668 \n",
            "[8/16] class_loss: 0.1257 s_domain_loss: 0.6503 t_domain_loss: 0.6591 \n",
            "[9/16] class_loss: 0.1205 s_domain_loss: 0.6538 t_domain_loss: 0.6609 \n",
            "[10/16] class_loss: 0.1377 s_domain_loss: 0.6584 t_domain_loss: 0.6603 \n",
            "[11/16] class_loss: 0.1457 s_domain_loss: 0.6437 t_domain_loss: 0.6601 \n",
            "[12/16] class_loss: 0.1280 s_domain_loss: 0.6599 t_domain_loss: 0.6661 \n",
            "[13/16] class_loss: 0.0845 s_domain_loss: 0.6263 t_domain_loss: 0.6696 \n",
            "[14/16] class_loss: 0.0353 s_domain_loss: 0.7103 t_domain_loss: 0.6682 \n",
            "[15/16] class_loss: 0.1884 s_domain_loss: 0.6712 t_domain_loss: 0.6668 \n",
            "[16/16] class_loss: 0.1177 s_domain_loss: 0.6527 t_domain_loss: 0.6680 \n",
            "Accuracy on  photo during epoch 18 is 0.9802395209580839 loss is 0.04800860211253166\n",
            "Accuracy on  artPainting during epoch 18 is 0.47802734375 loss is 4.994953155517578\n",
            "[1/16] class_loss: 0.1632 s_domain_loss: 0.6538 t_domain_loss: 0.6667 \n",
            "[2/16] class_loss: 0.1481 s_domain_loss: 0.6200 t_domain_loss: 0.6673 \n",
            "[3/16] class_loss: 0.1019 s_domain_loss: 0.6356 t_domain_loss: 0.6619 \n",
            "[4/16] class_loss: 0.0832 s_domain_loss: 0.6343 t_domain_loss: 0.6600 \n",
            "[5/16] class_loss: 0.1178 s_domain_loss: 0.6478 t_domain_loss: 0.6596 \n",
            "[6/16] class_loss: 0.0985 s_domain_loss: 0.6518 t_domain_loss: 0.6706 \n",
            "[7/16] class_loss: 0.0667 s_domain_loss: 0.6391 t_domain_loss: 0.6659 \n",
            "[8/16] class_loss: 0.1448 s_domain_loss: 0.6641 t_domain_loss: 0.6590 \n",
            "[9/16] class_loss: 0.0952 s_domain_loss: 0.6334 t_domain_loss: 0.6622 \n",
            "[10/16] class_loss: 0.1411 s_domain_loss: 0.6578 t_domain_loss: 0.6619 \n",
            "[11/16] class_loss: 0.0758 s_domain_loss: 0.6353 t_domain_loss: 0.6618 \n",
            "[12/16] class_loss: 0.1086 s_domain_loss: 0.6449 t_domain_loss: 0.6681 \n",
            "[13/16] class_loss: 0.1014 s_domain_loss: 0.6350 t_domain_loss: 0.6720 \n",
            "[14/16] class_loss: 0.0289 s_domain_loss: 0.7121 t_domain_loss: 0.6717 \n",
            "[15/16] class_loss: 0.1284 s_domain_loss: 0.6576 t_domain_loss: 0.6688 \n",
            "[16/16] class_loss: 0.1370 s_domain_loss: 0.6501 t_domain_loss: 0.6684 \n",
            "Accuracy on  photo during epoch 19 is 0.9802395209580839 loss is 0.03746096417307854\n",
            "Accuracy on  artPainting during epoch 19 is 0.4775390625 loss is 5.010908603668213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu1dmt7k_W1P",
        "colab_type": "code",
        "outputId": "81c972c4-8de2-4fc1-9716-516000f81b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u01ZFqgWF4zG",
        "colab_type": "code",
        "outputId": "f296d264-885b-4818-84d7-aebe5285bc98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alfa"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}