{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDL - Homework3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3b9b6f24a3a403db96706d43772b903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d71a261685de4cfba9f9cbb87495d237",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6e4808094a714d95a5119cfef2529f12",
              "IPY_MODEL_e3c16456f1bc446882b84a3ee187b19b"
            ]
          }
        },
        "d71a261685de4cfba9f9cbb87495d237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e4808094a714d95a5119cfef2529f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0cb157bdbeb948c58ee2dbc3bc948dd9",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244418560,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244418560,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_612a8e18ff0d4d398f5572ff2d46c5be"
          }
        },
        "e3c16456f1bc446882b84a3ee187b19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4f290b8052a84c5c8f2bc473202d264a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [01:34&lt;00:00, 2.58MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3b3cc96859942cfae2a1c5aa3b5cafd"
          }
        },
        "0cb157bdbeb948c58ee2dbc3bc948dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "612a8e18ff0d4d398f5572ff2d46c5be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f290b8052a84c5c8f2bc473202d264a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3b3cc96859942cfae2a1c5aa3b5cafd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luciainnocenti/Homework3-PACS/blob/master/MLDL_Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "#**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "from numpy import random \n",
        "\n",
        "random.seed(33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "#**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "\n",
        "BATCH_SIZE = 128     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 20      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "alfa = 0.01\n",
        "LR = 1e-4          # The initial Learning Rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "#**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
        "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
        "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
        "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
        "                                      #transforms.RandomCrop( 64 , padding =2) ,\n",
        "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n",
        "])\n",
        "# Define transforms for the test phase\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "#**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "outputId": "fad6c655-3111-4302-ce3a-caca1a007e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "# Clone github repository with data\n",
        "!git clone https://github.com/luciainnocenti/Homework3-PACS.git\n",
        "!mv 'Homework3-PACS' 'HW_PACS'\n",
        "\n",
        "from HW_PACS.dataset import PACS_Dataset \n",
        "\n",
        "rootPhoto = \"HW_PACS/PACS/photo\"\n",
        "photos = PACS_Dataset(root = rootPhoto, transform = train_transform)\n",
        "\n",
        "rootArt_painting = \"HW_PACS/PACS/art_painting\"\n",
        "art_painting = PACS_Dataset(root = rootArt_painting, transform = test_transform)\n",
        "\n",
        "# Check dataset sizes\n",
        "print('Train Dataset: {}'.format(len(photos)))\n",
        "print('Test Dataset: {}'.format(len(art_painting)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Homework3-PACS'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 10096 (delta 37), reused 0 (delta 0), pack-reused 10032\u001b[K\n",
            "Receiving objects: 100% (10096/10096), 174.17 MiB | 12.45 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n",
            "Checking out files: 100% (9995/9995), done.\n",
            "Train Dataset: 1670\n",
            "Test Dataset: 2048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "#**Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "#**Model without DANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "##**Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUjtXa22DN",
        "colab_type": "code",
        "outputId": "96f06964-4e10-490e-9023-26528aa67fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e3b9b6f24a3a403db96706d43772b903",
            "d71a261685de4cfba9f9cbb87495d237",
            "6e4808094a714d95a5119cfef2529f12",
            "e3c16456f1bc446882b84a3ee187b19b",
            "0cb157bdbeb948c58ee2dbc3bc948dd9",
            "612a8e18ff0d4d398f5572ff2d46c5be",
            "4f290b8052a84c5c8f2bc473202d264a",
            "b3b3cc96859942cfae2a1c5aa3b5cafd"
          ]
        }
      },
      "source": [
        "from HW_PACS.gradient_reversal_example import alexNetDA \n",
        "\n",
        "net = alexNetDA(num_classes = 7)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3b9b6f24a3a403db96706d43772b903",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "##**Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "# Choose parameters to optimize\n",
        "# To access a different set of parameters, you have to access submodules of AlexNet\n",
        "# (nn.Module objects, like AlexNet, implement the Composite Pattern)\n",
        "# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n",
        "# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n",
        "parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n",
        "\n",
        "# Define optimizer\n",
        "# An optimizer updates the weights based on loss\n",
        "# We use SGD with momentum\n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "#optimizer = optim.Adam(parameters_to_optimize, LR)\n",
        "\n",
        "# Define scheduler\n",
        "# A scheduler dynamically changes learning rate\n",
        "# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "outputId": "fa662f34-53c6-412d-da8a-a6ce3e484bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "running_corrects = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "# Iterate over the dataset\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  scheduler.step() \n",
        "  \n",
        "  for images, labels in  tqdm(photos_dataloader):\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(photos))\n",
        "  print(\"Accuracy on training set = \"  + str(accuracy))\n",
        "  running_corrects = 0\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "  7%|▋         | 1/14 [00:02<00:31,  2.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 1.7945976257324219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 12/14 [00:06<00:00,  2.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 10, Loss 1.3648267984390259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.15it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.47784431137724553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 7/14 [00:04<00:04,  1.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 20, Loss 0.9640223383903503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.31it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.7341317365269461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:08,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 30, Loss 0.6081467866897583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.13it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 40, Loss 0.5478993058204651\n",
            "Accuracy on training set = 0.829940119760479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:02,  1.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 50, Loss 0.47066453099250793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.34it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.8826347305389222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:03<00:05,  1.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 60, Loss 0.33082830905914307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.34it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9005988023952096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/14 [00:02<00:26,  2.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 70, Loss 0.28241416811943054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 12/14 [00:05<00:00,  2.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 80, Loss 0.2236263006925583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.32it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9143712574850299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 90, Loss 0.25102147459983826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.26it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9311377245508982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:08,  1.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 100, Loss 0.20372557640075684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.27it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 110, Loss 0.29970526695251465\n",
            "Accuracy on training set = 0.9347305389221557\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:02,  1.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 120, Loss 0.17396889626979828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.37it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9341317365269461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 5/14 [00:03<00:08,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 130, Loss 0.17130142450332642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:05<00:00,  2.37it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.944311377245509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2/14 [00:02<00:19,  1.65s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 140, Loss 0.16396862268447876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:06<00:01,  1.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 150, Loss 0.2937542498111725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.15it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9335329341317365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 7/14 [00:04<00:04,  1.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 160, Loss 0.16449202597141266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.20it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9455089820359281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:08,  1.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 170, Loss 0.1620987504720688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.17it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 180, Loss 0.1742718368768692\n",
            "Accuracy on training set = 0.9508982035928144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:03,  1.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 190, Loss 0.1835319846868515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.20it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9532934131736527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 5/14 [00:03<00:08,  1.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 200, Loss 0.09578991681337357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.23it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9491017964071856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2/14 [00:02<00:19,  1.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 210, Loss 0.17811855673789978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 11/14 [00:05<00:01,  1.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 220, Loss 0.1253374218940735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.15it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9568862275449102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 8/14 [00:04<00:02,  2.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 230, Loss 0.11044865101575851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.32it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9532934131736527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 4/14 [00:02<00:08,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 240, Loss 0.11085090786218643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.22it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 250, Loss 0.10590356588363647\n",
            "Accuracy on training set = 0.9580838323353293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 9/14 [00:05<00:03,  1.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 260, Loss 0.15872733294963837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.19it/s]\n",
            "  0%|          | 0/14 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9598802395209581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 6/14 [00:04<00:05,  1.35it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 270, Loss 0.11490757018327713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [00:06<00:00,  2.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set = 0.9646706586826347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsHFI-GAJd69",
        "colab_type": "text"
      },
      "source": [
        "##**Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3HV5pqJg1o",
        "colab_type": "code",
        "outputId": "ac69de64-bef0-40c3-81b0-dde445dca1bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(art_painting_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(art_painting))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.4296875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPzBRkB3iKWU",
        "colab_type": "code",
        "outputId": "8e158c4d-1737-489c-a499-a4f45fb8a67e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.094147682189941"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NHDb2yBC7jX",
        "colab_type": "text"
      },
      "source": [
        "# Model with DANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9PNdrqJdkSO",
        "colab_type": "text"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC1hCskMXaTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = alexNetDA(num_classes = 7)\n",
        "net = net.to(DEVICE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NemzVoaidnQA",
        "colab_type": "text"
      },
      "source": [
        "## Loss, Optim and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbFj42qsER6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion_class = nn.CrossEntropyLoss() \n",
        "criterion_domain = nn.CrossEntropyLoss()\n",
        "\n",
        "parameters_to_optimize = net.parameters() \n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW0rUNTbduSm",
        "colab_type": "text"
      },
      "source": [
        "## Train "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoZJAcaHEtYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#photos_dataloader = DataLoader(photos, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "#art_painting_dataloader = DataLoader(art_painting, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "max_batches = min(len(photos_dataloader), len(art_painting_dataloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4tSP1-uEPQt",
        "colab_type": "code",
        "outputId": "bbf8f01e-c835-454e-a367-d9bf16159aa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "running_corrects = 0\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "# Iterate over the dataset\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  scheduler.step() \n",
        "  iterPh = iter(photos_dataloader)\n",
        "  iterAP = iter(art_painting_dataloader)\n",
        "  for batch in range(max_batches):\n",
        "    net.train() # Sets module in training mode\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    images_source, labels_source = next(iterPh)\n",
        "    labels_domain = torch.zeros(len(images_source), dtype=torch.long)\n",
        "    \n",
        "    # Bring data over the device of choice\n",
        "    images_source = images_source.to(DEVICE)\n",
        "    labels_source = labels_source.to(DEVICE)\n",
        "    labels_domain = labels_domain.to(DEVICE)\n",
        "\n",
        "  \n",
        "    # Get the output for classes and domains; class_pred, domain_pred\n",
        "    classes_output = net(images_source)\n",
        "    # Compute the loss on the source domain\n",
        "    loss_s_label = criterion_class(classes_output, labels_source)\n",
        "\n",
        "    domain_output = net(images_source, alfa)\n",
        "    # Compute the loss on the source domain\n",
        "    loss_s_domain = criterion_domain(domain_output, labels_domain)\n",
        "\n",
        "    #In orter to compute the accuracy, count the right preditected labels\n",
        "    _, preds = torch.max(classes_output.data, 1)\n",
        "    \n",
        "    running_corrects += torch.sum(preds == labels_source.data).data.item()\n",
        "    \n",
        "    # Get the output for targets\n",
        "    targets, _ = next(iterAP)\n",
        "    target_domain = torch.ones(len(targets), dtype=torch.long)\n",
        "\n",
        "    # Bring data over the device of choice\n",
        "    targets = targets.to(DEVICE)\n",
        "    target_domain = target_domain.to(DEVICE)\n",
        "\n",
        "    target_output = net(targets, alfa)\n",
        "\n",
        "    # Compute the loss on the source domain\n",
        "    loss_t_domain = criterion_domain(target_output,target_domain)\n",
        "\n",
        "    loss = loss_s_label + loss_s_domain + loss_t_domain\n",
        "    loss.backward()  # backward pass: computes gradients\n",
        "\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "    print(f'[{batch+1}/{max_batches}] '\n",
        "          f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n",
        "          f't_domain_loss: {loss_t_domain.item():.4f} '\n",
        "          )  \n",
        "  # Calculate Accuracy \n",
        "  accuracy = running_corrects/float(len(photos))\n",
        "  print(f'Accuracy is: {accuracy}')\n",
        "  running_corrects = 0\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1/14] class_loss: 2.1772 s_domain_loss: 1.1837 t_domain_loss: 0.3980 \n",
            "[2/14] class_loss: 2.2323 s_domain_loss: 1.1558 t_domain_loss: 0.4094 \n",
            "[3/14] class_loss: 2.1053 s_domain_loss: 1.0724 t_domain_loss: 0.4414 \n",
            "[4/14] class_loss: 2.0718 s_domain_loss: 1.0181 t_domain_loss: 0.4903 \n",
            "[5/14] class_loss: 2.0512 s_domain_loss: 0.9228 t_domain_loss: 0.5420 \n",
            "[6/14] class_loss: 1.9476 s_domain_loss: 0.8376 t_domain_loss: 0.6116 \n",
            "[7/14] class_loss: 1.8671 s_domain_loss: 0.7533 t_domain_loss: 0.6761 \n",
            "[8/14] class_loss: 1.7421 s_domain_loss: 0.6775 t_domain_loss: 0.7415 \n",
            "[9/14] class_loss: 1.5578 s_domain_loss: 0.6182 t_domain_loss: 0.8106 \n",
            "[10/14] class_loss: 1.5299 s_domain_loss: 0.5725 t_domain_loss: 0.8690 \n",
            "[11/14] class_loss: 1.3954 s_domain_loss: 0.5416 t_domain_loss: 0.9200 \n",
            "[12/14] class_loss: 1.2927 s_domain_loss: 0.5182 t_domain_loss: 0.9525 \n",
            "[13/14] class_loss: 1.2481 s_domain_loss: 0.5116 t_domain_loss: 0.9353 \n",
            "[14/14] class_loss: 1.2274 s_domain_loss: 0.5246 t_domain_loss: 0.9524 \n",
            "Accuracy is: 0.332934131736527\n",
            "[1/14] class_loss: 1.1296 s_domain_loss: 0.5290 t_domain_loss: 0.9227 \n",
            "[2/14] class_loss: 1.3171 s_domain_loss: 0.5558 t_domain_loss: 0.8843 \n",
            "[3/14] class_loss: 1.1005 s_domain_loss: 0.5790 t_domain_loss: 0.8475 \n",
            "[4/14] class_loss: 1.1142 s_domain_loss: 0.6132 t_domain_loss: 0.8161 \n",
            "[5/14] class_loss: 1.0999 s_domain_loss: 0.6497 t_domain_loss: 0.7688 \n",
            "[6/14] class_loss: 1.0636 s_domain_loss: 0.6929 t_domain_loss: 0.7307 \n",
            "[7/14] class_loss: 1.0252 s_domain_loss: 0.7205 t_domain_loss: 0.6873 \n",
            "[8/14] class_loss: 0.8272 s_domain_loss: 0.7568 t_domain_loss: 0.6522 \n",
            "[9/14] class_loss: 0.7950 s_domain_loss: 0.7794 t_domain_loss: 0.6324 \n",
            "[10/14] class_loss: 0.7759 s_domain_loss: 0.8085 t_domain_loss: 0.6180 \n",
            "[11/14] class_loss: 0.7950 s_domain_loss: 0.8042 t_domain_loss: 0.6169 \n",
            "[12/14] class_loss: 0.6173 s_domain_loss: 0.8113 t_domain_loss: 0.6180 \n",
            "[13/14] class_loss: 0.5894 s_domain_loss: 0.8013 t_domain_loss: 0.6073 \n",
            "[14/14] class_loss: 0.7467 s_domain_loss: 0.8252 t_domain_loss: 0.6367 \n",
            "Accuracy is: 0.7263473053892215\n",
            "[1/14] class_loss: 0.7788 s_domain_loss: 0.7575 t_domain_loss: 0.6467 \n",
            "[2/14] class_loss: 0.7566 s_domain_loss: 0.7412 t_domain_loss: 0.6619 \n",
            "[3/14] class_loss: 0.6641 s_domain_loss: 0.7196 t_domain_loss: 0.6857 \n",
            "[4/14] class_loss: 0.5594 s_domain_loss: 0.6942 t_domain_loss: 0.7146 \n",
            "[5/14] class_loss: 0.6522 s_domain_loss: 0.6672 t_domain_loss: 0.7319 \n",
            "[6/14] class_loss: 0.6281 s_domain_loss: 0.6590 t_domain_loss: 0.7530 \n",
            "[7/14] class_loss: 0.6945 s_domain_loss: 0.6485 t_domain_loss: 0.7597 \n",
            "[8/14] class_loss: 0.5261 s_domain_loss: 0.6408 t_domain_loss: 0.7622 \n",
            "[9/14] class_loss: 0.5255 s_domain_loss: 0.6292 t_domain_loss: 0.7689 \n",
            "[10/14] class_loss: 0.4990 s_domain_loss: 0.6328 t_domain_loss: 0.7708 \n",
            "[11/14] class_loss: 0.5077 s_domain_loss: 0.6359 t_domain_loss: 0.7666 \n",
            "[12/14] class_loss: 0.5439 s_domain_loss: 0.6334 t_domain_loss: 0.7645 \n",
            "[13/14] class_loss: 0.5025 s_domain_loss: 0.6581 t_domain_loss: 0.7392 \n",
            "[14/14] class_loss: 0.2137 s_domain_loss: 0.6758 t_domain_loss: 0.7445 \n",
            "Accuracy is: 0.8389221556886227\n",
            "[1/14] class_loss: 0.4747 s_domain_loss: 0.6725 t_domain_loss: 0.7244 \n",
            "[2/14] class_loss: 0.4788 s_domain_loss: 0.6868 t_domain_loss: 0.7069 \n",
            "[3/14] class_loss: 0.4685 s_domain_loss: 0.6950 t_domain_loss: 0.6970 \n",
            "[4/14] class_loss: 0.4579 s_domain_loss: 0.7039 t_domain_loss: 0.6946 \n",
            "[5/14] class_loss: 0.4319 s_domain_loss: 0.7123 t_domain_loss: 0.6847 \n",
            "[6/14] class_loss: 0.4441 s_domain_loss: 0.7120 t_domain_loss: 0.6840 \n",
            "[7/14] class_loss: 0.4392 s_domain_loss: 0.7269 t_domain_loss: 0.6745 \n",
            "[8/14] class_loss: 0.4189 s_domain_loss: 0.7182 t_domain_loss: 0.6688 \n",
            "[9/14] class_loss: 0.4864 s_domain_loss: 0.7263 t_domain_loss: 0.6732 \n",
            "[10/14] class_loss: 0.3748 s_domain_loss: 0.7078 t_domain_loss: 0.6798 \n",
            "[11/14] class_loss: 0.4140 s_domain_loss: 0.7104 t_domain_loss: 0.6842 \n",
            "[12/14] class_loss: 0.4391 s_domain_loss: 0.7041 t_domain_loss: 0.6949 \n",
            "[13/14] class_loss: 0.4080 s_domain_loss: 0.6867 t_domain_loss: 0.6879 \n",
            "[14/14] class_loss: 0.3670 s_domain_loss: 0.7636 t_domain_loss: 0.7082 \n",
            "Accuracy is: 0.8880239520958084\n",
            "[1/14] class_loss: 0.2570 s_domain_loss: 0.6724 t_domain_loss: 0.7117 \n",
            "[2/14] class_loss: 0.3005 s_domain_loss: 0.6627 t_domain_loss: 0.7142 \n",
            "[3/14] class_loss: 0.3242 s_domain_loss: 0.6710 t_domain_loss: 0.7197 \n",
            "[4/14] class_loss: 0.3143 s_domain_loss: 0.6629 t_domain_loss: 0.7307 \n",
            "[5/14] class_loss: 0.4245 s_domain_loss: 0.6665 t_domain_loss: 0.7310 \n",
            "[6/14] class_loss: 0.3906 s_domain_loss: 0.6571 t_domain_loss: 0.7352 \n",
            "[7/14] class_loss: 0.3719 s_domain_loss: 0.6636 t_domain_loss: 0.7277 \n",
            "[8/14] class_loss: 0.3337 s_domain_loss: 0.6658 t_domain_loss: 0.7182 \n",
            "[9/14] class_loss: 0.3502 s_domain_loss: 0.6565 t_domain_loss: 0.7170 \n",
            "[10/14] class_loss: 0.3580 s_domain_loss: 0.6755 t_domain_loss: 0.7165 \n",
            "[11/14] class_loss: 0.3673 s_domain_loss: 0.6782 t_domain_loss: 0.7083 \n",
            "[12/14] class_loss: 0.3594 s_domain_loss: 0.6820 t_domain_loss: 0.7089 \n",
            "[13/14] class_loss: 0.3418 s_domain_loss: 0.6791 t_domain_loss: 0.6927 \n",
            "[14/14] class_loss: 0.2294 s_domain_loss: 0.6967 t_domain_loss: 0.7011 \n",
            "Accuracy is: 0.9059880239520958\n",
            "[1/14] class_loss: 0.3217 s_domain_loss: 0.6893 t_domain_loss: 0.6925 \n",
            "[2/14] class_loss: 0.3416 s_domain_loss: 0.6904 t_domain_loss: 0.6853 \n",
            "[3/14] class_loss: 0.2176 s_domain_loss: 0.6970 t_domain_loss: 0.6826 \n",
            "[4/14] class_loss: 0.2828 s_domain_loss: 0.6924 t_domain_loss: 0.6888 \n",
            "[5/14] class_loss: 0.2766 s_domain_loss: 0.6920 t_domain_loss: 0.6880 \n",
            "[6/14] class_loss: 0.2766 s_domain_loss: 0.6873 t_domain_loss: 0.6925 \n",
            "[7/14] class_loss: 0.2997 s_domain_loss: 0.6994 t_domain_loss: 0.6878 \n",
            "[8/14] class_loss: 0.3392 s_domain_loss: 0.6992 t_domain_loss: 0.6842 \n",
            "[9/14] class_loss: 0.3215 s_domain_loss: 0.6799 t_domain_loss: 0.6896 \n",
            "[10/14] class_loss: 0.3150 s_domain_loss: 0.6828 t_domain_loss: 0.6975 \n",
            "[11/14] class_loss: 0.2549 s_domain_loss: 0.6768 t_domain_loss: 0.6967 \n",
            "[12/14] class_loss: 0.3297 s_domain_loss: 0.6857 t_domain_loss: 0.7052 \n",
            "[13/14] class_loss: 0.2769 s_domain_loss: 0.6776 t_domain_loss: 0.6964 \n",
            "[14/14] class_loss: 0.4643 s_domain_loss: 0.6798 t_domain_loss: 0.7101 \n",
            "Accuracy is: 0.9137724550898204\n",
            "[1/14] class_loss: 0.2506 s_domain_loss: 0.6619 t_domain_loss: 0.7081 \n",
            "[2/14] class_loss: 0.2550 s_domain_loss: 0.6670 t_domain_loss: 0.7050 \n",
            "[3/14] class_loss: 0.2510 s_domain_loss: 0.6568 t_domain_loss: 0.7037 \n",
            "[4/14] class_loss: 0.2806 s_domain_loss: 0.6711 t_domain_loss: 0.7112 \n",
            "[5/14] class_loss: 0.3269 s_domain_loss: 0.6772 t_domain_loss: 0.7095 \n",
            "[6/14] class_loss: 0.3509 s_domain_loss: 0.6682 t_domain_loss: 0.7118 \n",
            "[7/14] class_loss: 0.2774 s_domain_loss: 0.6767 t_domain_loss: 0.7029 \n",
            "[8/14] class_loss: 0.2750 s_domain_loss: 0.6783 t_domain_loss: 0.6946 \n",
            "[9/14] class_loss: 0.2482 s_domain_loss: 0.6755 t_domain_loss: 0.6948 \n",
            "[10/14] class_loss: 0.3099 s_domain_loss: 0.6762 t_domain_loss: 0.6981 \n",
            "[11/14] class_loss: 0.2380 s_domain_loss: 0.6801 t_domain_loss: 0.6924 \n",
            "[12/14] class_loss: 0.2699 s_domain_loss: 0.6826 t_domain_loss: 0.6965 \n",
            "[13/14] class_loss: 0.1906 s_domain_loss: 0.6804 t_domain_loss: 0.6852 \n",
            "[14/14] class_loss: 0.2481 s_domain_loss: 0.7130 t_domain_loss: 0.6953 \n",
            "Accuracy is: 0.921556886227545\n",
            "[1/14] class_loss: 0.2196 s_domain_loss: 0.6741 t_domain_loss: 0.6924 \n",
            "[2/14] class_loss: 0.2910 s_domain_loss: 0.6814 t_domain_loss: 0.6900 \n",
            "[3/14] class_loss: 0.2220 s_domain_loss: 0.6779 t_domain_loss: 0.6890 \n",
            "[4/14] class_loss: 0.2691 s_domain_loss: 0.6840 t_domain_loss: 0.6984 \n",
            "[5/14] class_loss: 0.2203 s_domain_loss: 0.6729 t_domain_loss: 0.6991 \n",
            "[6/14] class_loss: 0.2864 s_domain_loss: 0.6717 t_domain_loss: 0.7039 \n",
            "[7/14] class_loss: 0.2233 s_domain_loss: 0.6673 t_domain_loss: 0.6981 \n",
            "[8/14] class_loss: 0.2573 s_domain_loss: 0.6698 t_domain_loss: 0.6925 \n",
            "[9/14] class_loss: 0.2148 s_domain_loss: 0.6712 t_domain_loss: 0.6943 \n",
            "[10/14] class_loss: 0.2831 s_domain_loss: 0.6707 t_domain_loss: 0.7003 \n",
            "[11/14] class_loss: 0.1788 s_domain_loss: 0.6667 t_domain_loss: 0.6946 \n",
            "[12/14] class_loss: 0.2723 s_domain_loss: 0.6705 t_domain_loss: 0.7001 \n",
            "[13/14] class_loss: 0.2317 s_domain_loss: 0.6702 t_domain_loss: 0.6893 \n",
            "[14/14] class_loss: 0.3419 s_domain_loss: 0.6861 t_domain_loss: 0.6977 \n",
            "Accuracy is: 0.9239520958083832\n",
            "[1/14] class_loss: 0.1893 s_domain_loss: 0.6705 t_domain_loss: 0.6941 \n",
            "[2/14] class_loss: 0.3064 s_domain_loss: 0.6838 t_domain_loss: 0.6904 \n",
            "[3/14] class_loss: 0.1663 s_domain_loss: 0.6713 t_domain_loss: 0.6873 \n",
            "[4/14] class_loss: 0.2133 s_domain_loss: 0.6592 t_domain_loss: 0.6960 \n",
            "[5/14] class_loss: 0.1905 s_domain_loss: 0.6840 t_domain_loss: 0.6950 \n",
            "[6/14] class_loss: 0.2727 s_domain_loss: 0.6749 t_domain_loss: 0.6983 \n",
            "[7/14] class_loss: 0.2908 s_domain_loss: 0.6745 t_domain_loss: 0.6922 \n",
            "[8/14] class_loss: 0.2146 s_domain_loss: 0.6840 t_domain_loss: 0.6859 \n",
            "[9/14] class_loss: 0.2577 s_domain_loss: 0.6658 t_domain_loss: 0.6875 \n",
            "[10/14] class_loss: 0.2741 s_domain_loss: 0.6734 t_domain_loss: 0.6943 \n",
            "[11/14] class_loss: 0.1301 s_domain_loss: 0.6671 t_domain_loss: 0.6882 \n",
            "[12/14] class_loss: 0.2276 s_domain_loss: 0.6598 t_domain_loss: 0.6950 \n",
            "[13/14] class_loss: 0.2103 s_domain_loss: 0.6673 t_domain_loss: 0.6860 \n",
            "[14/14] class_loss: 0.3472 s_domain_loss: 0.7485 t_domain_loss: 0.6931 \n",
            "Accuracy is: 0.9269461077844311\n",
            "[1/14] class_loss: 0.1952 s_domain_loss: 0.6703 t_domain_loss: 0.6915 \n",
            "[2/14] class_loss: 0.1585 s_domain_loss: 0.6596 t_domain_loss: 0.6890 \n",
            "[3/14] class_loss: 0.2266 s_domain_loss: 0.6663 t_domain_loss: 0.6857 \n",
            "[4/14] class_loss: 0.2323 s_domain_loss: 0.6714 t_domain_loss: 0.6949 \n",
            "[5/14] class_loss: 0.1868 s_domain_loss: 0.6799 t_domain_loss: 0.6939 \n",
            "[6/14] class_loss: 0.1968 s_domain_loss: 0.6687 t_domain_loss: 0.6977 \n",
            "[7/14] class_loss: 0.1927 s_domain_loss: 0.6684 t_domain_loss: 0.6919 \n",
            "[8/14] class_loss: 0.2187 s_domain_loss: 0.6629 t_domain_loss: 0.6853 \n",
            "[9/14] class_loss: 0.1839 s_domain_loss: 0.6663 t_domain_loss: 0.6864 \n",
            "[10/14] class_loss: 0.1548 s_domain_loss: 0.6650 t_domain_loss: 0.6932 \n",
            "[11/14] class_loss: 0.2449 s_domain_loss: 0.6733 t_domain_loss: 0.6859 \n",
            "[12/14] class_loss: 0.2383 s_domain_loss: 0.6655 t_domain_loss: 0.6924 \n",
            "[13/14] class_loss: 0.1768 s_domain_loss: 0.6799 t_domain_loss: 0.6838 \n",
            "[14/14] class_loss: 0.2898 s_domain_loss: 0.6709 t_domain_loss: 0.6908 \n",
            "Accuracy is: 0.9419161676646707\n",
            "[1/14] class_loss: 0.1910 s_domain_loss: 0.6729 t_domain_loss: 0.6881 \n",
            "[2/14] class_loss: 0.2232 s_domain_loss: 0.6731 t_domain_loss: 0.6855 \n",
            "[3/14] class_loss: 0.1508 s_domain_loss: 0.6689 t_domain_loss: 0.6821 \n",
            "[4/14] class_loss: 0.2002 s_domain_loss: 0.6666 t_domain_loss: 0.6919 \n",
            "[5/14] class_loss: 0.1380 s_domain_loss: 0.6558 t_domain_loss: 0.6909 \n",
            "[6/14] class_loss: 0.2432 s_domain_loss: 0.6733 t_domain_loss: 0.6947 \n",
            "[7/14] class_loss: 0.1917 s_domain_loss: 0.6672 t_domain_loss: 0.6891 \n",
            "[8/14] class_loss: 0.2355 s_domain_loss: 0.6626 t_domain_loss: 0.6821 \n",
            "[9/14] class_loss: 0.2170 s_domain_loss: 0.6550 t_domain_loss: 0.6831 \n",
            "[10/14] class_loss: 0.1719 s_domain_loss: 0.6664 t_domain_loss: 0.6902 \n",
            "[11/14] class_loss: 0.1792 s_domain_loss: 0.6651 t_domain_loss: 0.6827 \n",
            "[12/14] class_loss: 0.1902 s_domain_loss: 0.6704 t_domain_loss: 0.6888 \n",
            "[13/14] class_loss: 0.2592 s_domain_loss: 0.6678 t_domain_loss: 0.6808 \n",
            "[14/14] class_loss: 0.1860 s_domain_loss: 0.7087 t_domain_loss: 0.6873 \n",
            "Accuracy is: 0.9347305389221557\n",
            "[1/14] class_loss: 0.1971 s_domain_loss: 0.6753 t_domain_loss: 0.6860 \n",
            "[2/14] class_loss: 0.1835 s_domain_loss: 0.6572 t_domain_loss: 0.6852 \n",
            "[3/14] class_loss: 0.1461 s_domain_loss: 0.6560 t_domain_loss: 0.6824 \n",
            "[4/14] class_loss: 0.1513 s_domain_loss: 0.6620 t_domain_loss: 0.6924 \n",
            "[5/14] class_loss: 0.2575 s_domain_loss: 0.6546 t_domain_loss: 0.6914 \n",
            "[6/14] class_loss: 0.1884 s_domain_loss: 0.6600 t_domain_loss: 0.6957 \n",
            "[7/14] class_loss: 0.1385 s_domain_loss: 0.6679 t_domain_loss: 0.6896 \n",
            "[8/14] class_loss: 0.2486 s_domain_loss: 0.6615 t_domain_loss: 0.6817 \n",
            "[9/14] class_loss: 0.2153 s_domain_loss: 0.6646 t_domain_loss: 0.6829 \n",
            "[10/14] class_loss: 0.1591 s_domain_loss: 0.6531 t_domain_loss: 0.6901 \n",
            "[11/14] class_loss: 0.1617 s_domain_loss: 0.6626 t_domain_loss: 0.6821 \n",
            "[12/14] class_loss: 0.2056 s_domain_loss: 0.6679 t_domain_loss: 0.6889 \n",
            "[13/14] class_loss: 0.1242 s_domain_loss: 0.6670 t_domain_loss: 0.6812 \n",
            "[14/14] class_loss: 0.1153 s_domain_loss: 0.7181 t_domain_loss: 0.6874 \n",
            "Accuracy is: 0.9431137724550899\n",
            "[1/14] class_loss: 0.1178 s_domain_loss: 0.6697 t_domain_loss: 0.6826 \n",
            "[2/14] class_loss: 0.1352 s_domain_loss: 0.6668 t_domain_loss: 0.6789 \n",
            "[3/14] class_loss: 0.1838 s_domain_loss: 0.6719 t_domain_loss: 0.6744 \n",
            "[4/14] class_loss: 0.2227 s_domain_loss: 0.6629 t_domain_loss: 0.6832 \n",
            "[5/14] class_loss: 0.1418 s_domain_loss: 0.6742 t_domain_loss: 0.6814 \n",
            "[6/14] class_loss: 0.1766 s_domain_loss: 0.6613 t_domain_loss: 0.6863 \n",
            "[7/14] class_loss: 0.1560 s_domain_loss: 0.6521 t_domain_loss: 0.6808 \n",
            "[8/14] class_loss: 0.2101 s_domain_loss: 0.6599 t_domain_loss: 0.6734 \n",
            "[9/14] class_loss: 0.2245 s_domain_loss: 0.6801 t_domain_loss: 0.6756 \n",
            "[10/14] class_loss: 0.1569 s_domain_loss: 0.6577 t_domain_loss: 0.6840 \n",
            "[11/14] class_loss: 0.1669 s_domain_loss: 0.6580 t_domain_loss: 0.6772 \n",
            "[12/14] class_loss: 0.1215 s_domain_loss: 0.6646 t_domain_loss: 0.6851 \n",
            "[13/14] class_loss: 0.2052 s_domain_loss: 0.6468 t_domain_loss: 0.6790 \n",
            "[14/14] class_loss: 0.0891 s_domain_loss: 0.6853 t_domain_loss: 0.6853 \n",
            "Accuracy is: 0.9449101796407186\n",
            "[1/14] class_loss: 0.2335 s_domain_loss: 0.6631 t_domain_loss: 0.6818 \n",
            "[2/14] class_loss: 0.1176 s_domain_loss: 0.6605 t_domain_loss: 0.6793 \n",
            "[3/14] class_loss: 0.1527 s_domain_loss: 0.6468 t_domain_loss: 0.6752 \n",
            "[4/14] class_loss: 0.1438 s_domain_loss: 0.6547 t_domain_loss: 0.6838 \n",
            "[5/14] class_loss: 0.1308 s_domain_loss: 0.6492 t_domain_loss: 0.6811 \n",
            "[6/14] class_loss: 0.1676 s_domain_loss: 0.6654 t_domain_loss: 0.6849 \n",
            "[7/14] class_loss: 0.2275 s_domain_loss: 0.6613 t_domain_loss: 0.6789 \n",
            "[8/14] class_loss: 0.1489 s_domain_loss: 0.6574 t_domain_loss: 0.6707 \n",
            "[9/14] class_loss: 0.1631 s_domain_loss: 0.6686 t_domain_loss: 0.6725 \n",
            "[10/14] class_loss: 0.1110 s_domain_loss: 0.6795 t_domain_loss: 0.6805 \n",
            "[11/14] class_loss: 0.1792 s_domain_loss: 0.6679 t_domain_loss: 0.6735 \n",
            "[12/14] class_loss: 0.2352 s_domain_loss: 0.6660 t_domain_loss: 0.6820 \n",
            "[13/14] class_loss: 0.1657 s_domain_loss: 0.6499 t_domain_loss: 0.6774 \n",
            "[14/14] class_loss: 0.2944 s_domain_loss: 0.7059 t_domain_loss: 0.6847 \n",
            "Accuracy is: 0.9437125748502994\n",
            "[1/14] class_loss: 0.1595 s_domain_loss: 0.6538 t_domain_loss: 0.6819 \n",
            "[2/14] class_loss: 0.1684 s_domain_loss: 0.6526 t_domain_loss: 0.6804 \n",
            "[3/14] class_loss: 0.1190 s_domain_loss: 0.6476 t_domain_loss: 0.6772 \n",
            "[4/14] class_loss: 0.1383 s_domain_loss: 0.6745 t_domain_loss: 0.6863 \n",
            "[5/14] class_loss: 0.1783 s_domain_loss: 0.6601 t_domain_loss: 0.6842 \n",
            "[6/14] class_loss: 0.1797 s_domain_loss: 0.6542 t_domain_loss: 0.6886 \n",
            "[7/14] class_loss: 0.1836 s_domain_loss: 0.6501 t_domain_loss: 0.6831 \n",
            "[8/14] class_loss: 0.1295 s_domain_loss: 0.6480 t_domain_loss: 0.6742 \n",
            "[9/14] class_loss: 0.1146 s_domain_loss: 0.6487 t_domain_loss: 0.6749 \n",
            "[10/14] class_loss: 0.1412 s_domain_loss: 0.6599 t_domain_loss: 0.6816 \n",
            "[11/14] class_loss: 0.1999 s_domain_loss: 0.6470 t_domain_loss: 0.6726 \n",
            "[12/14] class_loss: 0.1704 s_domain_loss: 0.6651 t_domain_loss: 0.6784 \n",
            "[13/14] class_loss: 0.1393 s_domain_loss: 0.6600 t_domain_loss: 0.6720 \n",
            "[14/14] class_loss: 0.0096 s_domain_loss: 0.7174 t_domain_loss: 0.6775 \n",
            "Accuracy is: 0.9550898203592815\n",
            "[1/14] class_loss: 0.1403 s_domain_loss: 0.6545 t_domain_loss: 0.6708 \n",
            "[2/14] class_loss: 0.1675 s_domain_loss: 0.6587 t_domain_loss: 0.6664 \n",
            "[3/14] class_loss: 0.1555 s_domain_loss: 0.6700 t_domain_loss: 0.6609 \n",
            "[4/14] class_loss: 0.1550 s_domain_loss: 0.6620 t_domain_loss: 0.6692 \n",
            "[5/14] class_loss: 0.1320 s_domain_loss: 0.6768 t_domain_loss: 0.6670 \n",
            "[6/14] class_loss: 0.1699 s_domain_loss: 0.6683 t_domain_loss: 0.6727 \n",
            "[7/14] class_loss: 0.1478 s_domain_loss: 0.6669 t_domain_loss: 0.6697 \n",
            "[8/14] class_loss: 0.1364 s_domain_loss: 0.6670 t_domain_loss: 0.6636 \n",
            "[9/14] class_loss: 0.1619 s_domain_loss: 0.6502 t_domain_loss: 0.6681 \n",
            "[10/14] class_loss: 0.1987 s_domain_loss: 0.6549 t_domain_loss: 0.6784 \n",
            "[11/14] class_loss: 0.1463 s_domain_loss: 0.6659 t_domain_loss: 0.6725 \n",
            "[12/14] class_loss: 0.1461 s_domain_loss: 0.6609 t_domain_loss: 0.6819 \n",
            "[13/14] class_loss: 0.1395 s_domain_loss: 0.6350 t_domain_loss: 0.6783 \n",
            "[14/14] class_loss: 0.0693 s_domain_loss: 0.6699 t_domain_loss: 0.6850 \n",
            "Accuracy is: 0.9550898203592815\n",
            "[1/14] class_loss: 0.1030 s_domain_loss: 0.6461 t_domain_loss: 0.6826 \n",
            "[2/14] class_loss: 0.1838 s_domain_loss: 0.6464 t_domain_loss: 0.6808 \n",
            "[3/14] class_loss: 0.0806 s_domain_loss: 0.6413 t_domain_loss: 0.6768 \n",
            "[4/14] class_loss: 0.1842 s_domain_loss: 0.6429 t_domain_loss: 0.6854 \n",
            "[5/14] class_loss: 0.1378 s_domain_loss: 0.6431 t_domain_loss: 0.6815 \n",
            "[6/14] class_loss: 0.1383 s_domain_loss: 0.6562 t_domain_loss: 0.6848 \n",
            "[7/14] class_loss: 0.1454 s_domain_loss: 0.6487 t_domain_loss: 0.6785 \n",
            "[8/14] class_loss: 0.1496 s_domain_loss: 0.6495 t_domain_loss: 0.6681 \n",
            "[9/14] class_loss: 0.1625 s_domain_loss: 0.6476 t_domain_loss: 0.6693 \n",
            "[10/14] class_loss: 0.1131 s_domain_loss: 0.6552 t_domain_loss: 0.6760 \n",
            "[11/14] class_loss: 0.1543 s_domain_loss: 0.6453 t_domain_loss: 0.6663 \n",
            "[12/14] class_loss: 0.1271 s_domain_loss: 0.6602 t_domain_loss: 0.6722 \n",
            "[13/14] class_loss: 0.1580 s_domain_loss: 0.6686 t_domain_loss: 0.6664 \n",
            "[14/14] class_loss: 0.0593 s_domain_loss: 0.7167 t_domain_loss: 0.6732 \n",
            "Accuracy is: 0.9526946107784431\n",
            "[1/14] class_loss: 0.1932 s_domain_loss: 0.6779 t_domain_loss: 0.6686 \n",
            "[2/14] class_loss: 0.1457 s_domain_loss: 0.6531 t_domain_loss: 0.6678 \n",
            "[3/14] class_loss: 0.1248 s_domain_loss: 0.6560 t_domain_loss: 0.6652 \n",
            "[4/14] class_loss: 0.1592 s_domain_loss: 0.6491 t_domain_loss: 0.6756 \n",
            "[5/14] class_loss: 0.1915 s_domain_loss: 0.6420 t_domain_loss: 0.6740 \n",
            "[6/14] class_loss: 0.0998 s_domain_loss: 0.6469 t_domain_loss: 0.6792 \n",
            "[7/14] class_loss: 0.1344 s_domain_loss: 0.6371 t_domain_loss: 0.6749 \n",
            "[8/14] class_loss: 0.1203 s_domain_loss: 0.6454 t_domain_loss: 0.6658 \n",
            "[9/14] class_loss: 0.1135 s_domain_loss: 0.6666 t_domain_loss: 0.6681 \n",
            "[10/14] class_loss: 0.1028 s_domain_loss: 0.6498 t_domain_loss: 0.6761 \n",
            "[11/14] class_loss: 0.1491 s_domain_loss: 0.6411 t_domain_loss: 0.6672 \n",
            "[12/14] class_loss: 0.1657 s_domain_loss: 0.6561 t_domain_loss: 0.6745 \n",
            "[13/14] class_loss: 0.0932 s_domain_loss: 0.6494 t_domain_loss: 0.6691 \n",
            "[14/14] class_loss: 0.0938 s_domain_loss: 0.7211 t_domain_loss: 0.6754 \n",
            "Accuracy is: 0.9526946107784431\n",
            "[1/14] class_loss: 0.0923 s_domain_loss: 0.6498 t_domain_loss: 0.6699 \n",
            "[2/14] class_loss: 0.1192 s_domain_loss: 0.6461 t_domain_loss: 0.6679 \n",
            "[3/14] class_loss: 0.1559 s_domain_loss: 0.6452 t_domain_loss: 0.6635 \n",
            "[4/14] class_loss: 0.1418 s_domain_loss: 0.6452 t_domain_loss: 0.6727 \n",
            "[5/14] class_loss: 0.1509 s_domain_loss: 0.6292 t_domain_loss: 0.6695 \n",
            "[6/14] class_loss: 0.1138 s_domain_loss: 0.6621 t_domain_loss: 0.6733 \n",
            "[7/14] class_loss: 0.2358 s_domain_loss: 0.6350 t_domain_loss: 0.6687 \n",
            "[8/14] class_loss: 0.1067 s_domain_loss: 0.6511 t_domain_loss: 0.6590 \n",
            "[9/14] class_loss: 0.1169 s_domain_loss: 0.6511 t_domain_loss: 0.6619 \n",
            "[10/14] class_loss: 0.1246 s_domain_loss: 0.6696 t_domain_loss: 0.6701 \n",
            "[11/14] class_loss: 0.1309 s_domain_loss: 0.6761 t_domain_loss: 0.6621 \n",
            "[12/14] class_loss: 0.1345 s_domain_loss: 0.6412 t_domain_loss: 0.6707 \n",
            "[13/14] class_loss: 0.1229 s_domain_loss: 0.6626 t_domain_loss: 0.6669 \n",
            "[14/14] class_loss: 0.1196 s_domain_loss: 0.7057 t_domain_loss: 0.6734 \n",
            "Accuracy is: 0.9616766467065868\n",
            "[1/14] class_loss: 0.1543 s_domain_loss: 0.6514 t_domain_loss: 0.6702 \n",
            "[2/14] class_loss: 0.1660 s_domain_loss: 0.6557 t_domain_loss: 0.6681 \n",
            "[3/14] class_loss: 0.0993 s_domain_loss: 0.6497 t_domain_loss: 0.6634 \n",
            "[4/14] class_loss: 0.1679 s_domain_loss: 0.6165 t_domain_loss: 0.6725 \n",
            "[5/14] class_loss: 0.1325 s_domain_loss: 0.6466 t_domain_loss: 0.6692 \n",
            "[6/14] class_loss: 0.1050 s_domain_loss: 0.6493 t_domain_loss: 0.6741 \n",
            "[7/14] class_loss: 0.0611 s_domain_loss: 0.6379 t_domain_loss: 0.6705 \n",
            "[8/14] class_loss: 0.1303 s_domain_loss: 0.6478 t_domain_loss: 0.6616 \n",
            "[9/14] class_loss: 0.1385 s_domain_loss: 0.6620 t_domain_loss: 0.6653 \n",
            "[10/14] class_loss: 0.1684 s_domain_loss: 0.6435 t_domain_loss: 0.6740 \n",
            "[11/14] class_loss: 0.1982 s_domain_loss: 0.6482 t_domain_loss: 0.6661 \n",
            "[12/14] class_loss: 0.1226 s_domain_loss: 0.6379 t_domain_loss: 0.6744 \n",
            "[13/14] class_loss: 0.1030 s_domain_loss: 0.6452 t_domain_loss: 0.6706 \n",
            "[14/14] class_loss: 0.0012 s_domain_loss: 0.7084 t_domain_loss: 0.6766 \n",
            "Accuracy is: 0.9556886227544911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgONyH0xfN9W",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw4arKipfR0Q",
        "colab_type": "code",
        "outputId": "b93d8de2-de87-4533-a3ce-0ffa4f2376fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(art_painting_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(art_painting))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))\n",
        "print('Loss is: ' + str(loss.item()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:06<00:00,  2.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.42822265625\n",
            "Loss is: 4.8534088134765625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIyWY1Mn-ZP8",
        "colab_type": "code",
        "outputId": "2e6a3995-22af-48b2-9a57-2fcc5349e6fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "LR"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGi68vVW-a3G",
        "colab_type": "code",
        "outputId": "7ba25593-b646-44f2-d491-12470eb7cb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "alfa"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYzdDu7l-b5R",
        "colab_type": "code",
        "outputId": "b192cd0e-a9a0-4a26-fb15-005b7cac161f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NUM_EPOCHS"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}